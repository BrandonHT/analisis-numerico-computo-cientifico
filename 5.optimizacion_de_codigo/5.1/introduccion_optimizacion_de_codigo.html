
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>5.1 Introducción a optimización de código</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.2 Herramientas de lenguajes de programación y del sistema operativo para perfilamiento e implementaciones de BLAS" href="../5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html" />
    <link rel="prev" title="4.5 Método primal-dual de barrera logarítmica (BL)" href="../../4.optimizacion_en_redes_y_prog_lineal/4.5/Metodo_primal_dual_de_BL.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Optimización
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  1. Cómputo científico
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  2. Cómputo matricial
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  3. Optimización convexa y ecuaciones no lineales
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html">
   3.2 Algoritmos de descenso y búsqueda de línea en
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI.html">
   3.3 Ejemplos de problemas UCO, introducción a
   <em>
    Constrained Inequality and Equality Optimization
   </em>
   (CIEO) y puntos interiores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.4/Ecuaciones_no_lineales.html">
   3.4 Ecuaciones no lineales
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  4. Optimización en redes y programación lineal
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.1/Programacion_lineal_y_metodo_simplex.html">
   4.1 Programación lineal (PL) y método símplex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.2/Definiciones_generales_de_flujo_en_redes.html">
   4.2 Definiciones generales de flujo en redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.3/Ejemplo_metodo_simplex_de_redes.html">
   4.3 Ejemplo del método símplex de redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.4/Dualidad_lema_de_Farkas_condiciones_KKT_de_optimalidad.html">
   4.4 Dualidad, lema de Farkas y condiciones de Karush-Kuhn-Tucker (KKT) de optimalidad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.5/Metodo_primal_dual_de_BL.html">
   4.5 Método primal-dual de barrera logarítmica (BL)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  5. Optimización de código
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5.1 Introducción a optimización de código
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html">
   5.2 Herramientas de lenguajes de programación y del sistema operativo para perfilamiento e implementaciones de BLAS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.3/Compilacion_a_C.html">
   5.3 Compilación a C
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html">
   5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.5/Computo_en_paralelo_usando_GPUS_en_SMC.html">
   5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  6. Algoritmos de optimización convexa
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.1/Metodo_de_descenso_mas_pronunciado_para_UCO.html">
   6.1 Método de descenso más pronunciado para
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.2/Problemas_CECO.html">
   6.2 Problemas tipo
   <em>
    Constrained Equality Convex Optimization
   </em>
   (CECO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.3/Problemas_CIECO.html">
   6.3 Problemas tipo
   <em>
    Constrained Equality and Inequality Convex Optimization
   </em>
   (CIECO)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  7. Temas selectos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../7.temas_selectos/7.1/Optimizacion_estocastica.html">
   7.1 Optimización estocástica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../7.temas_selectos/7.2/Metodos_cuasi_Newton.html">
   7.2 Métodos cuasi Newton
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion_2?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/5.optimizacion_de_codigo/5.1/introduccion_optimizacion_de_codigo.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/5.optimizacion_de_codigo/5.1/introduccion_optimizacion_de_codigo.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#temas-a-considerar-para-escribir-un-programa-de-maquina-de-alto-rendimiento">
   Temas a considerar para escribir un programa de máquina de alto rendimiento
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#herramientas-que-tenemos-a-nuestra-disposicion-para-analizar-y-escribir-programas-de-maquina-para-un-alto-rendimiento">
   Herramientas que tenemos a nuestra disposición para analizar y escribir programas de máquina para un alto rendimiento
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectorizacion-blas-basic-linear-algebra-subprograms-y-el-uso-del-cache-eficientemente">
   Vectorización, BLAS: Basic Linear Algebra Subprograms y el uso del caché eficientemente.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-poco-de-historia-y-generalidades-del-sistema-en-una-computadora">
     Un poco de historia y generalidades del sistema en una computadora
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unidades-de-memoria">
     Unidades de memoria
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jerarquias-de-almacenamiento">
     Jerarquías de almacenamiento
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cache">
     Caché
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-funciona-el-acceso-a-la-memoria-en-un-sistema-de-computadora">
     ¿Cómo funciona el acceso a la memoria en un sistema de computadora?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interconexion-bus-o-capas-de-comunicacion-y-transferencia-de-datos">
     Interconexión,
     <em>
      bus
     </em>
     o capas de comunicación y transferencia de datos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unidades-computacionales">
     Unidades computacionales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiples-cpu-s-o-cores">
     Múltiples CPU’s o cores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#threading-o-hyperthreading">
     <em>
      Threading
     </em>
     o
     <em>
      Hyperthreading
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizacion-y-niveles-de-blas">
     Vectorización y niveles de BLAS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-de-operacion-nivel-blas-1-producto-interno-estandar-o-producto-punto">
     Ejemplo de operación nivel BLAS 1: producto interno estándar o producto punto
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementaciones-de-la-api-standard-de-blas-y-lapack">
     Implementaciones de la API standard de BLAS y LAPACK
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#que-es-el-perfilamiento-y-por-que-es-necesario">
   ¿Qué es el perfilamiento y por qué es necesario?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unit-testing">
     <em>
      Unit testing
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#por-que-compilar-a-codigo-de-maquina">
   ¿Por qué compilar a código de máquina?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#por-que-puede-ser-lenta-la-ejecucion-de-un-bloque-de-codigo-en-python-o-en-algun-otro-lenguaje-tipo-interprete">
     ¿Por qué puede ser lenta la ejecución de un bloque de código en
     <em>
      Python
     </em>
     (o en algún otro lenguaje tipo intérprete)?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sobre-los-terminos-concurrencia-paralelo-y-distribuido">
   Sobre los términos concurrencia, paralelo y distribuido
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paralelo">
     Paralelo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distribuido">
     Distribuido
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#concurrencia">
     Concurrencia
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#por-que-el-computo-en-paralelo">
     ¿Por qué el cómputo en paralelo?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#programas-cuya-ejecucion-es-en-paralelo">
     Programas cuya ejecución es en paralelo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cuando-es-recomendable-pensar-en-ejecutar-en-paralelo-tu-programa">
     ¿Cuando es recomendable pensar en ejecutar en paralelo tu programa?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#si-tengo-n-procesadores-espero-un-speedup-de-nx">
     Si tengo n procesadores ¿espero un
     <em>
      speedup
     </em>
     de
     <span class="math notranslate nohighlight">
      \(nx\)
     </span>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-que-nos-referimos-al-escribir-overhead-en-un-programa-cuya-ejecucion-es-en-paralelo">
     ¿A qué nos referimos al escribir
     <em>
      overhead
     </em>
     en un programa cuya ejecución es en paralelo?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cuales-enfoques-puedo-utilizar-para-escribir-programas-en-paralelo">
     ¿Cuáles enfoques puedo utilizar para escribir programas en paralelo?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-que-nos-referimos-con-el-termino-embarrassingly-parallel-problem">
     ¿A qué nos referimos con el término
     <em>
      embarrassingly parallel problem
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-inicio-en-la-programacion-en-paralelo-de-mi-codigo">
     ¿Cómo inicio en la programación en paralelo de mi código?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-en-la-regla-del-rectangulo-compuesta-en-una-maquina-multicore">
     Ejemplo en la regla del rectángulo compuesta en una máquina
     <em>
      multicore
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software">
     ¿
     <em>
      Software
     </em>
     ?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias-de-interes">
   Referencias de interés
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>5.1 Introducción a optimización de código</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#temas-a-considerar-para-escribir-un-programa-de-maquina-de-alto-rendimiento">
   Temas a considerar para escribir un programa de máquina de alto rendimiento
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#herramientas-que-tenemos-a-nuestra-disposicion-para-analizar-y-escribir-programas-de-maquina-para-un-alto-rendimiento">
   Herramientas que tenemos a nuestra disposición para analizar y escribir programas de máquina para un alto rendimiento
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectorizacion-blas-basic-linear-algebra-subprograms-y-el-uso-del-cache-eficientemente">
   Vectorización, BLAS: Basic Linear Algebra Subprograms y el uso del caché eficientemente.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-poco-de-historia-y-generalidades-del-sistema-en-una-computadora">
     Un poco de historia y generalidades del sistema en una computadora
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unidades-de-memoria">
     Unidades de memoria
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jerarquias-de-almacenamiento">
     Jerarquías de almacenamiento
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cache">
     Caché
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-funciona-el-acceso-a-la-memoria-en-un-sistema-de-computadora">
     ¿Cómo funciona el acceso a la memoria en un sistema de computadora?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interconexion-bus-o-capas-de-comunicacion-y-transferencia-de-datos">
     Interconexión,
     <em>
      bus
     </em>
     o capas de comunicación y transferencia de datos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unidades-computacionales">
     Unidades computacionales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiples-cpu-s-o-cores">
     Múltiples CPU’s o cores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#threading-o-hyperthreading">
     <em>
      Threading
     </em>
     o
     <em>
      Hyperthreading
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizacion-y-niveles-de-blas">
     Vectorización y niveles de BLAS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-de-operacion-nivel-blas-1-producto-interno-estandar-o-producto-punto">
     Ejemplo de operación nivel BLAS 1: producto interno estándar o producto punto
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementaciones-de-la-api-standard-de-blas-y-lapack">
     Implementaciones de la API standard de BLAS y LAPACK
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#que-es-el-perfilamiento-y-por-que-es-necesario">
   ¿Qué es el perfilamiento y por qué es necesario?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unit-testing">
     <em>
      Unit testing
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#por-que-compilar-a-codigo-de-maquina">
   ¿Por qué compilar a código de máquina?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#por-que-puede-ser-lenta-la-ejecucion-de-un-bloque-de-codigo-en-python-o-en-algun-otro-lenguaje-tipo-interprete">
     ¿Por qué puede ser lenta la ejecución de un bloque de código en
     <em>
      Python
     </em>
     (o en algún otro lenguaje tipo intérprete)?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sobre-los-terminos-concurrencia-paralelo-y-distribuido">
   Sobre los términos concurrencia, paralelo y distribuido
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paralelo">
     Paralelo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distribuido">
     Distribuido
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#concurrencia">
     Concurrencia
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#por-que-el-computo-en-paralelo">
     ¿Por qué el cómputo en paralelo?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#programas-cuya-ejecucion-es-en-paralelo">
     Programas cuya ejecución es en paralelo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cuando-es-recomendable-pensar-en-ejecutar-en-paralelo-tu-programa">
     ¿Cuando es recomendable pensar en ejecutar en paralelo tu programa?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#si-tengo-n-procesadores-espero-un-speedup-de-nx">
     Si tengo n procesadores ¿espero un
     <em>
      speedup
     </em>
     de
     <span class="math notranslate nohighlight">
      \(nx\)
     </span>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-que-nos-referimos-al-escribir-overhead-en-un-programa-cuya-ejecucion-es-en-paralelo">
     ¿A qué nos referimos al escribir
     <em>
      overhead
     </em>
     en un programa cuya ejecución es en paralelo?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cuales-enfoques-puedo-utilizar-para-escribir-programas-en-paralelo">
     ¿Cuáles enfoques puedo utilizar para escribir programas en paralelo?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-que-nos-referimos-con-el-termino-embarrassingly-parallel-problem">
     ¿A qué nos referimos con el término
     <em>
      embarrassingly parallel problem
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-inicio-en-la-programacion-en-paralelo-de-mi-codigo">
     ¿Cómo inicio en la programación en paralelo de mi código?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-en-la-regla-del-rectangulo-compuesta-en-una-maquina-multicore">
     Ejemplo en la regla del rectángulo compuesta en una máquina
     <em>
      multicore
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software">
     ¿
     <em>
      Software
     </em>
     ?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias-de-interes">
   Referencias de interés
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="introduccion-a-optimizacion-de-codigo">
<span id="introoptcodigo"></span><h1>5.1 Introducción a optimización de código<a class="headerlink" href="#introduccion-a-optimizacion-de-codigo" title="Permalink to this headline">#</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker y <code class="docutils literal notranslate"><span class="pre">&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code> por la versión más actualizada que se presenta en la documentación.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion_2</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion_2:&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion_2</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion_2:&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion_2">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de la <a class="reference external" href="https://www.dropbox.com/s/z465znq3wwao9ad/2.1.Un_poco_de_historia_y_generalidades.pdf?dl=0">liga</a></p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota la comunidad lectora:</p>
<ul class="simple">
<li><p>Conocerá razones del por qué algunas implementaciones de algoritmos son ineficientes a diferentes niveles. Uno es al nivel de lenguajes de programación utilizados. Otro es al nivel de componentes de un sistema computacional.</p></li>
<li><p>Conocerá herramientas para analizar y escribir programas para un alto rendimiento.</p></li>
<li><p>Conocerá rediseños que se han hecho a las unidades computacionales de un sistema computacional para resolver <em>bottlenecks</em>.</p></li>
<li><p>Conocerá la jerarquía de almacenamiento en el sistema de memoria de un sistema computacional.</p></li>
<li><p>Conocerá lo que significa vectorizar una operación y su relación con los niveles de BLAS.</p></li>
<li><p>Conocerá la diferencia entre programas secuenciales y en paralelo.</p></li>
<li><p>Aprenderá una metodología y enfoques utilizados para escribir programas con cómputo en paralelo.</p></li>
</ul>
</div>
<p>La implementación de los métodos o algoritmos en el contexto de grandes cantidades de datos o <em>big data</em> es crítica al ir a la práctica pues de esto depende que nuestra(s) máquina(s) tarde meses, semanas, días u horas para resolver problemas que se presentan en este contexto. Así, la <a class="reference external" href="https://en.wikipedia.org/wiki/Program_optimization">optimización de código o de software</a> nos ayuda a la eficiencia.</p>
<section id="temas-a-considerar-para-escribir-un-programa-de-maquina-de-alto-rendimiento">
<h2>Temas a considerar para escribir un programa de máquina de alto rendimiento<a class="headerlink" href="#temas-a-considerar-para-escribir-un-programa-de-maquina-de-alto-rendimiento" title="Permalink to this headline">#</a></h2>
<p>Para tener un alto <em>performance</em> en un programa de máquina, deben considerarse las siguientes preguntas:</p>
<ul class="simple">
<li><p>¿Qué tanto aprovecha mi programa aspectos como <em><strong>data reuse</strong></em> y <em><strong>data locality</strong></em>?</p></li>
</ul>
<p>La respuesta nos lleva a pensar en el número de instrucciones por ciclo y el número de ciclos que realiza el procesador. Entiéndase un ciclo por los pasos de leer una instrucción, determinar acciones a realizar por tal instrucción y ejecutar las acciones, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Instruction_cycle">liga</a>.</p>
<ul class="simple">
<li><p>¿Cómo es mi <em><strong>data layout</strong></em> en el almacenamiento? (forma en la que están almacenados o dispuestos los datos)</p></li>
</ul>
<p>Dependiendo de la respuesta podemos elegir una arquitectura de computadoras u otra y así también un algoritmo u otro.</p>
<ul class="simple">
<li><p>¿Cuánto <em><strong>data movement</strong></em> o <em><strong>data motion</strong></em> realiza mi programa? (flujo de datos entre los distintos niveles de jerarquía de almacenamiento o entre las máquinas en un clúster de máquinas, por ejemplo)</p></li>
</ul>
<p>La respuesta implica analizar el tráfico de datos entre las <strong>jerarquías de almacenamiento</strong> (o máquinas si estamos en un clúster de máquinas) y potenciales <em><strong>bottlenecks</strong></em>.</p>
</section>
<section id="herramientas-que-tenemos-a-nuestra-disposicion-para-analizar-y-escribir-programas-de-maquina-para-un-alto-rendimiento">
<h2>Herramientas que tenemos a nuestra disposición para analizar y escribir programas de máquina para un alto rendimiento<a class="headerlink" href="#herramientas-que-tenemos-a-nuestra-disposicion-para-analizar-y-escribir-programas-de-maquina-para-un-alto-rendimiento" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Vectorización que pueden realizar los procesadores.</p></li>
<li><p>Perfilamiento de código para lograr la eficiencia deseada.</p></li>
<li><p>Programación en lenguajes compilados en lugar de intérpretes (o combinando intérpretes con lenguajes compilados)</p></li>
<li><p>Conocimiento de los propósitos con los que fueron diseñados los procesadores para explotar su capacidad. Aquí decidimos si usamos <strong>código secuencial</strong> o <strong>código en paralelo</strong>.</p></li>
</ul>
<p>…además necesitamos conocer las diferentes <strong>arquitecturas</strong> que pueden utilizarse para cómputo en paralelo.</p>
<ul class="simple">
<li><p>¿Alguien ya resolvió mi <em>bottleneck</em>?</p></li>
<li><p>Experiencia en el lenguaje de programación seleccionado.</p></li>
</ul>
</section>
<section id="vectorizacion-blas-basic-linear-algebra-subprograms-y-el-uso-del-cache-eficientemente">
<h2>Vectorización, <a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">BLAS: Basic Linear Algebra Subprograms</a> y el uso del caché eficientemente.<a class="headerlink" href="#vectorizacion-blas-basic-linear-algebra-subprograms-y-el-uso-del-cache-eficientemente" title="Permalink to this headline">#</a></h2>
<p>Para comprender lo que la vectorización y finalmente las operaciones de la especificación BLAS en sus diferentes niveles tienen por objetivo resolver, revisemos de forma general el sistema de una computadora.</p>
<section id="un-poco-de-historia-y-generalidades-del-sistema-en-una-computadora">
<h3>Un poco de historia y generalidades del sistema en una computadora<a class="headerlink" href="#un-poco-de-historia-y-generalidades-del-sistema-en-una-computadora" title="Permalink to this headline">#</a></h3>
<p>Las componentes fundamentales de un sistema en una computadora pueden simplificarse en:</p>
<ul class="simple">
<li><p>Unidades computacionales. En éstas unidades nos interesa la pregunta ¿cuántos cálculos pueden realizar por segundo?</p></li>
<li><p>Unidades de memoria. En éstas unidades nos interesa la pregunta ¿cuántos datos pueden alojar y qué tan rápido puede leerse desde y escribirse hacia las distintas jerarquías?</p></li>
<li><p>Conexiones entre las unidades anteriores. Nos interesa ¿qué tan rápido pueden moverse datos de un lugar a otro?</p></li>
</ul>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="https://es.wikipedia.org/wiki/Cach%C3%A9">liga</a> para información sobre cachés tipo L.</p>
</aside>
<p>Con esta simplificación tenemos como ejemplo a la CPU como unidad de cómputo conectada tanto a la RAM y a un disco duro como dos unidades de memoria y un <em>bus</em> que provee las conexiones entre estas partes. Otro ejemplo es considerar que la CPU tiene diferentes unidades de memoria en ella: los cachés tipo L1, L2, L3 y L4 conectadas a la CPU a través de otro <em>bus</em>. También la GPU es ejemplo de una unidad de cómputo conectada a una unidades de memoria como RAM y cachés.</p>
<p>Un dibujo simplificado y basado en una arquitectura de computadoras con nombre <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann_architecture">Von Neumann</a> que nos ayuda a visualizar lo anterior en la <strong>CPU</strong> es el siguiente:</p>
<img src="https://dl.dropboxusercontent.com/s/txsj5mzxyajbypa/von_Neumann.png?dl=0" heigth="500" width="500"><ul class="simple">
<li><p>La <strong>memoria principal</strong> es una colección de ubicaciones que almacenan datos e instrucciones. Cada ubicación consiste de una dirección (<em>address</em>) que se utiliza para accesar a la ubicación y a sus contenidos.</p></li>
<li><p>La CPU está dividida en la <strong>unidad de control y la unidad aritmética y lógica</strong>. Aquí encontramos <em>registers</em> que son áreas o ubicaciones de almacenamiento (de datos, direcciones de memoria e información del estado de ejecución de un programa) de rápido acceso.</p></li>
<li><p>La <strong>interconexión</strong> o <em>bus</em> ayuda a la transferencia de datos e instrucciones entre la CPU y la memoria.</p></li>
</ul>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>En el dibujo no se está presentando los dispositivos de <em>input</em> y <em>output</em> pero sí aparecen en la arquitectura de Von Neumann.</p></li>
<li><p>También no se presentan en el dibujo unidades de almacenamiento como los discos duros pero también aparecen en la arquitectura de Von Neumann. Los discos duros se consideran dentro de las unidades de memoria y la CPU se conecta a ellos mediante un <em>bus</em>.</p></li>
<li><p>Si los datos se transfieren de la memoria a la CPU se dice que los datos o instrucciones son leídas y si van de la CPU a la memoria decimos que son escritos a memoria.</p></li>
<li><p>La separación entre la memoria y la CPU genera lo que se conoce como <strong>Von Neumann <em>bottleneck</em></strong> y tiene que ver con la lectura/escritura y almacenamiento de datos e instrucciones. La interconexión determina la tasa a la cual se accede a éstos.</p></li>
</ul>
</div>
</section>
<section id="unidades-de-memoria">
<h3>Unidades de memoria<a class="headerlink" href="#unidades-de-memoria" title="Permalink to this headline">#</a></h3>
<p>Su objetivo es el almacenamiento de bits de información. Como ejemplos tenemos la memoria RAM, discos duros o el caché. La principal diferencia entre cada tipo de unidad de memoria es la velocidad a la que pueden leer/escribir datos. Ésta velocidad depende enormemente de la forma en que se leen/escriben los datos. Por ejemplo, la mayoría de las unidades de memoria tienen un mejor <em>performance</em> al leer un gran pedazo de información que al leer muchos pedacitos.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Desde el punto de vista de los lenguajes de programación como Python o R, un resultado del manejo automático de memoria en estos lenguajes, es la fragmentación de datos o <em><strong>data fragmentation</strong></em> que surge al no tener bloques contiguos de memoria. Esto causa que en lugar de mover todo un bloque contiguo de datos en una sola transferencia a través del <em>bus</em> se requieran mover pedazos de memoria de forma individual lo que causa un mayor tiempo de lectura.</p>
</div>
<p>Las unidades de memoria tienen latencia que típicamente cambia dependiendo de una jerarquía de almacenamiento mostrada en el  dibujo siguiente:</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Entiéndase por latencia el tiempo que le toma a la unidad o dispositivo para encontrar los datos que serán usados por el proceso.</p>
</div>
</section>
<section id="jerarquias-de-almacenamiento">
<h3>Jerarquías de almacenamiento<a class="headerlink" href="#jerarquias-de-almacenamiento" title="Permalink to this headline">#</a></h3>
<img src="https://dl.dropboxusercontent.com/s/ahxsnpgp4rjdvw3/jerarquias_de_almacenamiento.png?dl=0" heigth="500" width="500">
<p>En el dibujo anterior se representan típicos dispositivos de almacenamiento en una máquina. La capacidad de almacenamiento <strong>disminuye</strong> conforme nos movemos hacia arriba en el dibujo: mientras que en disco podemos almacenar terabytes de información, en los <em>registers</em> sólo podemos almacenar bytes o kilobytes. Por el contrario, la velocidad de lectura/escritura <strong>disminuye</strong> conforme nos movemos hacia abajo: la lectura y escritura en disco es órdenes de veces más tardado que en los <em>registers</em> (que físicamente están en el procesador).</p>
</section>
<section id="cache">
<h3>Caché<a class="headerlink" href="#cache" title="Permalink to this headline">#</a></h3>
<p>Entre las técnicas que tenemos a nuestro alcance para que un algoritmo pueda aprovechar el <em><strong>data layout</strong></em> de la información se encuentra el <em>caching</em>: el eficiente uso del caché.</p>
<p>El caché es una memoria que está físicamente localizada más cercana a los registers del procesador para almacenar datos e instrucciones por lo que pueden ser accesados en menor tiempo que en otras unidades de memoria (como la RAM).</p>
<p>El caché se diseñó para resolver el Von Neumann <em>bottleneck</em> al existir un límite de tasa de transferencia entre la memoria RAM y el procesador (CPU o GPU). Si pudiéramos mover datos de una forma infinitamente rápida, no necesitaríamos al caché pues el procesador podría obtener los datos en cualquier instante, en esta situación no existiría tal bottleneck.</p>
<p>Aunque no tenemos en nuestros lenguajes de programación instrucciones del tipo “carga los datos en el caché” podemos usar los principios de <strong>localidad</strong> y <strong>temporalidad</strong> para mejorar la eficiencia de nuestros algoritmos. Los principios de localidad y temporalidad consisten en que el sistema de memoria tiende a usar los datos e instrucciones que físicamente son cercanos (localidad) y los datos e instrucciones que recientemente fueron usados (temporalidad).</p>
</section>
<section id="como-funciona-el-acceso-a-la-memoria-en-un-sistema-de-computadora">
<h3>¿Cómo funciona el acceso a la memoria en un sistema de computadora?<a class="headerlink" href="#como-funciona-el-acceso-a-la-memoria-en-un-sistema-de-computadora" title="Permalink to this headline">#</a></h3>
<p>Si el procesador requiere un conjunto de datos para ejecutar instrucciones, el sistema de memoria carga un bloque de datos (aunque pueden ser también instrucciones), conocido como <em><strong>cache blocks</strong></em> o <em><strong>cache lines</strong></em> para que el procesador opere en ellos.</p>
</section>
<section id="ejemplo">
<h3>Ejemplo<a class="headerlink" href="#ejemplo" title="Permalink to this headline">#</a></h3>
<p>En C al declarar un arreglo con la línea: <code class="docutils literal notranslate"><span class="pre">float</span> <span class="pre">z[20];</span></code> se le solicita al sistema de memoria que se alojen <span class="math notranslate nohighlight">\(20\)</span> bloques contiguos de ubicaciones de memoria en la RAM, esto es: la ubicación para el almacenamiento de <code class="docutils literal notranslate"><span class="pre">z[1]</span></code> está inmediatamente después de la de <code class="docutils literal notranslate"><span class="pre">z[0]</span></code>. Si además tenemos un programa como el siguiente:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="p">...</span><span class="w"></span>
<span class="kt">float</span><span class="w"> </span><span class="n">z</span><span class="p">[</span><span class="mi">20</span><span class="p">];</span><span class="w"></span>
<span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="mi">20</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">   </span><span class="n">sum</span><span class="o">+=</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="p">...</span><span class="w"></span>
</pre></div>
</div>
<p>y nuestro cache line permite almacenar <span class="math notranslate nohighlight">\(16\)</span> floats, entonces el sistema de memoria leerá los datos <code class="docutils literal notranslate"><span class="pre">z[0],...,z[15]</span></code> de la RAM al caché y el procesador realizará la suma.</p>
<p>Posteriormente el procesador (que en este caso es la CPU) al accesar a los datos checa primero el caché, si las encontró se le conoce como <em><strong>cache hit</strong></em>, si no lo encontró sería un <em><strong>cache miss</strong></em> y el sistema de memoria tendría que leer nuevamente desde la RAM.</p>
</section>
<section id="id1">
<h3>Ejemplo<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>C almacena los arreglos de dos dimensiones en una forma <em><strong>row major</strong></em>, esto es, aunque en papel representamos tales arreglos como un bloque rectangular, en la implementación en este lenguaje se están almacenando como un arreglo de una dimensión: el renglón <span class="math notranslate nohighlight">\(0\)</span> es almacenado primero, a continuación el renglón <span class="math notranslate nohighlight">\(1\)</span> y así sucesivamente.</p>
<p>Observemos los siguientes códigos que realizan una multiplicación <strong>secuencial</strong> entre una matriz <code class="docutils literal notranslate"><span class="pre">A</span></code> y un vector <code class="docutils literal notranslate"><span class="pre">x</span></code> para obtener al vector <code class="docutils literal notranslate"><span class="pre">y</span></code>:</p>
<p><strong>Algoritmo: multiplicación matriz vector secuencial</strong></p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">MAX</span><span class="p">][</span><span class="n">MAX</span><span class="p">],</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">MAX</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="p">[</span><span class="n">MAX</span><span class="p">];</span><span class="w"> </span><span class="c1">//MAX es un valor constante definido previamente</span>
<span class="p">...</span><span class="w"></span>

<span class="c1">//bloque de código para inicializar A,x</span>
<span class="c1">//bloque de código para inicializar y con ceros</span>

<span class="c1">//Algoritmo 1:</span>

<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">MAX</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="n">MAX</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">        </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+=</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">];</span><span class="w"></span>

<span class="c1">//volver a asignar a y con ceros</span>

<span class="c1">//Algoritmo 2:</span>

<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="n">MAX</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">MAX</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">        </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+=</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
<p>Supongamos que <code class="docutils literal notranslate"><span class="pre">MAX=4</span></code> y los elementos de <code class="docutils literal notranslate"><span class="pre">A</span></code> están almacenados en memoria como sigue:</p>
<img src="https://dl.dropboxusercontent.com/s/rgjh4pv0o1kbe24/ejemplo_cache.png?dl=0" heigth="500" width="500">
<p>para simplificar el siguiente análisis supóngase que:</p>
<ul class="simple">
<li><p>Ninguno de los elementos de <code class="docutils literal notranslate"><span class="pre">A</span></code> están en el caché al iniciar el par de loops.</p></li>
<li><p>Un <em>cache line</em> consiste de <span class="math notranslate nohighlight">\(4\)</span> elementos de <code class="docutils literal notranslate"><span class="pre">A</span></code> y <code class="docutils literal notranslate"><span class="pre">A[0][0]</span></code> es el primer elemento del <em>cache line</em>.</p></li>
<li><p>Cada <em>cache line</em> le corresponde una única úbicación en el caché al que será asignado.</p></li>
<li><p>El caché sólo puede almacenar <span class="math notranslate nohighlight">\(4\)</span> elementos de <code class="docutils literal notranslate"><span class="pre">A</span></code> o un <em>cache line</em>.</p></li>
</ul>
<p>Entonces para el algoritmo <span class="math notranslate nohighlight">\(1\)</span> se tiene que la CPU y el sistema de memoria:</p>
<ol class="simple">
<li><p>La CPU requiere <code class="docutils literal notranslate"><span class="pre">A[0][0]</span></code> que no se encuentra en el caché por lo que tenemos un <em>cache miss</em> y el sistema de memoria lee de RAM el <em>cache line</em>: <code class="docutils literal notranslate"><span class="pre">A[0][0]</span> <span class="pre">A[0][1]</span> <span class="pre">A[0][2]</span> <span class="pre">A[0][3]</span></code> y al estar en caché la CPU puede operar con <code class="docutils literal notranslate"><span class="pre">A[0][0]</span></code>.</p></li>
<li><p>La CPU requiere <code class="docutils literal notranslate"><span class="pre">A[0][1]</span></code> que sí se encuentra en el caché por lo que tenemos un <em>cache hit</em> y la CPU opera con éste dato. Posteriormente la CPU requiere <code class="docutils literal notranslate"><span class="pre">A[0][2]</span></code>, <code class="docutils literal notranslate"><span class="pre">A[0][3]</span></code> y <code class="docutils literal notranslate"><span class="pre">A[0][4]</span></code> que se encuentran en caché y se tienen otros tres <em>cache hits</em>.</p></li>
<li><p>La CPU requiere <code class="docutils literal notranslate"><span class="pre">A[1][0]</span></code> que resulta en un <em>cache miss</em> y el sistema de memoria lee de RAM el <em>cache line</em>: <code class="docutils literal notranslate"><span class="pre">A[1][0]</span> <span class="pre">A[1][1]</span> <span class="pre">A[1][2]</span> <span class="pre">A[1][3]</span></code> y al estar en caché la CPU puede operar con <code class="docutils literal notranslate"><span class="pre">A[1][0]</span></code>.</p></li>
</ol>
<p>…</p>
<p>Finalmente para el algoritmo <span class="math notranslate nohighlight">\(1\)</span> tenemos <span class="math notranslate nohighlight">\(4\)</span> cache misses, uno por cada renglón.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>¿Cuál es el número de cache misses para el algoritmo 2?.</p>
</div>
<p>Mayor número de <em>cache misses</em> incrementa el tiempo de ejecución de las instrucciones por el procesador pues no solamente el procesador espera mientras se transfieren los datos de la RAM hacia el caché sino también se interrumpe el flujo de la ejecución del <em>pipeline</em> (transferencia de datos y ejecución de instrucciones). Por ello es importante que los algoritmos trabajen con un buen <em><strong>data layout</strong></em> de la información en memoria y utilicen el <em><strong>data reuse</strong></em> y <em><strong>data locality</strong></em>.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El <em>pipelining</em> es un mecanismo utilizado por un procesador para la ejecución de instrucciones. Obstáculos al <em>pipelining</em> se encuentran los <em>cache misses</em> o el llamado <em>mispredicted branching</em>. El <em>branch prediction</em>, relacionado con el <em>branching</em> en un código (para el <em>branching</em> piénsese por ejemplo en una línea de código del tipo <code class="docutils literal notranslate"><span class="pre">if...then</span></code>), es otro mecanismo del procesador para tratar de predecir la siguiente instrucción a ejecutar y cargar las porciones relevantes de memoria en el caché mientras se trabaja en la instrucción actual. El procesador al toparse con un <em>branching</em> en el código trata de hacer una suposición de qué dirección se tomará en el <em>branching</em> y precargar las instrucciones relevantes, si falla tiene <em><strong>branch-misses</strong></em>. Aunque también son importantes estos aspectos al considerar la implementación de un algoritmo, la herramienta más rápida que tenemos para resolver los <em>bottlenecks</em> en este contexto, son trabajar en la localidad y temporalidad de los datos.</p></li>
<li><p>Un factor que incrementa el número de <em>cache-misses</em> es la fragmentación de datos, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Fragmentation_(computing)">Fragmentation</a>. La fragmentación incrementa el número de transferencias de memoria hacia la CPU y además imposibilita la vectorización porque el caché no está lleno. El caché puede llenarse sólo al tener bloques contiguos de memoria alojados para los datos (la interconexión o <em>bus</em> sólo puede mover <em>chunks</em> de memoria contigua). Python en su implementación común <a class="reference external" href="https://github.com/python/cpython">CPython</a>, tiene <em><strong>data fragmentation</strong></em> por ejemplo al usar listas. Las listas de Python alojan locaciones donde se pueden encontrar los datos y no los datos en sí. Al utilizar listas para operaciones matriciales el <em>runtime</em> de Python tiene <em>overhead</em> en la transferencia de datos pues debe realizar <em>lookups</em> por índices, al no encontrarse de forma contigua los datos se tendrán un mayor número de <em>cache-misses</em> y también los <em>cores</em> deberán esperar hasta que los datos estén disponibles en el caché. Por lo anterior las listas no se recomiendan para operaciones vectoriales o matriciales pero sí se utilizarían para almacenar diferentes tipos de valores en una sola estructura de datos.</p></li>
<li><p>En Python se tiene el paquete de <a class="reference external" href="https://numpy.org/">NumPy</a> para almacenamiento de bloques de memoria contiguos de arreglos y uso de la capacidad de la CPU para operaciones en un modo vectorizado. Sin extensiones a Python con paquetes como <code class="docutils literal notranslate"><span class="pre">numpy</span></code> no sería posible en este lenguaje aprovechar la vectorización (capaz de realizar un procesador actual) ni alojar bloques de memoria contiguos. El no soporte para operaciones vectorizadas tiene que ver con que el <a class="reference external" href="https://docs.python.org/3.9/glossary.html#term-bytecode">bytecode</a> de Python no está optimizado para vectorización. En el caso del alojamiento de bloques de memoria contiguos, Python es un <em>garbage-collected language</em> que permite que la memoria sea automáticamente alojada y liberada. No obstante tal característica causa problemas del tipo <em><strong>memory fragmentation</strong></em> que afecta la transferencia al caché de datos <strong>usables</strong> o <strong>relevantes</strong> para las operaciones (ver ejemplo del algoritmo 2 anterior).</p></li>
</ul>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Los archivos con extensión <code class="docutils literal notranslate"><span class="pre">.pyc</span></code> en <em>Python</em> contienen el <em>bytecode</em>. Ver <a class="reference external" href="https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files/2998544">if-python-is-interpreted-what-are-pyc-files</a>. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Bytecode">bytecode</a> para una explicación más general.</p>
</div>
</section>
<section id="interconexion-bus-o-capas-de-comunicacion-y-transferencia-de-datos">
<h3>Interconexión, <em>bus</em> o capas de comunicación y transferencia de datos<a class="headerlink" href="#interconexion-bus-o-capas-de-comunicacion-y-transferencia-de-datos" title="Permalink to this headline">#</a></h3>
<p>Hay distintos <em>bus</em> que permiten la comunicación entre las unidades computacionales y las de memoria:</p>
<ul class="simple">
<li><p>El <em>backside bus</em> que permite la conexión entre el caché y el procesador. Tiene la tasa de transferencia de datos más alta.</p></li>
<li><p>El <em>frontside bus</em> permite la conexión entre la RAM y los L’s cachés. Mueve los datos para ser procesados por el procesador (CPU o GPU) y mueve los datos de salida (resultados) entre estas regiones de memoria.</p></li>
<li><p>El <em>external bus</em> cuya acción se realiza en los dispositivos de hardware como los discos duros y tarjetas de memoria hacia la CPU y el sistema de memoria. Este <em>bus</em>  típicamente es más lento que el <em>frontside bus</em>.</p></li>
</ul>
<p>Entonces los datos se mueven del disco hacia la RAM con el <em>external bus</em>, luego de la RAM hacia el caché vía el <em>frontside bus</em> y finalmente del caché hacia la CPU con el <em>backside bus</em>.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>La GPU está conectada en un dispositivo periférico y se comunica através del <em>PCI bus</em>, (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Conventional_PCI">PCI</a>) el cual es más lento que el <em>frontside bus</em>. Como resultado, la transferencia de datos hacia la GPU y fuera de ésta es una operación costosa. Un diseño que atiende este problema es tener tanto a la CPU como a la GPU en el <em>frontside bus</em> para reducción de costos de transferencia hacia la GPU para grandes cantidades de información.</p></li>
<li><p>Otra capa de comunicación en un sistema de computadora es la red o <em>network</em>. Un dispositivo de red puede conectarse a una unidad de memoria u a otra unidad de computación. Típicamente la comunicación por red es mucho más lenta que las comunicaciones con el <em>backside, frontside, external bus</em> descritos antes.</p></li>
<li><p>La propiedad principal de un <em>bus</em> es su velocidad: ¿cuántos datos pueden moverse en un periodo de tiempo? Esta propiedad se obtiene combinando el <em>bus width</em> entendido como ¿cuántos datos se pueden mover en una transferencia? (físicamente se puede observar por el número de cables del <em>bus</em>) y el <em>bus frequency</em> ¿cuántas transferencias se pueden hacer por segundo? (físicamente se ve en la longitud de los cables que unen a las unidades de cómputo o memoria).</p></li>
<li><p>Es importante notar que el movimiento de los datos en una transferencia siempre es secuencial: un pedazo de datos es leído de memoria y es movido a otro lugar: no es posible leer un pedazo de datos y moverlo a distintos lugares o leer divisiones del pedazo de datos que estén en distintos lugares.</p></li>
<li><p>Un <em>bus width</em> grande ayuda a la vectorización pues en una sola transferencia se mueven los datos importantes. Un <em>bus frequency</em> alto puede ayudar al código a realizar una gran candidad de lecturas de diferentes lugares de la memoria. Depende qué operación es la que se desea realizar lo que en un caso u otro convendrá. Por ejemplo, si el problema a resolver se relaciona con la cantidad de lecturas que se deben hacer, podríamos tener un <em>bus frequency</em> alto y un <em>bus width</em> pequeño para resolver un <em>bottleneck</em> de lecturas.</p></li>
</ul>
</div>
</section>
<section id="unidades-computacionales">
<h3>Unidades computacionales<a class="headerlink" href="#unidades-computacionales" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Para referencias sobre IPC ver <a class="reference external" href="https://en.wikipedia.org/wiki/Instructions_per_cycle">liga</a> y número de ciclos por segundo ver <a class="reference external" href="https://en.wikipedia.org/wiki/Clock_rate">liga</a>.</p>
</aside>
<p>Sea una CPU o una GPU, las unidades computacionales toman como input un conjunto de bits (que representan números por ejemplo) y producen otro conjunto de bits (por ejemplo la suma de los números). El performance de éstas unidades se mide en <strong>instrucciones por ciclo (IPC)</strong> y en <strong>ciclos por segundo</strong>, nombrado <em>clock rate</em> o <em>clock speed</em>. La IPC puede incrementarse vía la <strong>vectorización</strong> pues piénsese que en una misma carga de datos en el caché se pueden realizar más operaciones que hacen referencia al bloque de datos en cuestión.</p>
<p>Entre los rediseños que se han hecho para las unidades computacionales de un modelo clásico de Von Neumman con el objetivo de resolver los <em>bottlenecks</em>, mejorar la velocidad y el <em>performance</em> se encuentran:</p>
</section>
<section id="multiples-cpu-s-o-cores">
<h3>Múltiples CPU’s o cores<a class="headerlink" href="#multiples-cpu-s-o-cores" title="Permalink to this headline">#</a></h3>
<p>Incrementar el <em>clock speed</em> en una unidad computacional hace más rápido a un programa y también es importante la medida de IPC. La IPC se puede incrementar vía la <strong>vectorización</strong> y es típico en procesadores que soportan las instrucciones llamadas <em><strong>Single Instruction Multiple Data</strong></em> (SIMD). La vectorización consiste en que dados múltiples datos, el procesador puede trabajar sobre ellos en un instante o tiempo (ejecución en <strong>paralelo</strong>):</p>
<img src="https://dl.dropboxusercontent.com/s/mpfk9xmtq9fm7vm/SIMD.png?dl=0" heigth="450" width="450"><div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>El término <em>core</em> hoy en día lo usamos como sinónimo de procesador.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Este tipo de procesadores reemplazaron al modelo de Von Neumann clásico <em><strong>Single Instruction Single Data</strong></em> (SISD):</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/bdx27axhnl3ug5n/SISD.png?dl=0" heigth="300" width="300">
<p>en el que un conjunto de datos se procesaban en un tiempo determinado y no de forma simultánea o en <strong>paralelo</strong>. Así, se transitó de un diseño de hardware secuencial hacia un hardware paralelo.</p>
<ul class="simple">
<li><p>Un ejemplo de procesadores SIMD son los procesadores vectoriales o en arreglo, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Vector_processor">liga</a>.</p></li>
<li><p>En la práctica se ha visto que simplemente añadir más CPU’s o cores al sistema <strong>no siempre</strong> aumenta la velocidad de ejecución en un programa. Existe una ley que explica lo anterior, <strong>la ley de Amdahl</strong>, la cual indica que si un programa está diseñado para ejecutarse en múltiples cores y tiene algunas secciones de su código que pueden sólo ejecutarse en un core, entonces éste será el <em>bottleneck</em> del programa. Por ejemplo, si tuviéramos que realizar una encuesta que tarda <span class="math notranslate nohighlight">\(1\)</span> min a <span class="math notranslate nohighlight">\(100\)</span> personas y tenemos una sola persona, entonces nos tardaríamos <span class="math notranslate nohighlight">\(100\)</span> minutos (proceso secuencial). Si tenemos a <span class="math notranslate nohighlight">\(100\)</span> personas entonces nos tardaríamos <span class="math notranslate nohighlight">\(1\)</span> minuto en completar todas las encuestas (proceso en paralelo). Pero si tenemos más de <span class="math notranslate nohighlight">\(100\)</span> personas, entonces no nos tardaremos menos de <span class="math notranslate nohighlight">\(1\)</span> minuto pues las personas “extras” no podrán participar en realizar la encuesta. En este punto la única forma de reducir el tiempo es reducir el tiempo que le toma a una persona encuestar a otra (esta es la parte secuencial del programa).</p></li>
<li><p>Los sistemas SISD, SIMD y <em><strong>Multiple Instruction Multiple Data</strong></em> (MIMD), presentado a continuación:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/ddze2xuzwn9bh6h/MIMD.png?dl=0" heigth="500" width="500">
<p>son parte de la <a class="reference external" href="https://en.wikipedia.org/wiki/Flynn%27s_taxonomy">taxonomía de Flynn</a> que clasifica a los sistemas dependiendo del <em>stream</em> de datos e instrucciones que puede procesar. Ejemplos de sistemas MIMD son máquinas <em>multicore</em> y clústers de máquinas.</p>
<ul class="simple">
<li><p>En la taxonomía de Flynn hay una división más, la del sistema <em><strong>Simple Program Multiple Data</strong></em> (SPMD) en el que un mismo programa se ejecuta en múltiples datos, éste sistema lo encontramos en la GPU por ejemplo.</p></li>
<li><p>Hoy en día la industria continúa desarrollando y creando procesadores capaces de ejecutar instrucciones basadas en operaciones vectorizadas. Ver por ejemplo <a class="reference external" href="https://en.wikipedia.org/wiki/SSE2">Streaming SIMD Extensions 2: SSE2</a> y <a class="reference external" href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">Advanced Vector Extensions: AVX</a>.</p></li>
<li><p>El incremento en IPC vía la vectorización se enfoca a que las instrucciones tiendan a completar trabajo útil por ciclo pues podría darse la situación en la que se tiene: a <em>high rate of instructions, but a low rate of actual work completed</em>.</p></li>
</ul>
</div>
</section>
<section id="threading-o-hyperthreading">
<span id="threadinghyper"></span><h3><em>Threading</em> o <em>Hyperthreading</em><a class="headerlink" href="#threading-o-hyperthreading" title="Permalink to this headline">#</a></h3>
<p>Otra funcionalidad que se les añadió a los procesadores para incrementar la velocidad de ejecución de un <strong>proceso</strong> y resolver el <em>bottleneck</em> de Von Neumann fue la capacidad de crear hilos, <em><strong>threads</strong></em>, de ejecución en un programa contenidos en un proceso. Esto es nombrado <em>threading</em> o <em>hyperthreading</em> en una CPU o en un <em>core</em>. Básicamente el <em>threading</em> permite la ejecución de más de una instrucción en un mismo <em>core</em> “virtualizando” un procesador adicional (el sistema operativo “cree” que en lugar de haber un <em>core</em> hay dos).</p>
<div class="admonition-definiciones admonition">
<p class="admonition-title">Definiciones</p>
<p>Un proceso es una instancia de un programa que se ejecuta en el procesador y está compuesto por elementos como por ejemplo los bloques de memoria que puede utilizar (los llamados <em>stack</em> y <em>heap</em>) e información de su estado, entre otros.</p>
<p>Un <em>thread</em>, al igual que un proceso, es una instancia de un programa, se ejecuta en el procesador pero está contenido en el proceso del que salió. Al estar contenido en el proceso, comparte elementos de éste, tienen distinto <em>stack</em> de memoria (variables locales creadas en funciones) y en sistemas <em>multicore</em> es posible definir variables que sean accesadas por todos los <em>threads</em> (variables compartidas).</p>
</div>
<p>La creación de threads a partir de un proceso se le nombra <em>fork</em> y su unión al proceso se le nombra <em>join</em>:</p>
<img src="https://dl.dropboxusercontent.com/s/0vnjfdk7fo62m8h/threading.png?dl=0" heigth="400" width="400"><p>Ambas acciones constituyen al <em>threading</em> que realiza un <em>core</em>, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Multithreading_(computer_architecture)">multithreading</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Thread_(computing)">thread</a>.</p>
</section>
<section id="vectorizacion-y-niveles-de-blas">
<h3>Vectorización y niveles de BLAS<a class="headerlink" href="#vectorizacion-y-niveles-de-blas" title="Permalink to this headline">#</a></h3>
<p>En términos simples vectorizar una operación significa realizar la operación de forma independiente al mismo tiempo sobre diferentes pedazos de datos. La vectorización <strong>sólo puede realizarse</strong> si se llena el caché con los datos usables o relevantes para la operación. Para lograr esto el <em>bus</em> moverá pedazos de memoria contiguos lo cual será posible sólo si los datos están almacenados secuencialmente en la memoria. Si se tiene <em>data fragmentation</em> causará <em>memory fragmentation</em> pues se tendrán los datos esparcidos en la memoria. Aún si se llenara la capacidad del <em>bus width</em> si no se tienen los datos usables o relevantes para la operación se tendrán <em>cache misses</em>.</p>
<p>Los múltiples <em>cores</em> junto con la funcionalidad del <em>threading</em> permiten a la CPU o GPU la vectorización. Análogamente la vectorización puede realizarse en un clúster de máquinas con el cómputo distribuido: cada máquina procesa un pedazo de los datos de un arreglo de una o más dimensiones.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>En <em>Python</em> se tiene <em>data fragmentation</em> al usar listas por lo que no se recomienda su uso para realizar operaciones vectoriales o matriciales. Un ejemplo de un paquete que permite realizar operaciones de forma vectorizada es <a class="reference external" href="https://numpy.org/">numpy</a>. Tales operaciones se clasifican de acuerdo a los niveles de BLAS que utilizan.</p>
</aside>
<p>Para lograr la vectorización los paquetes de <em>software</em> utilizan el hecho que el cómputo matricial está construído sobre una jerarquía de operaciones del álgebra lineal:</p>
<ul class="simple">
<li><p>Productos punto involucran operaciones escalares de suma y multiplicación (nivel BLAS 1).</p></li>
<li><p>La multiplicación matriz-vector está hecha de productos punto (nivel BLAS 2).</p></li>
<li><p>La multiplicación matriz-matriz utiliza colecciones de productos matriz-vector (nivel BLAS 3).</p></li>
</ul>
<p>Las operaciones anteriores se describen en el álgebra lineal con la teoría de espacios vectoriales pero también es posible describirlas en una forma algorítmica. Ambas descripciones se complementan una a la otra.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>El acrónimo BLAS es el nombre de la especificación que prescribe el conjunto de rutinas para realizar las operaciones del álgebra lineal. Hay diferentes implementaciones de tal especificación como se verá más adelante. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">Basic Linear Algebra Subprograms</a>.</p>
</div>
</section>
<section id="ejemplo-de-operacion-nivel-blas-1-producto-interno-estandar-o-producto-punto">
<h3>Ejemplo de operación nivel BLAS 1: producto interno estándar o producto punto<a class="headerlink" href="#ejemplo-de-operacion-nivel-blas-1-producto-interno-estandar-o-producto-punto" title="Permalink to this headline">#</a></h3>
<p>Consideramos <span class="math notranslate nohighlight">\(x,y \in \mathbb{R}^n\)</span>. El producto punto entre <span class="math notranslate nohighlight">\(x\)</span> y <span class="math notranslate nohighlight">\(y\)</span> es <span class="math notranslate nohighlight">\(c = x^Ty = \displaystyle \sum_{i=1}^n x_iy_i\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span><span class="o">=</span><span class="mi">0</span>
<span class="n">n</span><span class="o">=</span><span class="mi">5</span>
<span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">n</span>
<span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mf">1.5</span><span class="p">]</span><span class="o">*</span><span class="n">n</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-7.5
</pre></div>
</div>
</div>
</div>
</section>
<section id="implementaciones-de-la-api-standard-de-blas-y-lapack">
<h3>Implementaciones de la API standard de BLAS y LAPACK<a class="headerlink" href="#implementaciones-de-la-api-standard-de-blas-y-lapack" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="http://www.netlib.org/lapack/explore-html/dir_fa94b7b114d387a7a8beb2e3e22bf78d.html">Linear Algebra Package: LAPACK</a> para nombres que se utilizan para operaciones escalares, vectores o matrices y <a class="reference external" href="https://github.com/Reference-LAPACK/lapack">Reference-LAPACK / lapack</a> para el repositorio.</p>
</aside>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Application_programming_interface">Application Programming Interface: API</a> para una explicación de lo que es una API.</p>
</aside>
<p>En <a class="reference external" href="https://wiki.debian.org/DebianScience/LinearAlgebraLibraries">Handle different versions of BLAS and LAPACK</a> se explica que <a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">BLAS: Basic Linear Algebra Subprograms</a> y <a class="reference external" href="http://www.netlib.org/lapack/explore-html/dir_fa94b7b114d387a7a8beb2e3e22bf78d.html">Linear Algebra Package: LAPACK</a> además de ser implementaciones, también son API <em>standard</em> para operaciones básicas del álgebra lineal. Muchas implementaciones de la API existen. Un ejemplo de implementaciones son las incluidas al instalar R o Python. Otras son las que se pueden instalar vía línea de comando:</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="https://packages.debian.org/libblas3">libblas3</a> <a class="reference external" href="https://packages.debian.org/libblas-dev">libblas-dev</a> <a class="reference external" href="https://packages.debian.org/liblapack3">liblapack3</a> <a class="reference external" href="https://packages.debian.org/liblapack-dev">liblapack-dev</a>.</p>
</aside>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo apt-get install -y libblas3 libblas-dev liblapack3 liblapack-dev
</pre></div>
</div>
<p>en un sistema operativo Ubuntu por ejemplo.</p>
<p>Sin embargo existen otras implementaciones de la API que están optimizadas para la arquitectura de nuestras máquinas, por ejemplo:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/xianyi/OpenBLAS">OpenBLAS</a></p></li>
<li><p><a class="reference external" href="http://math-atlas.sourceforge.net">Atlas</a>, <a class="reference external" href="http://math-atlas.sourceforge.net/atlas_install/node8.html">Building a full LAPACK library using ATLAS and netlib’s LAPACK</a>, <a class="reference external" href="http://math-atlas.sourceforge.net/faq.html">ATLAS FAQ</a></p></li>
</ul>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Ver <a class="reference external" href="https://numpy.org/devdocs/user/building.html#prerequisites">Building from source-Prerequisites</a> para información sobre diferentes librerías de álgebra lineal que se pueden utilizar para <em>NumPy</em> al instalarlas en nuestras máquinas.</p>
</div>
</section>
</section>
<section id="que-es-el-perfilamiento-y-por-que-es-necesario">
<h2>¿Qué es el perfilamiento y por qué es necesario?<a class="headerlink" href="#que-es-el-perfilamiento-y-por-que-es-necesario" title="Permalink to this headline">#</a></h2>
<blockquote class="epigraph">
<div><p>Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered</p>
<p class="attribution">—D. Knuth</p>
</div></blockquote>
<blockquote class="epigraph">
<div><p>We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%”. A good programmer … will be wise to look carefully at the critical code; but only after that code has been identified</p>
<p class="attribution">—D. Knuth</p>
</div></blockquote>
<p>El perfilamiento de código nos ayuda a encontrar <em><strong>bottlenecks</strong></em> de nuestro código ya sea en el uso de CPU, RAM, <em>network bandwidth</em> u operaciones hacia el disco de <em>Input</em>/<em>Output</em> (I/O).</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Aún teniendo experiencia en programación identificar algunos <em>bottlenecks</em> en los códigos es difícil…</p>
</aside>
<p>Una mala práctica que es común al iniciar en la programación es intentar optimizar el código (y por optimización piénsese en algún caso, por ejemplo mejorar el tiempo de ejecución de un bloque de código) <strong>a ciegas</strong>, intentando cambiar líneas de código <strong>por intuición y no por evidencias o mediciones</strong>. Esto aunque puede funcionar en algunas ocasiones no conduce la mayoría de las veces a corregir los problemas de los <em>bottlenecks</em> del código (o bien en programas o ¡sistemas enteros!). La optimización guiada por la intuición conduce a un mayor tiempo en el desarrollo para un pequeño incremento en el <em>performance</em>.</p>
<p>Si bien es importante que el código resuelva un problema definido, también es importante perfilarlo. Considérese el caso en el que un código resuelve bien un problema en un día completo, es importante entonces perfilarlo para realizar mediciones (CPU, memoria p.ej.) de los lugares en los que el código gasta la mayor parte de tiempo (en general recursos).</p>
<p>A largo plazo el perfilamiento de código te dará las decisiones más pragmáticas posibles con el menor esfuerzo total.</p>
<p>Al perfilar tu código no olvides lo siguiente:</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><em>Overhead</em> en este caso se refiere a todo lo extra que se añade al perfilar tu código y que no se encuentra en tu código original. Por ejemplo el trabajo extra que realiza tu máquina para analizar tu código (con un paquete por ejemplo) no estaba presente desde un inicio en tu código.</p>
</aside>
<ul class="simple">
<li><p>Medir el tiempo total de tus códigos para decidir si se requiere optimizarlos.</p></li>
<li><p>Perfilar tus códigos para decidir en dónde se iniciará con la optimización. También ayuda definir hipótesis para decidir en qué bloques perfilar primero.</p></li>
<li><p>Escribir <em>tests</em> para asegurarse que se resuelve el problema de forma correcta al igual que antes de perfilarlo y optimizarlo.</p></li>
<li><p>Cualquier recurso medible puede ser perfilado (no sólo el uso de CPU p.ej.).</p></li>
<li><p>Perfilar típicamente añade <em>overhead</em> en la ejecución del código (aumento de tiempo de 10x o 100x es común).</p></li>
</ul>
<p>También considera el tiempo que inviertes para optimizar tu código y si vale la pena la inversión de tiempo que realizas en esto pues hay códigos que casi no son utilizados y otros que sí. No pierdas de vista:</p>
<img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png" heigth="400" width="400"><p>Principalmente porque es tentativo caer en la mala práctica de tratar de remover todos los <em>bottlenecks</em>. Sé una persona práctica, define un tiempo objetivo para tu código y optimiza sólo para llegar a ese objetivo.</p>
<p>Algunas <em><strong>strategies to profile your code successfully</strong></em> extraídas de <a class="reference external" href="https://www.oreilly.com/library/view/high-performance-python/9781492055013/">high performance python</a> para un perfilamiento de código exitoso:</p>
<ul class="simple">
<li><p><em>Disable TurboBoost in the BIOS (a cool CPU may run the same block of code faster than a hot CPU)</em>.</p></li>
<li><p><em>Disable the operating system’s ability to override the SpeedStep (you will find this in your BIOS if you’re allowed to control it)</em>.</p></li>
<li><p><em>Only use mains power (never battery power) &lt;- a laptop on battery power is likely to more agressively control CPU speed than a laptop on mains power</em>.</p></li>
<li><p><em>Disable background tools like backups and Dropbox while running experiments</em>.</p></li>
<li><p><em>Run the experiments many times to obtain a stable measurement</em>.</p></li>
<li><p><em>Possibly drop to run level 1 (Unix) so that no other tasks are running</em>.</p></li>
<li><p><em>Reboot and rerun the experiments to double-confirm the results</em>.</p></li>
</ul>
<p>Otras estrategias las encuentran en <a class="reference external" href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/master/doc/linuxtips.md">Reproducible benchmarking in Linux-based environments</a>.</p>
<section id="unit-testing">
<h3><em>Unit testing</em><a class="headerlink" href="#unit-testing" title="Permalink to this headline">#</a></h3>
<p>Además del perfilamiento del código, el <em>unit testing</em> ayuda a <strong>validar</strong> que cada unidad del <em>software</em> trabaje y se desempeñe como fue diseñada (una unidad puede ser una función, programa, procedimiento, método). El <em>unit testing</em> es importante pues se debe cuidar que el código genere resultados correctos. Puede realizarse independientemente del perfilamiento y si se ha hecho perfilamiento es muy indispensable que se haga un unit testing.</p>
<ul class="simple">
<li><p><em><strong>Unit testing during optimization to maintain correctness:</strong></em> … <em>after spending a day optimizing her code, having disabled unit tests because they were inconvenient, only to discover that her significant speedup result was due to breaking a part of the algorithm she was improving…</em></p></li>
<li><p><em>…If you try to performance test code deep inside a larger project without separating it from the larger project, you are likely to witness side effects that will sidetrack your efforts. It is likely to be harder to unit test a larger project when you’re making fine-grained changes, and this may further hamper your efforts. Side effects could include other threads and processes impacting CPU and memory usage and network and disk activity, which will skew your results.</em></p></li>
</ul>
</section>
</section>
<section id="por-que-compilar-a-codigo-de-maquina">
<h2>¿Por qué compilar a código de máquina?<a class="headerlink" href="#por-que-compilar-a-codigo-de-maquina" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Interpreter_(computing)">liga</a> para revisar lo que es un lenguaje tipo intérprete.</p>
</aside>
<p>De las opciones que tenemos a nuestra disposición para resolver <em>bottlenecks</em> en nuestro programa es hacer que nuestro código haga menos trabajo. Compilando nuestro código a código de máquina para que el código en los lenguajes tipo intérpretes ejecuten menos instrucciones es una opción a seguir.</p>
<section id="por-que-puede-ser-lenta-la-ejecucion-de-un-bloque-de-codigo-en-python-o-en-algun-otro-lenguaje-tipo-interprete">
<h3>¿Por qué puede ser lenta la ejecución de un bloque de código en <em>Python</em> (o en algún otro lenguaje tipo intérprete)?<a class="headerlink" href="#por-que-puede-ser-lenta-la-ejecucion-de-un-bloque-de-codigo-en-python-o-en-algun-otro-lenguaje-tipo-interprete" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><em>Overhead</em> en este caso se refiere a todo lo extra que debe realizar la máquina en un lenguaje intérprete y que no está presente en un lenguaje compilado. Por ejemplo, un objeto tipo <code class="docutils literal notranslate"><span class="pre">int</span></code> en <em>Python</em> tiene asociado un objeto de alto nivel con el que interactuamos. Tal objeto tiene asociados métodos, funciones y atributos por lo que en el código al querer utilizarlos disminuye eficiencia de ejecución pues deben encontrarse, cargarse, verificar tipo de valores, entre otras operaciones.</p>
</aside>
<ul class="simple">
<li><p>Verificación de tipo de valores: si son <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">double</span></code> o <code class="docutils literal notranslate"><span class="pre">string</span></code> u otros.</p></li>
<li><p>Los objetos temporales que se crean por tipo de dato causa <em>overhead</em> .</p></li>
<li><p>Las llamadas a funciones de alto nivel. Por ejemplo las que ayudan a almacenar al objeto en memoria.</p></li>
</ul>
<p>son tres de las fuentes que hacen a un lenguaje tipo intérprete como <em>Python</em> <em>R</em> o <em>Matlab</em> lento. También otras fuentes son:</p>
<ul class="simple">
<li><p>Desde el punto de vista de la memoria de la máquina, el número de referencias a un objeto y las copias entre objetos.</p></li>
<li><p>No es posible vectorizar un cálculo sin el uso de extensiones (por ejemplo paquetes como <code class="docutils literal notranslate"><span class="pre">numpy</span></code>).</p></li>
</ul>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Hay paquetes que permiten la compilación hacia lenguajes más eficientes como <em>Fortran</em> o <em>C</em> (lenguajes que deben realizar compilación), por ejemplo <a class="reference external" href="https://cython.org/">cython</a> o <a class="reference external" href="http://www.rcpp.org/">rcpp</a>.</p></li>
<li><p>Escribir directamente en el lenguaje <em>C</em> en un equipo para un proyecto de desarrollo de <em>software</em> indudablemente cambiará la velocidad de su trabajo si no conocen tal lenguaje. En este caso se recomienda ver ganancias y pérdidas para los tiempos de entrega del proyecto.</p></li>
<li><p>En la práctica si se tiene un <em>bottleneck</em> que no ha podido resolverse con herramientas como el cómputo en paralelo o vectorización, se recomienda utilizar paquetes para compilación hacia lenguajes más eficientes en regiones pequeñas del código y así resolver el <em>bottleneck</em> del programa. En ocasiones también puede ser la opción más viable a seguir si escribir un programa con cómputo en paralelo no es una opción.</p></li>
</ul>
</div>
</section>
</section>
<section id="sobre-los-terminos-concurrencia-paralelo-y-distribuido">
<h2>Sobre los términos concurrencia, paralelo y distribuido<a class="headerlink" href="#sobre-los-terminos-concurrencia-paralelo-y-distribuido" title="Permalink to this headline">#</a></h2>
<p>La distinción entre los términos de paralelo y distribuido es borrosa y en ocasiones es díficil de distinguir.</p>
<section id="paralelo">
<h3>Paralelo<a class="headerlink" href="#paralelo" title="Permalink to this headline">#</a></h3>
<p>El término <strong>paralelo</strong> típicamente se relaciona con programas cuya ejecución involucra <em>cores</em> o nodos que físicamente son cercanos y comparten memoria o están conectados por una red (<em>network</em>) para ejecución de instrucciones en un mismo tiempo o instante.</p>
</section>
<section id="distribuido">
<h3>Distribuido<a class="headerlink" href="#distribuido" title="Permalink to this headline">#</a></h3>
<p>Los programas <strong>distribuidos</strong> son ejecutados por nodos o máquinas separadas a  distancia y una de sus características es que no necesariamente fueron iniciados por un nodo central o <em>scheduler</em> por lo que su ejecución es independiente de los demás nodos. Así como con el término paralelo, existirán instrucciones en los programas que se ejecutarán en un mismo tiempo o instante.</p>
</section>
<section id="concurrencia">
<h3>Concurrencia<a class="headerlink" href="#concurrencia" title="Permalink to this headline">#</a></h3>
<p>El término de <strong>concurrencia</strong> se refiere a que las múltiples tareas que debe realizar un programa pueden estar en progreso en cualquier instante.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_(operating_system)">kernel operating system</a> para definición del kernel de una máquina.</p>
</aside>
<p>Por ejemplo: cada vez que tu código lee un archivo o escribe a un dispositivo (memoria, disco, <em>network</em>), debe pausar su ejecución para contactar al kernel del sistema operativo, solicitar que se ejecute tal operación, y esperar a que se complete, por ejemplo: alojamiento de memoria. Estas operaciones son órdenes de magnitud más lentas que las instrucciones u operaciones ejecutadas en la CPU y el tiempo que el programa espera a que se completen tales operaciones se le nombra <em>I/O wait</em>. La concurrencia nos ayuda a utilizar este tiempo perdido al permitir ejecutar operaciones mientras que una operación I/O se complete.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ejemplos de paquetes de <em>Python</em> para ejecución del código de forma asíncrona son: <a class="reference external" href="https://docs.python.org/3/library/asyncio.html">asyncio</a>, <a class="reference external" href="https://www.tornadoweb.org/en/stable/">tornado</a>. También <em>Dask</em> permite tal tipo de ejecución, ver <a class="reference external" href="https://distributed.dask.org/en/latest/asynchronous.html">dask-asynchronous</a>.</p>
</aside>
<p>Un programa concurrente en lugar de ejecutarse de forma secuencial, esto es, pasar de una línea a otra línea, tiene código escrito para ejecutar distintas líneas conforme sucedan “eventos”. Aquí se involucra una forma de programación llamada <strong>asíncrona</strong>, por ejemplo si una operación tipo I/O es solicitada, el programa ejecuta otras funciones mientras espera que se complete la operación I/O.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Cambiar de función a función en un programa asíncrono también genera costo pues el kernel debe invertir tiempo en hacer todo el <em>set up</em> para ejecutar a la función. La concurrencia funciona bien en programas con alto I/O wait.</p>
</div>
</section>
<section id="por-que-el-computo-en-paralelo">
<h3>¿Por qué el cómputo en paralelo?<a class="headerlink" href="#por-que-el-computo-en-paralelo" title="Permalink to this headline">#</a></h3>
<p>La industria entre los años <span class="math notranslate nohighlight">\(2003-2005\)</span> en lugar de fabricar procesadores monolíticos (clásico <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann_architecture">Von Neumann</a>) que fueran más rápidos y complejos, decidió fabricar múltiples, simples procesadores, <em>cores</em>, en un sólo chip para incrementar el poder de procesamiento, disminuir el Von Neumann <em>bottleneck</em> y aumentar el <em>clock speed</em>.</p>
<p>Esto fue motivado pues desde el año <span class="math notranslate nohighlight">\(2002\)</span> el incremento del <em>performance</em> de los procesadores con un sólo CPU fue de un <span class="math notranslate nohighlight">\(20\%\)</span> por año vs un <span class="math notranslate nohighlight">\(50\%\)</span> por año entre <span class="math notranslate nohighlight">\(1986\)</span> y <span class="math notranslate nohighlight">\(2002\)</span>. Lo anterior se debió a los problemas de la construcción de procesadores monolíticos o de un <em>core</em> relacionados con la disipación del calor por un mayor consumo de energía al hacer más pequeños los transistores.</p>
<p>Hoy en día podemos encontrar en nuestros celulares, laptops, computadoras de escritorio y servidores arquitecturas que cuentan con múltiples <em>cores</em> para procesamiento. Por lo anterior es <strong>indispensable</strong> explotar tal tecnología para tener programas de máquina más eficientes. Muchos de los dispositivos anteriores además tienen un(os) procesador(es) gráficos.</p>
<img src="https://dl.dropboxusercontent.com/s/k11qub01w4nvksi/CPU_multicore.png?dl=0" heigth="500" width="500">
<img src="https://dl.dropboxusercontent.com/s/lw9kia12qhwp95r/GPU.png?dl=0" heigth="500" width="500">
<p>En una buena cantidad de aplicaciones tenemos que implementar algoritmos considerando tal disponibilidad de <em>cores</em> para reducir el tiempo de procesamiento. Esto conduce a reimplementar o en otros casos a repensar al algoritmo en sí.</p>
<p>Y otro aspecto a tomar en cuenta en esta implementación es la transferencia de datos que existe en la jerarquía de memoria de una máquina.</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Los algoritmos que utilizan un sólo <em>core</em> para procesamiento les nombramos <strong>secuenciales</strong>, los que utilizan múltiples <em>cores</em> son <strong>paralelos</strong>.</p>
</div>
</section>
<section id="programas-cuya-ejecucion-es-en-paralelo">
<h3>Programas cuya ejecución es en paralelo<a class="headerlink" href="#programas-cuya-ejecucion-es-en-paralelo" title="Permalink to this headline">#</a></h3>
<p>La decisión de reescribir tu programa secuencial en un programa en paralelo depende mucho de considerar cuatro situaciones:</p>
<ul class="simple">
<li><p>Tener el <em>hardware</em> para ejecución en paralelo del programa.</p></li>
<li><p>Comunicarle al programa que está en un hardware para ejecución en paralelo de instrucciones.</p></li>
<li><p>Tener un método que aproveche el hardware paralelo de forma eficiente.</p></li>
<li><p>Tiempo invertido en la reescritura de un código secuencial a uno en paralelo vs ganancias en tiempo de ejecución.</p></li>
</ul>
<p>Lo primero es fácilmente alcanzable pues hoy en día tenemos celulares con múltiples <em>cores</em> o procesadores. Lo segundo es más dependiente del lenguaje e implementación de éste lenguaje en el que se esté programando. El tercer punto es quizás el más complicado de lograr pues en ocasiones implica repensar el método, disminuir la comunicación lo más posible entre los procesadores, el balanceo de carga o <em><strong>load balancing</strong></em> debe evaluarse y el perfilamiento o el <em>debugging</em> es más difícil en la programación en paralelo que en la forma secuencial. El cuarto punto es esencial para la decisión.</p>
</section>
<section id="cuando-es-recomendable-pensar-en-ejecutar-en-paralelo-tu-programa">
<h3>¿Cuando es recomendable pensar en ejecutar en paralelo tu programa?<a class="headerlink" href="#cuando-es-recomendable-pensar-en-ejecutar-en-paralelo-tu-programa" title="Permalink to this headline">#</a></h3>
<p>Si tus instrucciones a realizar pueden ser divididas en múltiples <em>cores</em> o nodos sin tanto esfuerzo de ingeniería (levantar un clúster de cero es difícil…) o no te lleva mucho tiempo el rediseño de tus métodos para decisiones prácticas (paralelizar el método de despomposición en valores singulares, SVD, es difícil de realizar…) entonces es una opción a considerar. Se recomienda mantener el nivel de paralelización lo más simple posible (aunque no se esté utilizando el 100% de todos tus <em>cores</em>) de modo que el desarrollo de <em>software</em> sea rápido.</p>
</section>
<section id="si-tengo-n-procesadores-espero-un-speedup-de-nx">
<h3>Si tengo n procesadores ¿espero un <em>speedup</em> de <span class="math notranslate nohighlight">\(nx\)</span>?<a class="headerlink" href="#si-tengo-n-procesadores-espero-un-speedup-de-nx" title="Permalink to this headline">#</a></h3>
<p>Normalmente <strong>no</strong> se tiene un mejoramiento en la velocidad de <span class="math notranslate nohighlight">\(n\)</span> veces (<span class="math notranslate nohighlight">\(nx\)</span>) (por ejemplo, si tienes una máquina de <span class="math notranslate nohighlight">\(8\)</span> <em>cores</em> es poco probable que observes un <span class="math notranslate nohighlight">\(8x\)</span> <em>speedup</em>).</p>
<p>Las razones de esto tienen que ver con que al paralelizar instrucciones típicamente se tiene <em>overhead</em> por la comunicación entre los procesos o <em>threads</em> y decrece la memoria RAM disponible que puede ser usada por subprocesos o <em>threads</em>.</p>
<p>También dentro de las razones se encuentran la <a class="reference external" href="https://en.wikipedia.org/wiki/Amdahl%27s_law">ley de Amdahl</a> que nos dice que si sólo una parte del código puede ser paralelizado, no importa cuántos cores tengas, en términos totales el código no se ejecutará más rápido en presencia de secciones secuenciales que dominarán el tiempo de ejecución.</p>
</section>
<section id="a-que-nos-referimos-al-escribir-overhead-en-un-programa-cuya-ejecucion-es-en-paralelo">
<h3>¿A qué nos referimos al escribir <em>overhead</em> en un programa cuya ejecución es en paralelo?<a class="headerlink" href="#a-que-nos-referimos-al-escribir-overhead-en-un-programa-cuya-ejecucion-es-en-paralelo" title="Permalink to this headline">#</a></h3>
<p>A todo lo que implica ejecutar el programa en paralelo que no está presente en la ejecución en una forma secuencial. Por ejemplo, iniciar procesos implica comunicación con el kernel del sistema operativo y por tanto, tiempo.</p>
</section>
<section id="cuales-enfoques-puedo-utilizar-para-escribir-programas-en-paralelo">
<h3>¿Cuáles enfoques puedo utilizar para escribir programas en paralelo?<a class="headerlink" href="#cuales-enfoques-puedo-utilizar-para-escribir-programas-en-paralelo" title="Permalink to this headline">#</a></h3>
<p>Hay <span class="math notranslate nohighlight">\(2\)</span> enfoques muy utilizados para escribir programas en paralelo:</p>
<ul class="simple">
<li><p>Paralelizar las tareas entre los cores. Su característica principal es la ejecución de instrucciones distintas en los cores. Por ejemplo: al llegar la persona invitada a casa, María le ofrecerá de tomar y Luis le abrirá la puerta.</p></li>
<li><p>Paralelización de los datos entre los cores. Su característica principal es la ejecución de mismas instrucciones en datos que fueron divididos por alguna metodología previa. Por ejemplo: tú repartes la mitad del pastel a las mesas 1,2 y 3, y yo la otra mitad a las mesas 4,5 y 6.</p></li>
</ul>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>No son enfoques excluyentes, esto es, podemos encontrar ambos en un mismo programa. La elección de alguno de éstos enfoques depende del problema y del software que será usado para tal enfoque.</p></li>
<li><p>Obsérvese que en el ejemplo de María y Luis necesitan <strong>coordinarse</strong>, <strong>comunicarse</strong> y <strong>sincronizarse</strong> para tener éxito en recibir a la invitada.</p></li>
<li><p>Obsérvese que en el ejemplo de repartir el pastel se requiere un buen <em><strong>load balancing</strong></em> pues no queremos que yo le reparta a <span class="math notranslate nohighlight">\(5\)</span> mesas y tú le repartas a ¡sólo una!.</p></li>
</ul>
</div>
</section>
<section id="a-que-nos-referimos-con-el-termino-embarrassingly-parallel-problem">
<h3>¿A qué nos referimos con el término <em>embarrassingly parallel problem</em>?<a class="headerlink" href="#a-que-nos-referimos-con-el-termino-embarrassingly-parallel-problem" title="Permalink to this headline">#</a></h3>
<p>A los problemas en los que la comunicación entre procesos o threads es cero. Por ejemplo sumar un array <code class="docutils literal notranslate"><span class="pre">a</span></code> con un array <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p>Y en general si evitamos compartir el estado (pensando a la palabra “estado” como un término más general que sólo comunicación) en un sistema paralelo nos hará la vida más fácil (el <em>speedup</em> será bueno, el <em>debugging</em> será sencillo, el perfilamiento será más fácil de realizar…).</p>
</section>
<section id="como-inicio-en-la-programacion-en-paralelo-de-mi-codigo">
<h3>¿Cómo inicio en la programación en paralelo de mi código?<a class="headerlink" href="#como-inicio-en-la-programacion-en-paralelo-de-mi-codigo" title="Permalink to this headline">#</a></h3>
<p>Ian Foster en su libro <em>Designing and Building Parallel Programs</em> da una serie de pasos que ayudan a la programación en paralelo:</p>
<ul class="simple">
<li><p><em>Partitioning. Divide the computation to be performed and the data operated on by the computation into small tasks. The focus here should be on identifying tasks that can be executed in parallel.</em></p></li>
<li><p><em>Communication. Determine what communication needs to be carried out among the tasks identified in the previous step.</em></p></li>
<li><p><em>Agglomeration or aggregation. Combine tasks and communications identified in the first step into larger tasks. For example, if task A must be executed before task B can be executed, it may make sense to aggregate them into a single composite task.</em></p></li>
<li><p><em>Mapping. Assign the composite tasks identified in the previous step to processes/threads. This should be done so that communication is minimized, and each process/thread gets roughly the same amount of work.</em></p></li>
</ul>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>En ocasiones es mejor dejar las tareas simples y redundantes que complicarlas y no redundantes. Por ejemplo, si en el programa en paralelo varios procesadores o <em>threads</em> hacen tarea redundante pero me evitan la comunicación, prefiero este programa a uno en el que haga  trabajo no redundate y muy específico a cada procesador o <em>thread</em> pero que la comunicación a realizar sea muy complicada o compleja.</p>
</div>
</section>
<section id="ejemplo-en-la-regla-del-rectangulo-compuesta-en-una-maquina-multicore">
<h3>Ejemplo en la regla del rectángulo compuesta en una máquina <em>multicore</em><a class="headerlink" href="#ejemplo-en-la-regla-del-rectangulo-compuesta-en-una-maquina-multicore" title="Permalink to this headline">#</a></h3>
<p>1.<em>Partitioning</em>: la tarea a realizar es el cálculo de un área de un rectángulo para un subintervalo.</p>
<img src="https://dl.dropboxusercontent.com/s/5nqciu6ca5xzdh9/parallel_processing_Rcf_1.png?dl=0" heigth="300" width="400"><p>2.<em>Communication</em> y <em>mapping</em>: los subintervalos deben repartirse entre los <em>cores</em> y se debe comunicar esta repartición por algún medio (por ejemplo con variables en memoria).</p>
<p>3.<em>Aggregation</em>: un <em>core</em> puede calcular más de un área de un rectángulo si recibe más de un subintervalo.</p>
<img src="https://dl.dropboxusercontent.com/s/lpcwd9mejb90rq3/parallel_processing_Rcf_2.png?dl=0" heigth="200" width="300">
<p>4.<em>Communication</em> y <em>mapping</em>: el área de los rectángulos calculados por cada procesador deben sumarse para calcular la aproximación a la integral.</p>
<img src="https://dl.dropboxusercontent.com/s/mfo5rfzjnonn8lq/parallel_processing_Rcf_3.png?dl=0" heigth="400" width="500">
</section>
<section id="software">
<h3>¿<em>Software</em>?<a class="headerlink" href="#software" title="Permalink to this headline">#</a></h3>
<p><strong>Nota: las listas de herramientas de <em>software</em> que se presentan son no exhaustivas</strong>.</p>
<p>Depende del procesador y arquitectura a utilizar. Si lo que deseamos usar son <em>cores</em> de una CPU en una máquina tenemos:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.dask.org/en/latest/">Dask</a></p></li>
<li><p><a class="reference external" href="https://docs.python.org/3.1/library/multiprocessing.html">multiprocessing</a></p></li>
<li><p><a class="reference external" href="https://github.com/cython/cython/">Cython</a> (que además provee compilación a <em>C</em>)</p></li>
<li><p><a class="reference external" href="https://github.com/numba/numba">Numba</a> (que además provee compilación a <em>C</em>)</p></li>
<li><p><a class="reference external" href="https://joblib.readthedocs.io/en/latest/">joblib</a></p></li>
<li><p><a class="reference external" href="https://www.rdocumentation.org/packages/parallel/versions/3.6.2">parallel</a></p></li>
<li><p><a class="reference external" href="https://www.rdocumentation.org/packages/foreach/versions/1.4.7/topics/foreach">foreach</a></p></li>
<li><p><a class="reference external" href="https://github.com/RcppCore/RcppParallel">RcppParallel</a> (que además provee compilación a <em>C++</em>)</p></li>
<li><p><a class="reference external" href="http://www.openmp.org/">openMP</a></p></li>
<li><p><a class="reference external" href="https://computing.llnl.gov/tutorials/pthreads/">Pthreads</a></p></li>
<li><p><a class="reference external" href="https://thrust.github.io/">Thrust</a></p></li>
<li><p><a class="reference external" href="https://www.lrz.de/services/software/mathematik/plasma/">PLASMA</a></p></li>
<li><p><a class="reference external" href="https://github.com/oneapi-src/oneTBB">oneTBB</a></p></li>
</ul>
<p>Si deseamos usar <em>cores</em> en una GPU y cómputo multi-GPU tenemos:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">CUDA C</a>, <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html">CUBLAS</a>, <a class="reference external" href="https://icl.cs.utk.edu/magma/">MAGMA</a>, <a class="reference external" href="http://www.culatools.com/cula_dense_programmers_guide/">CULA</a>, <a class="reference external" href="https://docs.nvidia.com/cuda/cusolver/index.html">CUSOLVER</a>, <a class="reference external" href="https://docs.nvidia.com/cuda/nvblas/">NVBLAS</a></p></li>
<li><p><a class="reference external" href="https://docs.cupy.dev/en/stable/">CuPy</a></p></li>
<li><p><a class="reference external" href="https://documen.tician.de/pycuda/">PyCUDA</a></p></li>
<li><p><a class="reference external" href="https://github.com/rapidsai/dask-cuda">dask-cuda</a>, <a class="reference external" href="https://rapids.ai/">Rapids</a></p></li>
<li><p><a class="reference external" href="https://github.com/numba/numba">Numba</a> (que además provee compilación a <em>C</em>)</p></li>
<li><p><a class="reference external" href="https://www.rdocumentation.org/packages/gputools/versions/1.1">gputools</a></p></li>
<li><p><a class="reference external" href="https://github.com/cdeterman/gpuR">gpuR</a></p></li>
<li><p><a class="reference external" href="https://github.com/Rth-org/Rth">Rth-org/Rth</a> y más reciente <a class="reference external" href="https://github.com/matloff/Rth">matloff/Rth</a>. Ver también <a class="reference external" href="https://rdrr.io/github/matloff/Rth/f/README.md">rdrr.io matloff/Rth</a>.</p></li>
<li><p><a class="reference external" href="https://thrust.github.io/">Thrust</a></p></li>
</ul>
<p>Para cómputo distribuido se encuentran:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.open-mpi.org/">OpenMPI</a></p></li>
<li><p><a class="reference external" href="https://www.schedmd.com/">Slurm</a>, <a class="reference external" href="https://github.com/SchedMD/slurm">Slurm github</a></p></li>
<li><p><a class="reference external" href="http://www.netlib.org/scalapack/">ScaLAPACK</a></p></li>
</ul>
<p>Para áreas como <em>deep learning</em> en el uso de la GPU y que también permiten cómputo distribuido y multigpu se tienen:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/tensorflow/tensorflow">tensorflow</a>, <a class="reference external" href="https://github.com/keras-team/keras">keras</a></p></li>
<li><p><a class="reference external" href="https://github.com/BVLC/caffe">caffe</a></p></li>
<li><p><a class="reference external" href="https://github.com/apache/incubator-mxnet">mxnet</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/pytorch">pytorch</a></p></li>
<li><p><a class="reference external" href="https://github.com/Theano/Theano">Theano</a>, <a class="reference external" href="https://github.com/pymc-devs/aesara">pymc-devs/aesara</a></p></li>
</ul>
<p>Varios de los paquetes anteriores están habilitadas con <a class="reference external" href="https://github.com/oneapi-src/oneDNN">oneDNN</a> para un buen <em>performance</em> en el uso de la CPU/GPU.</p>
<p>Y un estándar para cómputo en sistemas heterogéneos: <a class="reference external" href="https://www.khronos.org/opencl/">OpenCL</a>, <a class="reference external" href="https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_C.html#the-opencl-c-programming-language">OpenCL-c-programming-language</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/OpenCL">OpenCL-Wikipedia</a></p>
</section>
</section>
<section id="referencias-de-interes">
<h2>Referencias de interés<a class="headerlink" href="#referencias-de-interes" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf">MAGMA by example</a></p></li>
<li><p><a class="reference external" href="https://www.icl.utk.edu/files/publications/2009/icl-utk-388-2009.pdf">Numerical Linear Algebra on Emerging Architectures: the PLASMA and MAGMA Projects</a></p></li>
<li><p><a class="reference external" href="https://github.com/pymc-devs/pymc3">pymc3</a></p></li>
<li><p>Para monitoreo de número de instrucciones por ciclo, número de ciclos por segundo, <em>branch misses, cache references</em> (o <em>hits</em>) y <em>misses</em> se recomiendan las herramientas de <a class="reference external" href="https://en.wikipedia.org/wiki/Perf">perf</a>, <a class="reference external" href="https://valgrind.org/">valgrind</a>, ver también: <a class="reference external" href="https://en.wikipedia.org/wiki/Valgrind">Valgrind</a>.</p></li>
<li><p>Algunas ligas que explican lo que es el <em>garbage collector</em> en <em>Python</em> son: <a class="reference external" href="https://rushter.com/blog/python-garbage-collector/">python-garbage-collector</a>, <a class="reference external" href="https://stackabuse.com/basics-of-memory-management-in-python/">Basics of Memory Management in Python</a>, <a class="reference external" href="https://stackify.com/python-garbage-collection/">python-garbage-collection</a> y <a class="reference external" href="https://stackoverflow.com/questions/4484167/python-garbage-collector-documentation">python-garbage-collector-documentation</a>.</p></li>
<li><p>Ver <a class="reference external" href="https://stackoverflow.com/questions/17130975/python-vs-cpython">python-vs-cpython</a> para una breve explicación de implementaciones de <em>Python</em>.</p></li>
</ul>
<p><strong>Preguntas de comprehensión:</strong></p>
<p>1)¿Qué beneficios se pueden obtener al utilizar operaciones vectorizadas, en qué situaciones podríamos usarlas y cómo se relaciona con la especificación BLAS?</p>
<p>2)¿Qué factores han influido en que desde el 2002-2003 a la fecha, el <em>performance</em> de los procesadores se esté incrementando en un 20% por año vs el 50% de incremento por año que se tenía entre 1986 y 2002?</p>
<p>3)Menciona los componentes y realiza un esquema de una arquitectura von Neumann y descríbelas.</p>
<p>4)Menciona la ley de Amdahl.</p>
<p>5)¿Qué es un proceso y de qué consta?</p>
<p>6)¿Qué es un <em>thread</em>?</p>
<p>7)¿Qué es el <em>threading</em>? ¿qué ventajas nos da para la programación en un sistema de memoria compartida?</p>
<p>8)¿Qué es el caché?</p>
<p>9)Nosotros como programadores o programadoras, ¿cómo podemos obtener ventajas del caché?</p>
<p>10)¿Qué es un <em>cache hit</em>? ¿un <em>cache miss</em>?</p>
<p>11)De acuerdo a la taxonomía de Flynn, ¿qué tipos de arquitecturas existen? Menciona sus características, ventajas /desventajas y ejemplos.</p>
<p>12)Menciona algunos ejemplos de:</p>
<p>a.Sistemas de memoria distribuida.</p>
<p>b.Sistemas de memoria compartida.</p>
<p>13)¿Qué es el <em>pipelining</em> y el <em>branch prediction</em>?</p>
<p>14)Menciona los distintos <em>bus</em> o interconexiones en un sistema de computadora y su propiedad principal o lo que nos interesa medir en un <em>bus</em>.</p>
<p>15)¿Qué significan los términos concurrencia, paralelo, distribuido?</p>
<p>16)¿Cuáles son los enfoques que se utilizan para escribir programas en paralelo?</p>
<p>17)Define a cuál enfoque corresponde (de acuerdo a la pregunta anterior) cada uno de los siguientes incisos:</p>
<p>a)Supón que tienes 2 cores y un arreglo de tamaño 100</p>
<p>if(rango_core módulo 2 == 0 )
operar en los elementos 50 a 99
else
operar en los elementos 0 a 49</p>
<p>donde módulo es una operación que nos devuelve el residuo al dividir un número entre otro.</p>
<p>b)Tenemos tres trabajadores: Aurora, Pedro, Daniel</p>
<p>if(mi_nombre es Pedro)
lavo el baño
else
voy de compras</p>
<p>18)En el cómputo en paralelo debemos realizar coordinación entre procesos o <em>threads</em> y considerar el <em>load balancing</em>. Menciona tipos de coordinación que existen y ¿a qué se refiere el <em>load balancing</em>?</p>
<p>19)¿Cuáles son los pasos a seguir, que de acuerdo a Ian Foster, se puede seguir para el diseño de programas en paralelo?</p>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>M. Gorelick, I. Ozsvald, High Performance Python, O’Reilly Media, 2014.</p></li>
<li><p>E. Anderson, Z. Bai, C. Bischof, L. S. Blackford, J. Demmel, J. Dongarra, J. Du Croz,
A. Greenbaum, S. Hammarling, A. Mckenney and D. Sorensen, LAPACK Users Guide, Society for Industrial and Applied Mathematics, Philadelphia, PA, third ed., 1999.</p></li>
<li><p>P. Pacheco, An Introduction to Parallel Programming, Morgan Kaufmann, 2011.</p></li>
<li><p><a class="reference external" href="https://xkcd.com/">https://xkcd.com/</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion_2",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./5.optimizacion_de_codigo/5.1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../4.optimizacion_en_redes_y_prog_lineal/4.5/Metodo_primal_dual_de_BL.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">4.5 Método primal-dual de barrera logarítmica (BL)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">5.2 Herramientas de lenguajes de programación y del sistema operativo para perfilamiento e implementaciones de BLAS</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Erick Palacios Moreno<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>