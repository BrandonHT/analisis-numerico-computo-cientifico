
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6.1 Método de descenso más pronunciado para Unconstrained Convex Optimization (UCO)" href="../../6.algoritmos_optimizacion_convexa/6.1/Metodo_de_descenso_mas_pronunciado_para_UCO.html" />
    <link rel="prev" title="5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)" href="../5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Optimización
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  1. Cómputo científico
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  2. Cómputo matricial
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  3. Optimización convexa y ecuaciones no lineales
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html">
   3.2 Algoritmos de descenso y búsqueda de línea en
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI.html">
   3.3 Ejemplos de problemas UCO, introducción a
   <em>
    Constrained Inequality and Equality Optimization
   </em>
   (CIEO) y puntos interiores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3.optimizacion_convexa/3.4/Ecuaciones_no_lineales.html">
   3.4 Ecuaciones no lineales
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  4. Optimización en redes y programación lineal
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.1/Programacion_lineal_y_metodo_simplex.html">
   4.1 Programación lineal (PL) y método símplex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.2/Definiciones_generales_de_flujo_en_redes.html">
   4.2 Definiciones generales de flujo en redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.3/Ejemplo_metodo_simplex_de_redes.html">
   4.3 Ejemplo del método símplex de redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.4/Dualidad_lema_de_Farkas_condiciones_KKT_de_optimalidad.html">
   4.4 Dualidad, lema de Farkas y condiciones de Karush-Kuhn-Tucker (KKT) de optimalidad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.5/Metodo_primal_dual_de_BL.html">
   4.5 Método primal-dual de barrera logarítmica (BL)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  5. Optimización de código
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../5.1/introduccion_optimizacion_de_codigo.html">
   5.1 Introducción a optimización de código
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html">
   5.2 Herramientas de lenguajes de programación y del sistema operativo para perfilamiento e implementaciones de BLAS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.3/Compilacion_a_C.html">
   5.3 Compilación a C
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html">
   5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  6. Algoritmos de optimización convexa
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.1/Metodo_de_descenso_mas_pronunciado_para_UCO.html">
   6.1 Método de descenso más pronunciado para
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.2/Problemas_CECO.html">
   6.2 Problemas tipo
   <em>
    Constrained Equality Convex Optimization
   </em>
   (CECO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.3/Problemas_CIECO.html">
   6.3 Problemas tipo
   <em>
    Constrained Equality and Inequality Convex Optimization
   </em>
   (CIECO)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  7. Temas selectos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../7.temas_selectos/7.1/Optimizacion_estocastica.html">
   7.1 Optimización estocástica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../7.temas_selectos/7.2/Metodos_cuasi_Newton.html">
   7.2 Métodos cuasi Newton
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion_2?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/5.optimizacion_de_codigo/5.5/Computo_en_paralelo_usando_GPUS_en_SMC.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/5.optimizacion_de_codigo/5.5/Computo_en_paralelo_usando_GPUS_en_SMC.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compute-unified-device-architecture-cuda">
   <em>
    Compute Unified Device Architecture
   </em>
   (CUDA)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-poco-de-historia">
     Un poco de historia…
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#diferencia-con-la-cpu-multicore">
     ¿Diferencia con la CPU multicore?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otras-companias-producen-tarjetas-graficas">
     ¿Otras compañías producen tarjetas gráficas?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#si-tengo-una-tarjeta-grafica-de-amd-puedo-correr-un-programa-de-cuda">
     ¿Si tengo una tarjeta gráfica de AMD puedo correr un programa de CUDA?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#si-tengo-una-tarjeta-grafica-de-nvidia-un-poco-antigua-puedo-correr-un-programa-de-cuda">
     ¿Si tengo una tarjeta gráfica de NVIDIA un poco antigua puedo correr un programa de CUDA?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#que-es-cuda-c">
     ¿Qué es
     <em>
      CUDA C
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-que-se-refiere-la-terminologia-de-host-y-device">
     ¿A qué se refiere la terminología de
     <em>
      host
     </em>
     y
     <em>
      device
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tengo-una-tarjeta-nvidia-cuda-capable-que-debo-realizar-primero">
     Tengo una tarjeta NVIDIA CUDA
     <em>
      capable
     </em>
     ¿qué debo realizar primero?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instale-lo-necesario-y-al-ejecutar-en-la-terminal-nvcc-v-obtengo-la-version-como-puedo-probar-mi-instalacion">
     Instalé lo necesario y al ejecutar en la terminal
     <code class="docutils literal notranslate">
      <span class="pre">
       nvcc
      </span>
      <span class="pre">
       -V
      </span>
     </code>
     obtengo la versión… ¿cómo puedo probar mi instalación?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#por-que-usar-cuda-y-cuda-c-o-mas-general-computo-en-la-gpu">
     ¿Por qué usar CUDA y
     <em>
      CUDA-C
     </em>
     o más general cómputo en la GPU?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cuda-c">
   CUDA-C
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel">
     <em>
      Kernel
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bloques-de-threads">
     ¿Bloques de threads?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-s-y-bloques-3-dimensionales">
     ¿Grid’s y bloques 3-dimensionales?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alojamiento-de-memoria-en-el-device">
     Alojamiento de memoria en el
     <em>
      device
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perfilamiento-en-cuda">
     ¿Perfilamiento en CUDA?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tenemos-que-inicializar-los-datos-en-la-cpu-y-copiarlos-hacia-la-gpu">
     ¿Tenemos que inicializar los datos en la CPU y copiarlos hacia la GPU?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arquitectura-de-una-gpu-y-limites-en-numero-de-threads-y-bloques-que-podemos-lanzar-en-el-kernel">
   Arquitectura de una GPU y límites en número de
   <em>
    threads
   </em>
   y bloques que podemos lanzar en el
   <em>
    kernel
   </em>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#que-otros-limites-puedo-encontrar-en-mi-s-device-s-de-mi-sistema">
     ¿Qué otros límites puedo encontrar en mi(s) device(s) de mi sistema?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-configuration-choices">
     <em>
      Grid Configuration Choices
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-regla-compuesta-del-rectangulo">
     Ejemplo regla compuesta del rectángulo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cupy">
   CuPy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arrays">
     <em>
      Arrays
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#operaciones-en-el-algebra-lineal-con-cupy">
     Operaciones en el álgebra lineal con CuPy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-escalar-vector-suma-y-punto-entre-vectores">
     Producto escalar-vector, suma y punto entre vectores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-matriz-vector-point-wise">
     Producto matriz vector
     <em>
      point-wise
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-matriz-vector">
     Producto matriz-vector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#suma-y-producto-matriz-matriz-pointwise">
     Suma y producto matriz-matriz pointwise
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-matriz-matriz">
     Producto matriz-matriz
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunas-operaciones-basicas-del-algebra-lineal">
     Algunas operaciones básicas del álgebra lineal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#norma-de-vectores">
     Norma de vectores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#norma-de-matrices">
     Norma de matrices
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resolver-sistema-de-ecuaciones-lineales">
     Resolver sistema de ecuaciones lineales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transferencia-de-datos-del-host-al-device-o-viceversa">
     Transferencia de datos del
     <em>
      host
     </em>
     al
     <em>
      device
     </em>
     o viceversa
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#funcion-ejecutada-dependiendo-de-que-sean-array-s-de-numpy-o-cupy">
     Función ejecutada dependiendo de que sean
     <em>
      array
     </em>
     ’s de
     <em>
      NumPy
     </em>
     o
     <em>
      CuPy
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     Ejemplo regla compuesta del rectángulo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias-de-interes">
   Referencias de interés
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compute-unified-device-architecture-cuda">
   <em>
    Compute Unified Device Architecture
   </em>
   (CUDA)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-poco-de-historia">
     Un poco de historia…
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#diferencia-con-la-cpu-multicore">
     ¿Diferencia con la CPU multicore?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otras-companias-producen-tarjetas-graficas">
     ¿Otras compañías producen tarjetas gráficas?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#si-tengo-una-tarjeta-grafica-de-amd-puedo-correr-un-programa-de-cuda">
     ¿Si tengo una tarjeta gráfica de AMD puedo correr un programa de CUDA?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#si-tengo-una-tarjeta-grafica-de-nvidia-un-poco-antigua-puedo-correr-un-programa-de-cuda">
     ¿Si tengo una tarjeta gráfica de NVIDIA un poco antigua puedo correr un programa de CUDA?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#que-es-cuda-c">
     ¿Qué es
     <em>
      CUDA C
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-que-se-refiere-la-terminologia-de-host-y-device">
     ¿A qué se refiere la terminología de
     <em>
      host
     </em>
     y
     <em>
      device
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tengo-una-tarjeta-nvidia-cuda-capable-que-debo-realizar-primero">
     Tengo una tarjeta NVIDIA CUDA
     <em>
      capable
     </em>
     ¿qué debo realizar primero?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instale-lo-necesario-y-al-ejecutar-en-la-terminal-nvcc-v-obtengo-la-version-como-puedo-probar-mi-instalacion">
     Instalé lo necesario y al ejecutar en la terminal
     <code class="docutils literal notranslate">
      <span class="pre">
       nvcc
      </span>
      <span class="pre">
       -V
      </span>
     </code>
     obtengo la versión… ¿cómo puedo probar mi instalación?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#por-que-usar-cuda-y-cuda-c-o-mas-general-computo-en-la-gpu">
     ¿Por qué usar CUDA y
     <em>
      CUDA-C
     </em>
     o más general cómputo en la GPU?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cuda-c">
   CUDA-C
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel">
     <em>
      Kernel
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bloques-de-threads">
     ¿Bloques de threads?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-s-y-bloques-3-dimensionales">
     ¿Grid’s y bloques 3-dimensionales?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alojamiento-de-memoria-en-el-device">
     Alojamiento de memoria en el
     <em>
      device
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perfilamiento-en-cuda">
     ¿Perfilamiento en CUDA?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tenemos-que-inicializar-los-datos-en-la-cpu-y-copiarlos-hacia-la-gpu">
     ¿Tenemos que inicializar los datos en la CPU y copiarlos hacia la GPU?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arquitectura-de-una-gpu-y-limites-en-numero-de-threads-y-bloques-que-podemos-lanzar-en-el-kernel">
   Arquitectura de una GPU y límites en número de
   <em>
    threads
   </em>
   y bloques que podemos lanzar en el
   <em>
    kernel
   </em>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#que-otros-limites-puedo-encontrar-en-mi-s-device-s-de-mi-sistema">
     ¿Qué otros límites puedo encontrar en mi(s) device(s) de mi sistema?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-configuration-choices">
     <em>
      Grid Configuration Choices
     </em>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-regla-compuesta-del-rectangulo">
     Ejemplo regla compuesta del rectángulo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cupy">
   CuPy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arrays">
     <em>
      Arrays
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#operaciones-en-el-algebra-lineal-con-cupy">
     Operaciones en el álgebra lineal con CuPy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-escalar-vector-suma-y-punto-entre-vectores">
     Producto escalar-vector, suma y punto entre vectores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-matriz-vector-point-wise">
     Producto matriz vector
     <em>
      point-wise
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-matriz-vector">
     Producto matriz-vector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#suma-y-producto-matriz-matriz-pointwise">
     Suma y producto matriz-matriz pointwise
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producto-matriz-matriz">
     Producto matriz-matriz
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunas-operaciones-basicas-del-algebra-lineal">
     Algunas operaciones básicas del álgebra lineal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#norma-de-vectores">
     Norma de vectores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#norma-de-matrices">
     Norma de matrices
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resolver-sistema-de-ecuaciones-lineales">
     Resolver sistema de ecuaciones lineales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transferencia-de-datos-del-host-al-device-o-viceversa">
     Transferencia de datos del
     <em>
      host
     </em>
     al
     <em>
      device
     </em>
     o viceversa
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#funcion-ejecutada-dependiendo-de-que-sean-array-s-de-numpy-o-cupy">
     Función ejecutada dependiendo de que sean
     <em>
      array
     </em>
     ’s de
     <em>
      NumPy
     </em>
     o
     <em>
      CuPy
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     Ejemplo regla compuesta del rectángulo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias-de-interes">
   Referencias de interés
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="computo-en-paralelo-usando-gpus-en-un-sistema-de-memoria-compartida-smc">
<span id="compparalelogpussmc"></span><h1>5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)<a class="headerlink" href="#computo-en-paralelo-usando-gpus-en-un-sistema-de-memoria-compartida-smc" title="Permalink to this headline">#</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker y <code class="docutils literal notranslate"><span class="pre">&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code> por la versión más actualizada que se presenta en la documentación.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion_2</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion_2:&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion_2</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion_2:&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion_2">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de <a class="reference external" href="https://www.dropbox.com/s/yjijtfuky3s5dfz/2.5.Compute_Unified_Device_Architecture.pdf?dl=0">liga</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota la comunidad lectora:</p>
<ul class="simple">
<li><p>Aprenderá un poco de historia y arquitectura de la GPU.</p></li>
<li><p>Se familiarizará con la sintaxis de <em>CUDA-C</em> para cómputo en la GPU con ejemplos sencillos y los relacionará con el modelo de programación CUDA.</p></li>
<li><p>Utilizará el paquete <em>CuPy</em> de <em>Python</em> para cómputo en la GPU.</p></li>
</ul>
</div>
<p>Se presentan códigos y sus ejecuciones en una máquina <code class="docutils literal notranslate"><span class="pre">p2.xlarge</span></code> con una AMI <code class="docutils literal notranslate"><span class="pre">ubuntu</span> <span class="pre">20.04</span> <span class="pre">-</span> <span class="pre">ami-042e8287309f5df03</span></code> de la nube de <a class="reference external" href="https://aws.amazon.com/">AWS</a>. Se utilizó en la sección de <code class="docutils literal notranslate"><span class="pre">User</span> <span class="pre">data</span></code> el <a class="reference external" href="https://github.com/palmoreck/scripts_for_useful_tools_installations/blob/main/AWS/ubuntu_20.04/optimizacion_2/script_cuda_and_tools.sh">script_cuda_and_tools.sh</a></p>
<p>La máquina <code class="docutils literal notranslate"><span class="pre">p2.xlarge</span></code> tiene las siguientes características:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
lscpu
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   46 bits physical, 48 bits virtual
CPU(s):                          4
On-line CPU(s) list:             0-3
Thread(s) per core:              2
Core(s) per socket:              2
Socket(s):                       1
NUMA node(s):                    1
Vendor ID:                       GenuineIntel
CPU family:                      6
Model:                           79
Model name:                      Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:                        1
CPU MHz:                         2701.377
CPU max MHz:                     3000.0000
CPU min MHz:                     1200.0000
BogoMIPS:                        4600.15
Hypervisor vendor:               Xen
Virtualization type:             full
L1d cache:                       64 KiB
L1i cache:                       64 KiB
L2 cache:                        512 KiB
L3 cache:                        45 MiB
NUMA node0 CPU(s):               0-3
Vulnerability Itlb multihit:     KVM: Vulnerable
Vulnerability L1tf:              Mitigation; PTE Inversion
Vulnerability Mds:               Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
Vulnerability Meltdown:          Mitigation; PTI
Vulnerability Spec store bypass: Vulnerable
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full generic retpoline, STIBP disabled, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
sudo lshw -C memory
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  *-firmware
       description: BIOS
       vendor: Xen
       physical id: 0
       version: 4.2.amazon
       date: 08/24/2006
       size: 96KiB
       capabilities: pci edd
  *-memory
       description: System Memory
       physical id: 1000
       size: 61GiB
       capabilities: ecc
       configuration: errordetection=multi-bit-ecc
     *-bank:0
          description: DIMM RAM
          physical id: 0
          slot: DIMM 0
          size: 16GiB
          width: 64 bits
     *-bank:1
          description: DIMM RAM
          physical id: 1
          slot: DIMM 1
          size: 16GiB
          width: 64 bits
     *-bank:2
          description: DIMM RAM
          physical id: 2
          slot: DIMM 2
          size: 16GiB
          width: 64 bits
     *-bank:3
          description: DIMM RAM
          physical id: 3
          slot: DIMM 3
          size: 13GiB
          width: 64 bits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
#execute next line to have in the book output of cell
sudo lshw -C display
</pre></div>
</div>
</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="o">*-</span><span class="n">display</span><span class="p">:</span><span class="mi">0</span> <span class="n">UNCLAIMED</span>
       <span class="n">description</span><span class="p">:</span> <span class="n">VGA</span> <span class="n">compatible</span> <span class="n">controller</span>
       <span class="n">product</span><span class="p">:</span> <span class="n">GD</span> <span class="mi">5446</span>
       <span class="n">vendor</span><span class="p">:</span> <span class="n">Cirrus</span> <span class="n">Logic</span>
       <span class="n">physical</span> <span class="nb">id</span><span class="p">:</span> <span class="mi">2</span>
       <span class="n">bus</span> <span class="n">info</span><span class="p">:</span> <span class="n">pci</span><span class="o">@</span><span class="mi">0000</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mf">02.0</span>
       <span class="n">version</span><span class="p">:</span> <span class="mi">00</span>
       <span class="n">width</span><span class="p">:</span> <span class="mi">32</span> <span class="n">bits</span>
       <span class="n">clock</span><span class="p">:</span> <span class="mi">33</span><span class="n">MHz</span>
       <span class="n">capabilities</span><span class="p">:</span> <span class="n">vga_controller</span>
       <span class="n">configuration</span><span class="p">:</span> <span class="n">latency</span><span class="o">=</span><span class="mi">0</span>
       <span class="n">resources</span><span class="p">:</span> <span class="n">memory</span><span class="p">:</span><span class="mi">80000000</span><span class="o">-</span><span class="mi">81</span><span class="n">ffffff</span> <span class="n">memory</span><span class="p">:</span><span class="mi">86004000</span><span class="o">-</span><span class="mi">86004</span><span class="n">fff</span> <span class="n">memory</span><span class="p">:</span><span class="n">c0000</span><span class="o">-</span><span class="n">dffff</span>
  <span class="o">*-</span><span class="n">display</span><span class="p">:</span><span class="mi">1</span> <span class="n">UNCLAIMED</span>
       <span class="n">description</span><span class="p">:</span> <span class="mi">3</span><span class="n">D</span> <span class="n">controller</span>
       <span class="n">product</span><span class="p">:</span> <span class="n">GK210GL</span> <span class="p">[</span><span class="n">Tesla</span> <span class="n">K80</span><span class="p">]</span>
       <span class="n">vendor</span><span class="p">:</span> <span class="n">NVIDIA</span> <span class="n">Corporation</span>
       <span class="n">physical</span> <span class="nb">id</span><span class="p">:</span> <span class="mi">1</span><span class="n">e</span>
       <span class="n">bus</span> <span class="n">info</span><span class="p">:</span> <span class="n">pci</span><span class="o">@</span><span class="mi">0000</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">1</span><span class="n">e</span><span class="mf">.0</span>
       <span class="n">version</span><span class="p">:</span> <span class="n">a1</span>
       <span class="n">width</span><span class="p">:</span> <span class="mi">64</span> <span class="n">bits</span>
       <span class="n">clock</span><span class="p">:</span> <span class="mi">33</span><span class="n">MHz</span>
       <span class="n">capabilities</span><span class="p">:</span> <span class="n">pm</span> <span class="n">msi</span> <span class="n">pciexpress</span> <span class="n">cap_list</span>
       <span class="n">configuration</span><span class="p">:</span> <span class="n">latency</span><span class="o">=</span><span class="mi">0</span>
       <span class="n">resources</span><span class="p">:</span> <span class="n">iomemory</span><span class="p">:</span><span class="mi">100</span><span class="o">-</span><span class="n">ff</span> <span class="n">memory</span><span class="p">:</span><span class="mi">84000000</span><span class="o">-</span><span class="mi">84</span><span class="n">ffffff</span> <span class="n">memory</span><span class="p">:</span><span class="mi">1000000000</span><span class="o">-</span><span class="mi">13</span><span class="n">ffffffff</span> <span class="n">memory</span><span class="p">:</span><span class="mi">82000000</span><span class="o">-</span><span class="mi">83</span><span class="n">ffffff</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
uname -ar #r for kernel, a for all
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linux ip-10-0-0-128 5.4.0-1045-aws #47-Ubuntu SMP Tue Apr 13 07:02:25 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>En la celda anterior se utilizó el comando de <em>magic</em> <code class="docutils literal notranslate"><span class="pre">%%bash</span></code>. Algunos comandos de <em>magic</em> los podemos utilizar también con <code class="docutils literal notranslate"><span class="pre">import</span></code>. Ver <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/magics.html">ipython-magics</a></p>
</div>
<section id="compute-unified-device-architecture-cuda">
<h2><em>Compute Unified Device Architecture</em> (CUDA)<a class="headerlink" href="#compute-unified-device-architecture-cuda" title="Permalink to this headline">#</a></h2>
<section id="un-poco-de-historia">
<h3>Un poco de historia…<a class="headerlink" href="#un-poco-de-historia" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>GPGPU es un término que se utilizó para referirse a la programación en unidades de procesamiento gráfico de forma general. Hoy en día se conoce simplemente como <em>GPU programming</em>. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units">General-purpose computing on graphics processing units</a>.</p>
</aside>
<p>La industria de videojuegos impulsó el desarrollo de las tarjetas gráficas a una velocidad sin precedente a partir del año 1999 para incrementar el nivel de detalle visual en los juegos de video. Alrededor del 2003 se planteó la posibilidad de utilizar las unidades de procesamiento gráfico para procesamiento en paralelo relacionado con aplicaciones distintas al ambiente de gráficas. A partir del 2006 la empresa <a class="reference external" href="https://www.nvidia.com/en-us/about-nvidia/">NVIDIA</a> introdujo CUDA, una plataforma GPGPU y un modelo de programación que facilita el procesamiento en paralelo en las GPU’s.</p>
<p>Desde el 2006, las tarjetas gráficas muestran una brecha significativa con las unidades de procesamiento CPU’s. Ver por ejemplo las gráficas que <em>NVIDIA</em> publica año tras año y que están relacionadas con el número de operaciones en punto flotante por segundo (FLOPS) y la transferencia de datos en la memoria RAM de la GPU: <a class="reference external" href="https://www.google.com/search?q=plot+gflops+gpu+cpu+nvidia&amp;tbm=isch&amp;ved=2ahUKEwjKk7Le_bzwAhUUaKwKHX9-AP8Q2-cCegQIABAA&amp;oq=plot+gflops+gpu+cpu+nvidia&amp;gs_lcp=CgNpbWcQA1C_W1i_W2DhXGgAcAB4AIABX4gBX5IBATGYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&amp;sclient=img&amp;ei=xAiYYMqhL5TQsQX__IH4Dw">gráficas cpu vs gpu en imágenes de google</a>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>La GPU y la CPU están conectadas por una interconexión de nombre <a class="reference external" href="https://en.wikipedia.org/wiki/Conventional_PCI">PCI</a>.</p>
</aside>
<p>Hoy en día se continúa el desarrollo de GPU’s con mayor RAM, con mayor capacidad de cómputo y mejor conectividad con la CPU. Estos avances han permitido resolver problemas con mayor exactitud que los resueltos con las CPU’s, por ejemplo en el terreno de <em>deep learning</em> en reconocimiento de imágenes. Ver <a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>, <a class="reference external" href="https://medium.com/limitlessai/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73">2012: A Breakthrough Year for Deep Learning</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Para más avances ver <a class="reference external" href="https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/">NVIDIA Turing Architecture In-Depth</a>, <a class="reference external" href="https://wccftech.com/samsung-amd-rdna-gpu-2021/">samsung-amd-rdna-gpu-2021</a>, <a class="reference external" href="https://www.theguardian.com/games/2020/mar/19/playstation-5-specifications-revealed-but-design-is-still-a-mystery">playstation-5-specifications-revealed-but-design-is-still-a-mystery</a>, <a class="reference external" href="https://news.xbox.com/en-us/2020/03/16/xbox-series-x-tech/">xbox-series-x-tech</a> y recientemente <a class="reference external" href="https://www.ibm.com/blogs/nordic-msp/ibm-supercomputer-summit-attacks-coronavirus/">IBM Supercomputer Summit Attacks Coronavirus…</a>.</p>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese la <a class="reference external" href="https://en.wikipedia.org/wiki/Flynn%27s_taxonomy">taxonomía de Flynn</a>.</p>
</aside>
<p>La arquitectura en la que podemos ubicar a las GPU’s es en la de un sistema MIMD y SIMD. De hecho es <a class="reference external" href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads">SIMT: Simple Instruction Multiple Thread</a> en un modelo de sistema de memoria compartida pues “los <em>threads</em> en un <em>warp</em> leen la misma instrucción para ser ejecutada”.</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un <em>warp</em> en el contexto de GPU <em>programming</em> es un conjunto de <em>threads</em>. Equivale a <span class="math notranslate nohighlight">\(32\)</span> <em>threads</em>.</p>
</div>
</section>
<section id="diferencia-con-la-cpu-multicore">
<h3>¿Diferencia con la CPU multicore?<a class="headerlink" href="#diferencia-con-la-cpu-multicore" title="Permalink to this headline">#</a></h3>
<img src="https://dl.dropboxusercontent.com/s/k11qub01w4nvksi/CPU_multicore.png?dl=0" heigth="500" width="500">
<p><strong>GPU</strong></p>
<img src="https://dl.dropboxusercontent.com/s/lw9kia12qhwp95r/GPU.png?dl=0" heigth="500" width="500"><div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese en el dibujo anterior la diferencia en tamaño del caché en la CPU y GPU. También la unidad de control es más pequeña en la GPU.</p>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Una máquina <em>quad core</em> soporta cuatro threads en cada <em>core</em>.</p>
</aside>
<p>A diferencia de una máquina <em>multicore</em> o multi CPU’s con la habilidad de lanzar en un instante de tiempo unos cuantos <em>threads</em>, la GPU puede lanzar cientos o miles de threads en un instante siendo cada core <em>heavily multithreaded</em>. Sí hay restricciones en el número de threads que se pueden lanzar en un instante pues las tarjetas gráficas tienen diferentes características (modelo) y arquitecturas, pero la diferencia con la CPU es grande. Por ejemplo, la serie <strong>GT 200</strong> (2009) en un instante puede lanzar 30,720 threads con sus 240 <em>cores</em>. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/GeForce_200_series">GeForce_200_series</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units">List of NVIDIA GPU’s</a>.</p>
<p>Ver <a class="reference external" href="https://computer.howstuffworks.com/graphics-card1.htm">How Graphics Cards Work</a> y <a class="reference external" href="https://computer.howstuffworks.com/microprocessor.htm">How Microprocessors Work</a> para más información.</p>
</section>
<section id="otras-companias-producen-tarjetas-graficas">
<h3>¿Otras compañías producen tarjetas gráficas?<a class="headerlink" href="#otras-companias-producen-tarjetas-graficas" title="Permalink to this headline">#</a></h3>
<p>Sí, ver por ejemplo la lista de GPU’s de <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units">Advanced Micro Devices</a>.</p>
</section>
<section id="si-tengo-una-tarjeta-grafica-de-amd-puedo-correr-un-programa-de-cuda">
<h3>¿Si tengo una tarjeta gráfica de AMD puedo correr un programa de CUDA?<a class="headerlink" href="#si-tengo-una-tarjeta-grafica-de-amd-puedo-correr-un-programa-de-cuda" title="Permalink to this headline">#</a></h3>
<p>No es posible pero algunas alternativas son:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.khronos.org/opencl/">OpenCl</a></p></li>
<li><p><a class="reference external" href="https://www.openacc.org/about">OpenACC</a></p></li>
</ul>
</section>
<section id="si-tengo-una-tarjeta-grafica-de-nvidia-un-poco-antigua-puedo-correr-un-programa-de-cuda">
<h3>¿Si tengo una tarjeta gráfica de NVIDIA un poco antigua puedo correr un programa de CUDA?<a class="headerlink" href="#si-tengo-una-tarjeta-grafica-de-nvidia-un-poco-antigua-puedo-correr-un-programa-de-cuda" title="Permalink to this headline">#</a></h3>
<p>Las GPU’s producidas por NVIDIA desde 2006 son capaces de correr programas basados en <em><strong>CUDA C</strong></em>. La cuestión sería revisar qué <em>compute capability</em> tiene tu tarjeta. Ver <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">Compute Capabilities</a> para las características que tienen las tarjetas más actuales.</p>
</section>
<section id="que-es-cuda-c">
<h3>¿Qué es <em>CUDA C</em>?<a class="headerlink" href="#que-es-cuda-c" title="Permalink to this headline">#</a></h3>
<p>Es una extensión al lenguaje <em>C</em> de programación en el que se utiliza una nueva sintaxis para procesamiento en la GPU. Contiene también una librería <em>runtime</em> que define funciones que se ejecutan desde el <em><strong>host</strong></em> por ejemplo para alojar y desalojar memoria en el <em><strong>device</strong></em>, transferir datos entre la memoria <em>host</em> y la memoria <em>device</em> o manejar múltiples <em>devices</em>. La librería <em>runtime</em> está hecha encima de una API de <em>C</em> de bajo nivel llamada <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html">NVIDIA CUDA Driver API</a> la cual es accesible desde el código. Para información de la API de la librería runtime ver <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html">NVIDIA CUDA Runtime API</a>.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>La transferencia de datos entre la memoria del <em>host</em> a <em>device</em> o viceversa constituye un <em>bottleneck</em> fuerte.</p>
</div>
</section>
<section id="a-que-se-refiere-la-terminologia-de-host-y-device">
<h3>¿A qué se refiere la terminología de <em>host</em> y <em>device</em>?<a class="headerlink" href="#a-que-se-refiere-la-terminologia-de-host-y-device" title="Permalink to this headline">#</a></h3>
<p><em>Host</em> es la máquina <em>multicore</em> CPU y <em>device</em> es la GPU. Una máquina puede tener múltiples GPU’s por lo que tendrá múltiples <em>devices</em>.</p>
</section>
<section id="tengo-una-tarjeta-nvidia-cuda-capable-que-debo-realizar-primero">
<h3>Tengo una tarjeta NVIDIA CUDA <em>capable</em> ¿qué debo realizar primero?<a class="headerlink" href="#tengo-una-tarjeta-nvidia-cuda-capable-que-debo-realizar-primero" title="Permalink to this headline">#</a></h3>
<p>Realizar instalaciones dependiendo de tu sistema operativo. Ver <a class="reference external" href="https://github.com/palmoreck/programming-languages/tree/master/C/extensiones_a_C/CUDA/instalacion">instalación</a> donde además se encontrará información para instalación de <a class="reference external" href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a>.</p>
</section>
<section id="instale-lo-necesario-y-al-ejecutar-en-la-terminal-nvcc-v-obtengo-la-version-como-puedo-probar-mi-instalacion">
<h3>Instalé lo necesario y al ejecutar en la terminal <code class="docutils literal notranslate"><span class="pre">nvcc</span> <span class="pre">-V</span></code> obtengo la versión… ¿cómo puedo probar mi instalación?<a class="headerlink" href="#instale-lo-necesario-y-al-ejecutar-en-la-terminal-nvcc-v-obtengo-la-version-como-puedo-probar-mi-instalacion" title="Permalink to this headline">#</a></h3>
<p>1)Obteniendo información del <em>NVIDIA driver</em> ejecutando en la terminal el comando <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mon May 10 23:31:35 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA Tesla K80    On   | 00000000:00:1E.0 Off |                    0 |
| N/A   34C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
nvidia-smi -a #a for all
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==============NVSMI LOG==============

Timestamp                                 : Mon May 10 23:31:35 2021
Driver Version                            : 465.19.01
CUDA Version                              : 11.3

Attached GPUs                             : 1
GPU 00000000:00:1E.0
    Product Name                          : NVIDIA Tesla K80
    Product Brand                         : Tesla
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Enabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 0325116067357
    GPU UUID                              : GPU-30cfb81b-c816-3139-4205-7e6a686b4699
    Minor Number                          : 0
    VBIOS Version                         : 80.21.1F.00.02
    MultiGPU Board                        : No
    Board ID                              : 0x1e
    GPU Part Number                       : 900-22080-0000-000
    Inforom Version
        Image Version                     : 2080.0200.00.04
        OEM Object                        : 1.1
        ECC Object                        : 3.0
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GPU Virtualization Mode
        Virtualization Mode               : Pass-Through
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x00
        Device                            : 0x1E
        Domain                            : 0x0000
        Device Id                         : 0x102D10DE
        Bus Id                            : 00000000:00:1E.0
        Sub System Id                     : 0x106C10DE
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 1
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : N/A
        Rx Throughput                     : N/A
    Fan Speed                             : N/A
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : N/A
            HW Power Brake Slowdown       : N/A
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 11441 MiB
        Used                              : 0 MiB
        Free                              : 11441 MiB
    BAR1 Memory Usage
        Total                             : 16384 MiB
        Used                              : 2 MiB
        Free                              : 16382 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : Enabled
        Pending                           : Enabled
    ECC Errors
        Volatile
            Single Bit            
                Device Memory             : 0
                Register File             : 0
                L1 Cache                  : 0
                L2 Cache                  : 0
                Texture Memory            : 0
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : 0
            Double Bit            
                Device Memory             : 0
                Register File             : 0
                L1 Cache                  : 0
                L2 Cache                  : 0
                Texture Memory            : 0
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : 0
        Aggregate
            Single Bit            
                Device Memory             : 0
                Register File             : 0
                L1 Cache                  : 0
                L2 Cache                  : 0
                Texture Memory            : 0
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : 0
            Double Bit            
                Device Memory             : 0
                Register File             : 0
                L1 Cache                  : 0
                L2 Cache                  : 0
                Texture Memory            : 0
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : 0
    Retired Pages
        Single Bit ECC                    : 0
        Double Bit ECC                    : 0
        Pending Page Blacklist            : No
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 34 C
        GPU Shutdown Temp                 : 110 C
        GPU Slowdown Temp                 : 88 C
        GPU Max Operating Temp            : N/A
        GPU Target Temperature            : N/A
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 30.91 W
        Power Limit                       : 149.00 W
        Default Power Limit               : 149.00 W
        Enforced Power Limit              : 149.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 175.00 W
    Clocks
        Graphics                          : 324 MHz
        SM                                : 324 MHz
        Memory                            : 324 MHz
        Video                             : 405 MHz
    Applications Clocks
        Graphics                          : 562 MHz
        Memory                            : 2505 MHz
    Default Applications Clocks
        Graphics                          : 562 MHz
        Memory                            : 2505 MHz
    Max Clocks
        Graphics                          : 875 MHz
        SM                                : 875 MHz
        Memory                            : 2505 MHz
        Video                             : 540 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : On
        Auto Boost Default                : On
    Processes                             : None
</pre></div>
</div>
</div>
</div>
<p>Para más información del comando <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> ver <a class="reference external" href="https://askubuntu.com/questions/1220144/can-somebody-explain-the-results-for-the-nvidia-smi-command-in-a-terminal">results-for-the-nvidia-smi-command-in-a-terminal</a> y <a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf">nvidia-smi-367.38</a>.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Ejecutando <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">-l</span> <span class="pre">1</span></code> nos da información cada segundo. Otra opción es <code class="docutils literal notranslate"><span class="pre">watch</span> <span class="pre">-n</span> <span class="pre">3</span> <span class="pre">nvidia-smi</span> <span class="pre">--query-gpu=&lt;queries&gt;</span> <span class="pre">--format=csv</span></code>. Por ejemplo:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>watch -n <span class="m">3</span> nvidia-smi --query-gpu<span class="o">=</span>index,gpu_name,memory.total,memory.used,memory.free,temperature.gpu,pstate,utilization.gpu,utilization.memory --format<span class="o">=</span>csv
</pre></div>
</div>
<p>Ver <a class="reference external" href="https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries">useful-nvidia-smi-queries</a></p>
<ul class="simple">
<li><p>Una herramienta que nos ayuda al monitoreo de uso de la(s) GPU(s) es <a class="reference external" href="https://github.com/Syllo/nvtop">nvtop</a>.</p></li>
</ul>
</div>
<p>2)Compilando y ejecutando el siguiente programa de <em>CUDA C</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> hello_world.cu

<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world! del bloque </span><span class="si">%d</span><span class="s2"> del thread </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">);</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world! del cpu thread</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing hello_world.cu
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>La sintaxis <code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;2,3&gt;&gt;&gt;</span></code> refiere que serán lanzados 2 bloques de 3 <em>threads</em> cada uno.</p>
</div>
<p>Compilamos con <code class="docutils literal notranslate"><span class="pre">nvcc</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 hello_world.cu -o hello_world.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nvcc</span></code> es un <em>wrapper</em> para el compilador de programas escritos en <em>C</em>.</p></li>
<li><p>En ocasiones para tener funcionalidad de un determinado <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">compute capability</a> se especifica la <em>flag</em> de <code class="docutils literal notranslate"><span class="pre">-arch=sm_11</span></code> en la línea de <code class="docutils literal notranslate"><span class="pre">nvcc</span></code>. En este caso se le indica al compilador que compile el programa para un <em>compute capability</em> de <span class="math notranslate nohighlight">\(1.1\)</span>. Ver <a class="reference external" href="https://stackoverflow.com/questions/16954931/cuda-5-0-cudagetdeviceproperties-strange-grid-size-or-a-bug-in-my-code">run a kernel using the larger grid size support offered</a>.</p></li>
<li><p>Para la versión 11 de CUDA se requiere explícitamente indicar la arquitectura y código para la compilación. Ver <a class="reference external" href="https://stackoverflow.com/questions/63675040/cuda-11-kernel-doesnt-run">cuda-11-kernel-doesnt-run</a>, <a class="reference external" href="https://stackoverflow.com/questions/35656294/cuda-how-to-use-arch-and-code-and-sm-vs-compute/35657430#35657430">cuda-how-to-use-arch-and-code-and-sm-vs-compute</a>, <a class="reference external" href="https://stackoverflow.com/questions/28932864/cuda-compute-capability-requirements/28933055#28933055">cuda-compute-capability-requirements</a>, <a class="reference external" href="https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api">what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api</a>.</p></li>
</ul>
</div>
<p>Ejecutamos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./hello_world.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hello world! del bloque 0 del thread 0
Hello world! del bloque 0 del thread 1
Hello world! del bloque 0 del thread 2
Hello world! del bloque 1 del thread 0
Hello world! del bloque 1 del thread 1
Hello world! del bloque 1 del thread 2
Hello world! del cpu thread
</pre></div>
</div>
</div>
</div>
<p>3)Haciendo un query a la GPU para ver qué características tiene (lo siguiente es posible ejecutar sólo si se instaló el <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit">CUDA toolkit</a>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
cd /usr/local/cuda/samples/1_Utilities/deviceQuery/ &amp;&amp; sudo make
/usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>make: Nothing to be done for &#39;all&#39;.
/usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: &quot;NVIDIA Tesla K80&quot;
  CUDA Driver Version / Runtime Version          11.3 / 11.3
  CUDA Capability Major/Minor version number:    3.7
  Total amount of global memory:                 11441 MBytes (11996954624 bytes)
  (013) Multiprocessors, (192) CUDA Cores/MP:    2496 CUDA Cores
  GPU Max Clock rate:                            824 MHz (0.82 GHz)
  Memory Clock rate:                             2505 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 1572864 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        114688 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            No
  Supports Cooperative Kernel Launch:            No
  Supports MultiDevice Co-op Kernel Launch:      No
  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 30
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.3, CUDA Runtime Version = 11.3, NumDevs = 1
Result = PASS
</pre></div>
</div>
</div>
</div>
</section>
<section id="por-que-usar-cuda-y-cuda-c-o-mas-general-computo-en-la-gpu">
<h3>¿Por qué usar CUDA y <em>CUDA-C</em> o más general cómputo en la GPU?<a class="headerlink" href="#por-que-usar-cuda-y-cuda-c-o-mas-general-computo-en-la-gpu" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>NVIDIA como se mencionó al inicio de la nota fue de las primeras compañías en utilizar la GPU para tareas no relacionadas con el área de gráficos, ha colaborado en el avance del conocimiento de las GPU’s y desarrollo de algoritmos y tarjetas gráficas. Otra compañía es <a class="reference external" href="https://en.wikipedia.org/wiki/Khronos_Group">Khronos_Group</a> por ejemplo, quien actualmente desarrolla <a class="reference external" href="https://www.khronos.org/opencl/">OpenCl</a>.</p></li>
</ul>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><em>Deep learning</em> se ha utilizado para resolver problemas en <em>machine learning</em> típicos. Ejemplos de esto son la clasificación de imágenes, de sonidos o análisis de textos. Ver por ejemplo <a class="reference external" href="https://medium.com/&#64;michael.fire/practical-text-analysis-using-deep-learning-5fb0744efdf9">Practical text analysis using deep learning</a>.</p>
</aside>
<ul class="simple">
<li><p>El cómputo en la GPU constituye hoy en día una alternativa fuerte a la implementación de modelos de <em>machine learning</em> ampliamente utilizada por la comunidad científica, también para cómputo matricial y <em>deep learning</em>.</p></li>
<li><p>Sí hay publicaciones científicas para la implementación de <em>deep learning</em> en las CPU’s, ver por ejemplo el <em>paper</em> reciente de <a class="reference external" href="https://www.cs.rice.edu/~as143/Papers/SLIDE_MLSys.pdf">SLIDE</a> cuyo repo de <em>github</em> es <a class="reference external" href="https://github.com/keroro824/HashingDeepLearning">HashingDeepLearning</a>. Tal <em>paper</em> plantea una discusión a realizar con la frase:</p></li>
</ul>
<p><em>…change in the state-of-the-art algorithms can render specialized hardware less effective in the future</em>.</p>
<p>Ver por ejemplo <a class="reference external" href="https://developer.nvidia.com/tensor-cores">Tensor Cores</a>, <a class="reference external" href="https://www.nvidia.com/en-us/data-center/tensorcore/">NVIDIA TENSOR CORES, The Next Generation of Deep Learning</a>, <a class="reference external" href="https://www.ibm.com/thought-leadership/summit-supercomputer/">The most powerful computers on the planet: SUMMIT</a> como ejemplos de hardware especializado para aprendizaje con <em>Tensorflow</em>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p><em>Summit powered by 9,126 IBM Power9 CPUs and over 27,000 NVIDIA V100 Tensor Core GPUS, is able to do 200 quadrillion calculations per second…</em> <a class="reference external" href="https://www.ibm.com/blogs/nordic-msp/ibm-supercomputer-summit-attacks-coronavirus/">IBM Supercomputer Summit Attacks Coronavirus…</a>.</p>
</div>
<p>Sin embargo, por falta de implementaciones algorítmicas en la <em>CPU</em> se han adoptado implementaciones de <em>deep learning</em> utilizando GPU’s:</p>
<p><em>…However, for the case of DL, this investment is justified due to the lack of significant progressin the algorithmic alternatives for years.</em></p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Revisar también las entradas <a class="reference external" href="https://www.engadget.com/2020/03/03/rice-university-slide-cpu-gpu-machine-learning/">An algorithm could make CPUs a cheap way to train AI</a> y <a class="reference external" href="https://www.sciencedaily.com/releases/2020/03/200305135041.htm">Deep learning rethink overcomes major obstacle in AI industry</a>.</p>
</div>
</section>
</section>
<section id="cuda-c">
<h2><a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">CUDA-C</a><a class="headerlink" href="#cuda-c" title="Permalink to this headline">#</a></h2>
<p>Consiste en extensiones al lenguaje C y en una <em>runtime library</em>.</p>
<section id="kernel">
<h3><em>Kernel</em><a class="headerlink" href="#kernel" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>En <em>CUDA C</em> se define una función que se ejecuta en el <em><strong>device</strong></em> y que se le nombra <em><strong>kernel</strong></em>. El <em>kernel</em> inicia con la sintaxis:</p></li>
</ul>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">mifun</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">param</span><span class="p">){</span><span class="w"></span>
<span class="p">...</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Siempre es tipo <code class="docutils literal notranslate"><span class="pre">void</span></code> (no hay <code class="docutils literal notranslate"><span class="pre">return</span></code>).</p></li>
<li><p>El llamado al <em>kernel</em> se realiza desde el <em><strong>host</strong></em> y con una sintaxis en la que se define el número de <em>threads</em>, nombrados <em><strong>CUDA threads</strong></em> (que son distintos a los <em>CPU threads</em>), y bloques, nombrados <em><strong>CUDA blocks</strong></em>, que serán utilizados para la ejecución del <em>kernel</em>. La sintaxis que se utiliza es <code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;</span> <span class="pre">&gt;&gt;&gt;</span></code> y en la primera entrada se coloca el número de <em>CUDA blocks</em> y en la segunda entrada el número de <em>CUDA threads</em>. Por ejemplo para lanzar N bloques de 5 <em>threads</em>.</p></li>
</ul>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">mifun</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">param</span><span class="p">){</span><span class="w"></span>
<span class="p">...</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(){</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">par</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">mifun</span><span class="o">&lt;&lt;&lt;</span><span class="n">N</span><span class="p">,</span><span class="mi">5</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">par</span><span class="p">);</span><span class="w"> </span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="ejemplo">
<h3>Ejemplo<a class="headerlink" href="#ejemplo" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> hello_world_simple.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world!</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing hello_world_simple.cu
</pre></div>
</div>
</div>
</div>
<p>Compilación:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall hello_world_simple.cu -o hello_world_simple.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<p>Ejecución:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./hello_world_simple.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hello world!
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>La función <code class="docutils literal notranslate"><span class="pre">main</span></code> se ejecuta en la CPU.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">func</span></code> es un <em>kernel</em> y es ejecutada por los <em>CUDA threads</em> en el <em>device</em>. Obsérvese que tal función inicia con la sintaxis <code class="docutils literal notranslate"><span class="pre">__global__</span></code>. En este caso el <em>CUDA thread</em> que fue lanzado no realiza ninguna acción pues el cuerpo del kernel está vacío.</p></li>
<li><p>El <em>kernel</em> sólo puede tener un <code class="docutils literal notranslate"><span class="pre">return</span></code> tipo <em>void</em>: <code class="docutils literal notranslate"><span class="pre">__global__</span> <span class="pre">void</span> <span class="pre">func</span></code> por lo que el <em>kernel</em> debe regresar sus resultados a través de sus argumentos.</p></li>
<li><p>La extensión del archivo debe ser <code class="docutils literal notranslate"><span class="pre">.cu</span></code> aunque esto puede modificarse al compilar con <code class="docutils literal notranslate"><span class="pre">nvcc</span></code>:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvcc -x cu hello_world.c -o hello_world.out
</pre></div>
</div>
</div>
</section>
<section id="bloques-de-threads">
<h3>¿Bloques de threads?<a class="headerlink" href="#bloques-de-threads" title="Permalink to this headline">#</a></h3>
<p>Los <em>CUDA threads</em> son divididos en <em>CUDA blocks</em> y éstos se encuentran en un <em>grid</em>. En el lanzamiento del <em>kernel</em> se debe especificar al hardware cuántos <em>CUDA blocks</em> tendrá nuestro <em>grid</em> y cuántos <em>CUDA threads</em> estarán en cada bloque.</p>
</section>
<section id="id1">
<h3>Ejemplo<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><code class="docutils literal notranslate"><span class="pre">func&lt;&lt;&lt;2,3&gt;&gt;&gt;();</span></code> representa 2 bloques de 3 <em>threads</em> cada uno.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> hello_world_2.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world! del bloque </span><span class="si">%d</span><span class="s2"> del thread </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">);</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing hello_world_2.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall hello_world_2.cu -o hello_world_2.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./hello_world_2.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hello world! del bloque 0 del thread 0
Hello world! del bloque 0 del thread 1
Hello world! del bloque 0 del thread 2
Hello world! del bloque 1 del thread 0
Hello world! del bloque 1 del thread 1
Hello world! del bloque 1 del thread 2
</pre></div>
</div>
</div>
</div>
<p><strong>En lo que continúa de la nota el nombre <em>thread</em> hará referencia a <em>CUDA thread</em> y el nombre bloque a <em>CUDA block</em>.</strong></p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El llamado a la ejecución del <em>kernel</em> se realizó en el <em>host</em> y se lanzaron <span class="math notranslate nohighlight">\(2\)</span> bloques cada uno con <span class="math notranslate nohighlight">\(3\)</span> <em>threads</em>.</p></li>
<li><p>Se utiliza la función <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d">cudaDeviceSynchronize</a> para que el <em>cpu-thread</em> espere la finalización de la ejecución del <em>kernel</em>.</p></li>
<li><p>En el ejemplo anterior, las variables <code class="docutils literal notranslate"><span class="pre">blockIdx</span></code> y <code class="docutils literal notranslate"><span class="pre">threadIdx</span></code> hacen referencia a los <strong>id</strong>’s que tienen los bloques y los <em>threads</em>. El <em>id</em> del bloque dentro del <em>grid</em> y el <em>id</em> del thread dentro del bloque. La parte <code class="docutils literal notranslate"><span class="pre">.x</span></code> de las variables: <code class="docutils literal notranslate"><span class="pre">blockIdx.x</span></code> y <code class="docutils literal notranslate"><span class="pre">threadIdx.x</span></code> refieren a la <strong>primera coordenada</strong> del bloque en el <em>grid</em> y a la <strong>primera coordenada</strong> del <em>thread</em> en en el bloque.</p></li>
<li><p>La elección del número de bloques en un <em>grid</em> o el número de <em>threads</em> en un bloque no corresponde a alguna disposición del <em>hardware</em>. Esto es, si se lanza un <em>kernel</em> con <code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;</span> <span class="pre">1,</span> <span class="pre">3</span> <span class="pre">&gt;&gt;&gt;</span></code> no implica que la GPU tenga en su <em>hardware</em> un bloque o 3 <em>threads</em>. Asimismo, las coordenadas que se obtienen vía <code class="docutils literal notranslate"><span class="pre">blockIdx</span></code> o <code class="docutils literal notranslate"><span class="pre">threadIdx</span></code> son meras abstracciones, no corresponden a algún ordenamiento en el hardware de la GPU.</p></li>
<li><p>Todos los <em>threads</em> de un bloque  ejecutan el <em>kernel</em> por lo que se tienen tantas copias del kernel como número de bloques sean lanzados. Esto es una muestra la GPU sigue el modelo  <em>Single Instruction Multiple Threads <a class="reference external" href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads">(SIMT)</a></em>.</p></li>
</ul>
</div>
</section>
<section id="grid-s-y-bloques-3-dimensionales">
<h3>¿Grid’s y bloques 3-dimensionales?<a class="headerlink" href="#grid-s-y-bloques-3-dimensionales" title="Permalink to this headline">#</a></h3>
<p>En el <em>device</em> podemos definir el <em>grid</em> de bloques y el bloque de <em>threads</em> utilizando el tipo de dato <code class="docutils literal notranslate"><span class="pre">dim3</span></code> el cual también es parte de <em>CUDA C</em>.</p>
</section>
<section id="id2">
<h3>Ejemplo<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimGrid(1,2,1);</span></code> representa 2 bloques en el <em>grid</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimBlock(1,1,3);</span></code> representa 3 <em>threads</em> por bloque.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> hello_world_3.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world! del bloque </span><span class="si">%d</span><span class="s2"> del thread </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">z</span><span class="p">);</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span>
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world! del cpu thread</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing hello_world_3.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall hello_world_3.cu -o hello_world_3.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./hello_world_3.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hello world! del bloque 0 del thread 0
Hello world! del bloque 0 del thread 1
Hello world! del bloque 0 del thread 2
Hello world! del bloque 1 del thread 0
Hello world! del bloque 1 del thread 1
Hello world! del bloque 1 del thread 2
Hello world! del cpu thread
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h3>Ejemplo<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimGrid(1,1,1);</span></code> representa 1 bloque en el <em>grid</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimBlock(1,3,1);</span></code> representa 3 <em>threads</em> por bloque.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> thread_idxs.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">z</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;blockIdx.x:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;thread idx.x:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;thread idx.y:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;thread idx.z:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">z</span><span class="p">);</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing thread_idxs.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span> 
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 thread_idxs.cu -o thread_idxs.out 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./thread_idxs.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>blockIdx.x:0
thread idx.x:0
thread idx.x:0
thread idx.x:0
thread idx.y:0
thread idx.y:1
thread idx.y:2
thread idx.z:0
thread idx.z:0
thread idx.z:0
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h3>Ejemplo<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimGrid(1,2,2);</span></code> representa 4 bloques en el <em>grid</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimBlock(1,1,1);</span></code> representa 1 <em>thread</em> por bloque.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> block_idxs.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;blockIdx.x:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;blockIdx.y:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;blockIdx.z:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">z</span><span class="p">);</span>

<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span> 
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span> 
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing block_idxs.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall block_idxs.cu -o block_idxs.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./block_idxs.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>blockIdx.x:0
blockIdx.x:0
blockIdx.x:0
blockIdx.x:0
blockIdx.y:1
blockIdx.y:0
blockIdx.y:1
blockIdx.y:0
blockIdx.z:1
blockIdx.z:0
blockIdx.z:0
blockIdx.z:1
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h3>Ejemplo<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<p>Podemos usar la variable <code class="docutils literal notranslate"><span class="pre">blockDim</span></code> para cada coordenada <code class="docutils literal notranslate"><span class="pre">x,</span> <span class="pre">y</span></code> o <code class="docutils literal notranslate"><span class="pre">z</span></code> y obtener la dimensión de los bloques.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimGrid(2,2,2);</span></code> representa 8 bloques en el <em>grid</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimBlock(3,1,2);</span></code> representa 6 <em>threads</em> por bloque.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> block_dims.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">z</span><span class="o">==</span><span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">z</span><span class="o">==</span><span class="mi">1</span><span class="p">){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;blockDim.x:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;blockDim.y:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">blockDim</span><span class="o">.</span><span class="n">y</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;blockDim.z:</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">blockDim</span><span class="o">.</span><span class="n">z</span><span class="p">);</span>
    <span class="p">}</span>

<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing block_dims.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall block_dims.cu -o block_dims.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./block_dims.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>blockDim.x:3
blockDim.x:3
blockDim.x:3
blockDim.x:3
blockDim.y:1
blockDim.y:1
blockDim.y:1
blockDim.y:1
blockDim.z:2
blockDim.z:2
blockDim.z:2
blockDim.z:2
</pre></div>
</div>
</div>
</div>
</section>
<section id="alojamiento-de-memoria-en-el-device">
<h3>Alojamiento de memoria en el <em>device</em><a class="headerlink" href="#alojamiento-de-memoria-en-el-device" title="Permalink to this headline">#</a></h3>
<p>Para alojar memoria en el <em>device</em> se utiliza el llamado a <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356">cudaMalloc</a> y para transferir datos del <em>host</em> al <em>device</em> o viceversa se llama a la función <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8">cudaMemcpy</a> con respectivos parámetros como <code class="docutils literal notranslate"><span class="pre">cudaMemcpyHostToDevice</span></code> o <code class="docutils literal notranslate"><span class="pre">cudaMemcpyDeviceToHost</span></code>.</p>
<p>Para desalojar memoria del <em>device</em> se utiliza el llamado a <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094">cudaFree</a>.</p>
</section>
<section id="id6">
<h3>Ejemplo<a class="headerlink" href="#id6" title="Permalink to this headline">#</a></h3>
<p><strong>N bloques de 1 thread</strong></p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimGrid(N,1,1);</span></code> representa N bloques en el <em>grid</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimBlock(1,1,1);</span></code> representa 1 <em>thread</em> por bloque.</p>
<p><code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;dimGrid,dimBlock&gt;&gt;&gt;</span></code> N bloques de 1 <em>thread</em>.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> vector_sum.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#define N 10</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">vect_sum</span><span class="p">(</span><span class="nb">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="nb">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="nb">int</span> <span class="o">*</span><span class="n">c</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">block_id_x</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">block_id_x</span><span class="o">&lt;</span><span class="n">N</span><span class="p">)</span> <span class="o">//</span><span class="n">we</span> <span class="n">assume</span> <span class="n">N</span> <span class="ow">is</span> <span class="n">less</span> <span class="n">than</span> <span class="n">maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">blocks</span>
                     <span class="o">//</span><span class="n">that</span> <span class="n">can</span> <span class="n">be</span> <span class="n">launched</span>
        <span class="n">c</span><span class="p">[</span><span class="n">block_id_x</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">block_id_x</span><span class="p">]</span><span class="o">+</span><span class="n">b</span><span class="p">[</span><span class="n">block_id_x</span><span class="p">];</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">a</span><span class="p">[</span><span class="n">N</span><span class="p">],</span> <span class="n">b</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="n">c</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
    <span class="nb">int</span> <span class="o">*</span><span class="n">device_a</span><span class="p">,</span> <span class="o">*</span><span class="n">device_b</span><span class="p">,</span> <span class="o">*</span><span class="n">device_c</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="o">//</span><span class="n">allocation</span> <span class="ow">in</span> <span class="n">device</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">device_a</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span> 
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">device_b</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">device_c</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="o">//</span><span class="n">dummy</span> <span class="n">data</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">i</span><span class="p">;</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">i</span><span class="o">*</span><span class="n">i</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="o">//</span><span class="n">making</span> <span class="n">copies</span> <span class="n">of</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="n">arrays</span> <span class="n">to</span> <span class="n">GPU</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">device_a</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">N</span><span class="o">*</span><span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">device_b</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">N</span><span class="o">*</span><span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">vect_sum</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">device_a</span><span class="p">,</span><span class="n">device_b</span><span class="p">,</span><span class="n">device_c</span><span class="p">);</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="o">//</span><span class="n">copy</span> <span class="n">result</span> <span class="n">to</span> <span class="n">c</span> <span class="n">array</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="n">device_c</span><span class="p">,</span><span class="n">N</span><span class="o">*</span><span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2">+</span><span class="si">%d</span><span class="s2"> = </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_a</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_b</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_c</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing vector_sum.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall vector_sum.cu -o vector_sum.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./vector_sum.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0+0 = 0
1+1 = 2
2+4 = 6
3+9 = 12
4+16 = 20
5+25 = 30
6+36 = 42
7+49 = 56
8+64 = 72
9+81 = 90
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El <em>statement</em>:</p></li>
</ul>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">device_a</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">device_b</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">device_c</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
<p>en sintaxis de <em>C</em> definen apuntadores que refieren a una dirección de memoria. En el contexto de la <em>GPU programming</em> estos apuntadores no apuntan a una dirección de memoria en el <em>device</em>. Aunque NVIDIA añadió el <em>feature</em> de <a class="reference external" href="https://devblogs.nvidia.com/unified-memory-cuda-beginners/">Unified Memory</a> (un espacio de memoria accesible para el <em>host</em> y el <em>device</em>) aquí no se está usando tal <em>feature</em>. Más bien se están utilizando los apuntadores anteriores para apuntar a un <a class="reference external" href="https://en.wikipedia.org/wiki/Struct_(C_programming_language)">struct</a> de <em>C</em> en el que uno de sus tipos de datos es una dirección de memoria en el <em>device</em>.</p>
<ul class="simple">
<li><p>El uso de <code class="docutils literal notranslate"><span class="pre">(void</span> <span class="pre">**)</span></code> en el <em>statement</em>  <code class="docutils literal notranslate"><span class="pre">cudaMalloc((void</span> <span class="pre">**)&amp;device_a,</span> <span class="pre">sizeof(int)*N);</span></code> es por la definición de la función <code class="docutils literal notranslate"><span class="pre">cudaMalloc</span></code>.</p></li>
<li><p>En el programa anterior se coloca en comentario que se asume que <span class="math notranslate nohighlight">\(N\)</span> el número de datos en el arreglo es menor al número de bloques que es posible lanzar. Esto como veremos más adelante es importante considerar pues aunque en un <em>device</em> se pueden lanzar muchos bloques y muchos <em>threads</em>, se tienen límites en el número de éstos que es posible lanzar.</p></li>
</ul>
</div>
</section>
<section id="perfilamiento-en-cuda">
<h3>¿Perfilamiento en CUDA?<a class="headerlink" href="#perfilamiento-en-cuda" title="Permalink to this headline">#</a></h3>
<p>Al instalar el <em>CUDA toolkit</em> en sus máquinas se instala la línea de comando <a class="reference external" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html">nvprof</a> para perfilamiento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvprof --normalized-time-unit s ./vector_sum.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0+0 = 0
1+1 = 2
2+4 = 6
3+9 = 12
4+16 = 20
5+25 = 30
6+36 = 42
7+49 = 56
8+64 = 72
9+81 = 90
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==17783== NVPROF is profiling process 17783, command: ./vector_sum.out
==17783== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.
==17783== Profiling application: ./vector_sum.out
==17783== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
                        %         s                   s         s         s
 GPU activities:    46.15  5.38e-06         1  5.38e-06  5.38e-06  5.38e-06  vect_sum(int*, int*, int*)
                    31.59  3.68e-06         2  1.84e-06  1.57e-06  2.11e-06  [CUDA memcpy HtoD]
                    22.25  2.59e-06         1  2.59e-06  2.59e-06  2.59e-06  [CUDA memcpy DtoH]
      API calls:    99.59  0.264985         3  0.088328  4.07e-06  0.264975  cudaMalloc
                     0.19  5.17e-04         1  5.17e-04  5.17e-04  5.17e-04  cuDeviceTotalMem
                     0.10  2.59e-04       101  2.57e-06  7.33e-07  8.57e-05  cuDeviceGetAttribute
                     0.06  1.58e-04         3  5.25e-05  4.71e-06  1.44e-04  cudaFree
                     0.02  6.43e-05         3  2.14e-05  1.17e-05  2.74e-05  cudaMemcpy
                     0.01  3.55e-05         1  3.55e-05  3.55e-05  3.55e-05  cudaLaunchKernel
                     0.01  2.60e-05         1  2.60e-05  2.60e-05  2.60e-05  cuDeviceGetName
                     0.00  1.05e-05         1  1.05e-05  1.05e-05  1.05e-05  cudaDeviceSynchronize
                     0.00  9.46e-06         1  9.46e-06  9.46e-06  9.46e-06  cuDeviceGetPCIBusId
                     0.00  4.01e-06         3  1.34e-06  8.12e-07  2.04e-06  cuDeviceGetCount
                     0.00  2.58e-06         2  1.29e-06  7.99e-07  1.78e-06  cuDeviceGet
                     0.00  8.94e-07         1  8.94e-07  8.94e-07  8.94e-07  cuDeviceGetUuid
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Las unidades en las que se reporta son s: second, ms: millisecond, us: microsecond, ns: nanosecond.</p></li>
<li><p>En la documentación de NVIDIA se menciona que <code class="docutils literal notranslate"><span class="pre">nvprof</span></code> será reemplazada próximamente por <a class="reference external" href="https://developer.nvidia.com/nsight-compute">NVIDIA Nsight Compute</a> y <a class="reference external" href="https://developer.nvidia.com/nsight-systems">NVIDIA Nsight Systems</a>.</p></li>
</ul>
</div>
<p>En el ejemplo anterior se lanzaron <span class="math notranslate nohighlight">\(N\)</span> bloques con <span class="math notranslate nohighlight">\(1\)</span> <em>thread</em> cada uno y a continuación se lanza <span class="math notranslate nohighlight">\(1\)</span> bloque con <span class="math notranslate nohighlight">\(N\)</span> <em>threads</em>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimGrid(1,1,1);</span></code> representa 1 bloque en el <em>grid</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">dimBlock(N,1,1);</span></code> representa N <em>threads</em> por bloque.</p>
<p><code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;dimGrid,dimBlock&gt;&gt;&gt;</span></code> 1 bloque con N <em>threads</em>.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> vector_sum_2.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#define N 10</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">vect_sum</span><span class="p">(</span><span class="nb">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="nb">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="nb">int</span> <span class="o">*</span><span class="n">c</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">thread_id_x</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">thread_id_x</span><span class="o">&lt;</span><span class="n">N</span><span class="p">)</span> 
        <span class="n">c</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">]</span><span class="o">+</span><span class="n">b</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">];</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="nb">int</span> <span class="o">*</span><span class="n">device_a</span><span class="p">,</span> <span class="o">*</span><span class="n">device_b</span><span class="p">,</span> <span class="o">*</span><span class="n">device_c</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="o">//</span><span class="n">allocation</span> <span class="ow">in</span> <span class="n">device</span> <span class="k">with</span> <span class="n">Unified</span> <span class="n">Memory</span>
    <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device_a</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device_b</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device_c</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="o">//</span><span class="n">dummy</span> <span class="n">data</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">device_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">i</span><span class="p">;</span>
        <span class="n">device_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">i</span><span class="o">*</span><span class="n">i</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">vect_sum</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">device_a</span><span class="p">,</span><span class="n">device_b</span><span class="p">,</span><span class="n">device_c</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2">+</span><span class="si">%d</span><span class="s2"> = </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">device_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">device_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">device_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_a</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_b</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_c</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing vector_sum_2.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall vector_sum_2.cu -o vector_sum_2.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvprof --normalized-time-unit s ./vector_sum_2.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0+0 = 0
1+1 = 2
2+4 = 6
3+9 = 12
4+16 = 20
5+25 = 30
6+36 = 42
7+49 = 56
8+64 = 72
9+81 = 90
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==17829== NVPROF is profiling process 17829, command: ./vector_sum_2.out
==17829== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.
==17829== Profiling application: ./vector_sum_2.out
==17829== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
                        %         s                   s         s         s
 GPU activities:   100.00  5.89e-06         1  5.89e-06  5.89e-06  5.89e-06  vect_sum(int*, int*, int*)
      API calls:    99.57  0.294598         3  0.098199  5.80e-06  0.294578  cudaMallocManaged
                     0.18  5.23e-04         1  5.23e-04  5.23e-04  5.23e-04  cuDeviceTotalMem
                     0.09  2.68e-04       101  2.65e-06  7.37e-07  9.11e-05  cuDeviceGetAttribute
                     0.09  2.62e-04         1  2.62e-04  2.62e-04  2.62e-04  cudaLaunchKernel
                     0.05  1.35e-04         3  4.50e-05  9.83e-06  1.01e-04  cudaFree
                     0.01  3.49e-05         1  3.49e-05  3.49e-05  3.49e-05  cuDeviceGetName
                     0.01  1.92e-05         1  1.92e-05  1.92e-05  1.92e-05  cudaDeviceSynchronize
                     0.00  9.34e-06         1  9.34e-06  9.34e-06  9.34e-06  cuDeviceGetPCIBusId
                     0.00  3.96e-06         3  1.32e-06  7.76e-07  1.99e-06  cuDeviceGetCount
                     0.00  2.94e-06         2  1.47e-06  9.12e-07  2.02e-06  cuDeviceGet
                     0.00  9.58e-07         1  9.58e-07  9.58e-07  9.58e-07  cuDeviceGetUuid

==17829== Unified Memory profiling result:
Device &quot;NVIDIA Tesla K80 (0)&quot;
   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name
       1  8.0000KB  8.0000KB  8.0000KB  8.000000KB  3.8720e-06s  Host To Device
       5  25.600KB  4.0000KB  60.000KB  128.0000KB  2.7422e-05s  Device To Host
Total CPU Page faults: 2
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El programa anterior utiliza la <a class="reference external" href="https://devblogs.nvidia.com/unified-memory-cuda-beginners/">Unified Memory</a> con la función <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e">cudaMallocManaged</a>. La <em>Unified Memory</em> es un <em>feature</em> que se añadió a CUDA desde las arquitecturas de <strong>Kepler</strong> y <strong>Maxwell</strong> pero que ha ido mejorando (por ejemplo añadiendo <a class="reference external" href="https://en.wikipedia.org/wiki/Page_fault">page faulting</a> and <a class="reference external" href="https://www.kernel.org/doc/html/latest/vm/page_migration.html">migration</a>) en las arquitecturas siguientes a la de <em>Kepler</em>: la arquitectura Pascal y Volta. Por esto en el <em>output</em> anterior de <em>nvprof</em> aparece una sección de <em>page fault</em>.</p></li>
<li><p>Al igual que antes, en el programa anterior se asume que <span class="math notranslate nohighlight">\(N\)</span> el número de datos en el arreglo es menor al número de <em>threads</em> que es posible lanzar. Esto como veremos más adelante es importante considerar pues aunque en el <em>device</em> se pueden lanzar muchos bloques y muchos <em>threads</em>, se tienen límites en el número de éstos que es posible lanzar.</p></li>
</ul>
</div>
</section>
<section id="tenemos-que-inicializar-los-datos-en-la-cpu-y-copiarlos-hacia-la-gpu">
<h3>¿Tenemos que inicializar los datos en la CPU y copiarlos hacia la GPU?<a class="headerlink" href="#tenemos-que-inicializar-los-datos-en-la-cpu-y-copiarlos-hacia-la-gpu" title="Permalink to this headline">#</a></h3>
<p>En realidad no tenemos que realizarlo para el ejemplo de <code class="docutils literal notranslate"><span class="pre">vector_sum_3.cu</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> vector_sum_3.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#define N 10</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">fill_arrays</span><span class="p">(</span><span class="nb">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="nb">int</span> <span class="o">*</span><span class="n">b</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">thread_id_x</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="n">a</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">]</span><span class="o">=</span><span class="n">thread_id_x</span><span class="p">;</span>
    <span class="n">b</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">]</span><span class="o">=</span><span class="n">thread_id_x</span><span class="o">*</span><span class="n">thread_id_x</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">vect_sum</span><span class="p">(</span><span class="nb">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="nb">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="nb">int</span> <span class="o">*</span><span class="n">c</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">thread_id_x</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">thread_id_x</span><span class="o">&lt;</span><span class="n">N</span><span class="p">)</span>
        <span class="n">c</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">]</span><span class="o">+</span><span class="n">b</span><span class="p">[</span><span class="n">thread_id_x</span><span class="p">];</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="nb">int</span> <span class="o">*</span><span class="n">device_a</span><span class="p">,</span> <span class="o">*</span><span class="n">device_b</span><span class="p">,</span> <span class="o">*</span><span class="n">device_c</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="o">//</span><span class="n">allocating</span> <span class="n">using</span> <span class="n">Unified</span> <span class="n">Memory</span> <span class="ow">in</span> <span class="n">device</span>
    <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device_a</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device_b</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">device_c</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">);</span>
    <span class="n">fill_arrays</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">device_a</span><span class="p">,</span><span class="n">device_b</span><span class="p">);</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">vect_sum</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">device_a</span><span class="p">,</span><span class="n">device_b</span><span class="p">,</span><span class="n">device_c</span><span class="p">);</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2">+</span><span class="si">%d</span><span class="s2"> = </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">device_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">device_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">device_c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_a</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_b</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_c</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing vector_sum_3.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall vector_sum_3.cu -o vector_sum_3.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvprof --normalized-time-unit s ./vector_sum_3.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0+0 = 0
1+1 = 2
2+4 = 6
3+9 = 12
4+16 = 20
5+25 = 30
6+36 = 42
7+49 = 56
8+64 = 72
9+81 = 90
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==17875== NVPROF is profiling process 17875, command: ./vector_sum_3.out
==17875== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.
==17875== Profiling application: ./vector_sum_3.out
==17875== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
                        %         s                   s         s         s
 GPU activities:    50.47  5.12e-06         1  5.12e-06  5.12e-06  5.12e-06  fill_arrays(int*, int*)
                    49.53  5.02e-06         1  5.02e-06  5.02e-06  5.02e-06  vect_sum(int*, int*, int*)
      API calls:    99.55  0.293179         3  0.097726  6.68e-06  0.293161  cudaMallocManaged
                     0.18  5.16e-04         1  5.16e-04  5.16e-04  5.16e-04  cuDeviceTotalMem
                     0.12  3.40e-04         2  1.70e-04  1.54e-04  1.86e-04  cudaLaunchKernel
                     0.09  2.61e-04       101  2.59e-06  7.38e-07  8.75e-05  cuDeviceGetAttribute
                     0.05  1.36e-04         3  4.53e-05  9.37e-06  1.02e-04  cudaFree
                     0.01  3.53e-05         1  3.53e-05  3.53e-05  3.53e-05  cuDeviceGetName
                     0.01  3.11e-05         2  1.55e-05  1.39e-05  1.71e-05  cudaDeviceSynchronize
                     0.00  8.34e-06         1  8.34e-06  8.34e-06  8.34e-06  cuDeviceGetPCIBusId
                     0.00  4.03e-06         3  1.34e-06  7.84e-07  2.03e-06  cuDeviceGetCount
                     0.00  2.78e-06         2  1.39e-06  9.01e-07  1.88e-06  cuDeviceGet
                     0.00  8.84e-07         1  8.84e-07  8.84e-07  8.84e-07  cuDeviceGetUuid

==17875== Unified Memory profiling result:
Device &quot;NVIDIA Tesla K80 (0)&quot;
   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name
       3  21.333KB  4.0000KB  52.000KB  64.00000KB  1.4625e-05s  Device To Host
Total CPU Page faults: 1
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="arquitectura-de-una-gpu-y-limites-en-numero-de-threads-y-bloques-que-podemos-lanzar-en-el-kernel">
<h2>Arquitectura de una GPU y límites en número de <em>threads</em> y bloques que podemos lanzar en el <em>kernel</em><a class="headerlink" href="#arquitectura-de-una-gpu-y-limites-en-numero-de-threads-y-bloques-que-podemos-lanzar-en-el-kernel" title="Permalink to this headline">#</a></h2>
<p>Un <em>device</em> está compuesto por arreglos de <strong>streaming multiprocessors SM’s</strong> (también denotados como MP’s) y en cada <em>SM</em> encontramos un número (determinado por la arquitectura del device) de <strong>streaming processors SP’s</strong> que comparten el caché y unidades de control (que están dentro de cada SM):</p>
<img src="https://dl.dropboxusercontent.com/s/oxx55upoayfmliw/SMS_CUDA.png?dl=0" heigth="700" width="700">
<p>Ver <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model">Hardware model: streamingmultiprocessor</a>.</p>
<p>En el dibujo anterior se muestran las SM’s en color rojo y los SP’s en morado. Hay dos SM’s por cada bloque anaranjado y ocho SP’s por cada SM. Así, una GPU es una máquina <em>multicore</em>. Aunque cada SM ejecuta las instrucciones de forma independiente a otra SM, comparten la <strong>memoria global</strong>.</p>
<p>Los bloques de <em>threads</em> son <strong>asignados a cada SM por el <em>CUDA runtime system</em></strong>, el cual puede asignar más de un bloque a una SM pero hay un límite de bloques que pueden ser asignados a cada SM. Ver <a class="reference external" href="https://stackoverflow.com/questions/22520209/programmatically-retrieve-maximum-number-of-blocks-per-multiprocessor">maximum number of blocks per multiprocessor</a>.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Por ejemplo para el modelo <em>GT200</em> el máximo número de bloques que podían asignarse a cada SM eran de <span class="math notranslate nohighlight">\(8\)</span> bloques. Tal modelo tenía <span class="math notranslate nohighlight">\(30\)</span> SM’s lo que resultaban en <span class="math notranslate nohighlight">\(240\)</span> bloques que en un instante podían asignarse al <em>device</em> para su ejecución simultánea (asignándose en cualquier orden en alguna SM disponible). Por supuesto que un <em>grid</em> podía contener más de <span class="math notranslate nohighlight">\(240\)</span> bloques en este modelo y en este caso el <em>CUDA runtime system</em> lleva una lista de bloques que va asignando a cada SM y conforme cada SM terminan la ejecución, nuevos bloques son asignados a tales SM que finalizaron. Para visualizar esta situación, considérese una simplificación de lo anterior en donde se tiene un <em>device</em> con <span class="math notranslate nohighlight">\(2\)</span> SM’s y con un <em>kernel</em> se han lanzado <span class="math notranslate nohighlight">\(6\)</span> bloques. El <em>CUDA runtime system</em> ha asignado <span class="math notranslate nohighlight">\(3\)</span> bloques a cada SM, entonces se tiene un dibujo como el siguiente:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/p0nu72ofmdjtck8/kernel_launch_example.png?dl=0" heigth="600" width="600">
<ul class="simple">
<li><p>Los bloques asignados a una SM comparten recursos (por ejemplo memoria) y su ejecución es independiente entre ellos, no es posible sincronizar al bloque 1 con el bloque 0. También no es posible sincronizar a los <em>threads</em> de diferentes SM’s pero sí es posible sincronizar a los <em>threads</em> dentro de un mismo bloque.</p></li>
</ul>
</div>
<section id="que-otros-limites-puedo-encontrar-en-mi-s-device-s-de-mi-sistema">
<h3>¿Qué otros límites puedo encontrar en mi(s) device(s) de mi sistema?<a class="headerlink" href="#que-otros-limites-puedo-encontrar-en-mi-s-device-s-de-mi-sistema" title="Permalink to this headline">#</a></h3>
<p>Para responder lo anterior se puede utilizar el siguiente programa que está basado en <a class="reference external" href="https://devblogs.nvidia.com/how-query-device-properties-and-handle-errors-cuda-cc/">how-query-device-properties-and-handle-errors-cuda-cc</a> y <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html">cudaDeviceProp Struct Reference</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> device_properties.cu

<span class="c1">#include&lt;stdio.h&gt;</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">cudaDeviceProp</span> <span class="n">properties</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">count</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">cudaGetDeviceCount</span><span class="p">(</span><span class="o">&amp;</span><span class="n">count</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">count</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;----------------------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
        <span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">properties</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;----device </span><span class="si">%d</span><span class="s2"> ----</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">);</span> 
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Device Name: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">name</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Compute capability: </span><span class="si">%d</span><span class="s2">.</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">major</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">minor</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Clock rate: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">clockRate</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Unified memory: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">unifiedAddressing</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot; ---Memory Information for device </span><span class="si">%d</span><span class="s2"> (results on bytes)---</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Total global mem: </span><span class="si">%ld</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">totalGlobalMem</span><span class="p">);</span> 
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Total constant Mem: </span><span class="si">%ld</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">totalConstMem</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Shared memory per thread block: </span><span class="si">%ld</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">sharedMemPerBlock</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Shared memory per SM: </span><span class="si">%ld</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">properties</span><span class="o">.</span><span class="n">sharedMemPerMultiprocessor</span> <span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot; ---MP Information for device </span><span class="si">%d</span><span class="s2"> ---</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;SM count: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">multiProcessorCount</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Threads in warp: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">warpSize</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Max threads per SM: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxThreadsPerMultiProcessor</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Max warps per SM: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">properties</span><span class="o">.</span><span class="n">maxThreadsPerMultiProcessor</span><span class="o">/</span><span class="n">properties</span><span class="o">.</span><span class="n">warpSize</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Max threads per block: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxThreadsPerBlock</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Max thread dimensions: (</span><span class="si">%d</span><span class="s2">, </span><span class="si">%d</span><span class="s2">, </span><span class="si">%d</span><span class="s2">)</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxThreadsDim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxThreadsDim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxThreadsDim</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Max grid dimensions: (</span><span class="si">%d</span><span class="s2">, </span><span class="si">%d</span><span class="s2">, </span><span class="si">%d</span><span class="s2">)</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxGridSize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxGridSize</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">properties</span><span class="o">.</span><span class="n">maxGridSize</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span> 
    <span class="p">}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
    
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing device_properties.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc --compiler-options -Wall device_properties.cu -o device_properties.out
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./device_properties.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>----------------------
----device 0 ----
Device Name: NVIDIA Tesla K80
Compute capability: 3.7
Clock rate: 823500
Unified memory: 1
 ---Memory Information for device 0 (results on bytes)---
Total global mem: 11996954624
Total constant Mem: 65536
Shared memory per thread block: 49152
Shared memory per SM: 114688
 ---MP Information for device 0 ---
SM count: 13
Threads in warp: 32
Max threads per SM: 2048
Max warps per SM: 64
Max threads per block: 1024
Max thread dimensions: (1024, 1024, 64)
Max grid dimensions: (2147483647, 65535, 65535)
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>También en la documentación oficial de NVIDIA dentro de <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">compute-capabilities</a> se pueden revisar los valores anteriores y muchos más.</p></li>
<li><p>En un <em>device</em> encontramos diferentes tipos de memoria: global, constante, <em>shared</em> y <em>texture</em>. En esta nota únicamente trabajamos con la memoria global.</p></li>
<li><p>Tenemos funciones en CUDA para poder comunicar/coordinar a los <em>threads</em> en un bloque por medio de la <em>shared memory</em>. Ver por ejemplo <a class="reference external" href="https://devblogs.nvidia.com/using-shared-memory-cuda-cc/">Using Shared Memory in CUDA C/C++</a> para un pequeño <em>post</em> del <span class="math notranslate nohighlight">\(2013\)</span> sobre <em>shared memory</em>.</p></li>
<li><p>Los bloques de <em>threads</em> que son asignados a una SM son divididos en <em><strong>warps</strong></em> que es la unidad de <em><strong>thread scheduling</strong></em> que tiene el <em>CUDA run time system</em>. El <em>output</em> anterior indica que son divisiones de <span class="math notranslate nohighlight">\(32\)</span> <em>threads</em>.</p></li>
<li><p>El <em>thread scheduling</em> se puede pensar a la funcionalidad que tiene el <em>hardware</em> del <em>device</em> para seleccionar una instrucción del programa y asginar su ejecución por los <em>threads</em> en un <em>warp</em> (<a class="reference external" href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads">SIMT</a>). Otro ejemplo es tener una instrucción que indica que se debe realizar lectura o escritura, entonces el <em>hardware</em> del <em>device</em> utiliza un <em>warp</em> de threads para tal operación mientras selecciona un <em>warp</em> de <em>threads</em> distinto para seleccionar otra instrucción diferente a la de I/O.</p></li>
<li><p>El número máximo de <em>threads</em> que pueden iniciarse de forma simultánea o en un instante por SM es de <span class="math notranslate nohighlight">\(2048\)</span> o bien <span class="math notranslate nohighlight">\(2048/32 = 64\)</span> warps.</p></li>
<li><p>El <em>output</em> anterior muestra los límites para número de bloques en las tres dimensiones de un <em>grid</em> y el número de <em>threads</em> en las tres dimensiones en un bloque.</p></li>
<li><p>Un bloque puede tener como máximo <span class="math notranslate nohighlight">\(1024\)</span> <em>threads</em> en cualquier configuración: por ejemplo <span class="math notranslate nohighlight">\((1024,1,1), (32,1,32), (4,4,64)\)</span>.</p></li>
<li><p>Por los puntos anteriores si lanzamos bloques de <span class="math notranslate nohighlight">\(1024\)</span> <em>threads</em> entonces sólo <span class="math notranslate nohighlight">\(2\)</span> bloques pueden residir en una SM en un instante. Con esta configuración alcanzaríamos <span class="math notranslate nohighlight">\(1024/32=32\)</span> <em>warps</em> por cada bloque y como lanzamos <span class="math notranslate nohighlight">\(2\)</span> bloques alcanzaríamos <span class="math notranslate nohighlight">\(64\)</span> <em>warps</em> (que es el máximo de <em>warps</em> por SM que podemos tener en un instante). Otra configuración para alcanzar el máximo número de <em>warps</em> en un instante, es considerar <span class="math notranslate nohighlight">\(4\)</span> bloques de <span class="math notranslate nohighlight">\(512\)</span> <em>threads</em> pues tendríamos <span class="math notranslate nohighlight">\(512/32=16\)</span> <em>warps</em> por bloque y en total serían <span class="math notranslate nohighlight">\(16*4\)</span> (<em>warps</em> <span class="math notranslate nohighlight">\(\times\)</span> bloques) <span class="math notranslate nohighlight">\(=64\)</span> <em>warps</em>. Entre los datos que hay que elegir en los programas de <em>CUDA C</em> se encuentran las configuraciones en el número de <em>threads</em> y el número de bloques a lanzar. La idea es alcanzar o rebasar el máximo número de <em>warps</em> en cada SM que soporta nuestro <em>device</em> en un instante.</p></li>
<li><p>Por ejemplo para el dibujo en el que se asumió que el <em>CUDA runtime system</em> había asignado <span class="math notranslate nohighlight">\(3\)</span> bloques a cada SM, se tendría una división de cada bloque en un <em>warp</em> de <span class="math notranslate nohighlight">\(32\)</span> <em>threads</em> como sigue:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/yngq4r66i2nk5mg/warp_division.png?dl=0" heigth="600" width="600">
</div>
</section>
<section id="grid-configuration-choices">
<h3><em>Grid Configuration Choices</em>?<a class="headerlink" href="#grid-configuration-choices" title="Permalink to this headline">#</a></h3>
<p>Los programas de <em>CUDA C</em> tienen la opción de elegir el número de <em>threads</em> y de <em>bloques</em> a ser lanzados. En la referencia <em>Parallel Computing for Data Science. With Examples in R, C++ and CUDA</em> de N. Matloff se enlistan algunas consideraciones para elegir tales parámetros:</p>
<ul class="simple">
<li><p><em>Given that scheduling is done on a warp basis, block size should be a multiple of the warp size (32).</em></p></li>
<li><p><em>One wants to utilize all the SMs. If one sets the block size too large, not all will be used, as a block cannot be split across SM’s.</em></p></li>
<li><p><em>…, barrier synchronization can be done effectively only at the block level. The larger the block, the more the barrier delay, so one might want smaller blocks.</em></p></li>
<li><p><em>On the other hand, if one is using shared memory, this can only be done at the block level, and efficient use may indicate using a larger block.</em></p></li>
<li><p><em>Two threads doing unrelated work, or the same work but with many if/elses, would cause a lot of thread divergence if they were in the same block. In some cases, it may be known in advance which threads will do the “ifs” and which will do the “elses”, in which case they should be placed in different blocks if possible.</em></p></li>
<li><p><em>A commonly-cited rule of thumb is to have between <span class="math notranslate nohighlight">\(128\)</span> and <span class="math notranslate nohighlight">\(256\)</span> <em>threads</em> per block.</em></p></li>
</ul>
</section>
<section id="ejemplo-regla-compuesta-del-rectangulo">
<h3>Ejemplo regla compuesta del rectángulo<a class="headerlink" href="#ejemplo-regla-compuesta-del-rectangulo" title="Permalink to this headline">#</a></h3>
<p>En el uso de CUDA se recomienda que:</p>
<ul class="simple">
<li><p><em>Users</em> escriban código de <em>CUDA C</em> simple.</p></li>
<li><p>Utilicen las librerías ya hechas por NVIDIA o terceros para mantener simplicidad y eficiencia en el código.</p></li>
</ul>
<p>Lo anterior para disminuir el tiempo y la cantidad de código que <em>users</em> tengan que hacer (o rehacer) y puesto que dominar la programación de <em>CUDA C</em> requiere una buena inversión de tiempo.</p>
<p>Así, tenemos a <a class="reference external" href="https://docs.nvidia.com/cuda/thrust/index.html">Thrust</a> una <em>template library</em> basada en la <a class="reference external" href="https://en.wikipedia.org/wiki/Standard_Template_Library">Standard Template Library (STL)</a> de C++ construída por NVIDIA que de acuerdo a su documentación:</p>
<p><em>Thrust provides a rich collection of data parallel primitives such as scan, sort, and reduce, which can be composed together to implement complex algorithms with concise, readable source code. By describing your computation in terms of these high-level abstractions you provide Thrust with the freedom to select the most efficient implementation automatically. As a result, Thrust can be utilized in rapid prototyping of CUDA applications, where programmer productivity matters most, as well as in production, where robustness and absolute performance are crucial.</em></p>
<p><em>Thrust</em> tiene la opción de utilizarse con <a class="reference external" href="https://www.openmp.org/">OpenMP</a>, <a class="reference external" href="https://www.threadingbuildingblocks.org/intel-tbb-tutorial">Thread Building Blocks (TBB)</a> y con <em>CUDA C++</em>. Ver por ejemplo <a class="reference external" href="https://github.com/thrust/thrust/wiki/Device-Backends">Device Backends</a> para conocer cómo cambiar entre <em>OpenMP</em> y <em>CUDA C++</em>, lo cual se realiza en la compilación y <strong>¡sin hacer cambios en el código!</strong>.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Al <em>software</em> que aprovecha el <em>feature</em> anterior de los sistemas computacionales (por ejemplo cambiar entre <em>OpenMP</em> y <em>CUDA C++</em>) se les nombra <a class="reference external" href="https://en.wikipedia.org/wiki/Heterogeneous_computing">Heterogeneous computing</a>.</p></li>
<li><p>Si se instala el <em>CUDA toolkit</em>, los <em>headers</em> en la librería template de <code class="docutils literal notranslate"><span class="pre">Thrust</span></code> estarán disponibles para su uso.</p></li>
</ul>
</div>
<p>En el siguiente ejemplo de la regla del rectángulo compuesta se utiliza:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.nvidia.com/cuda/thrust/index.html#reductions">Reductions</a></p></li>
<li><p>Los <em>headers</em>:</p>
<ul>
<li><p><a class="reference external" href="https://thrust.github.io/doc/structthrust_1_1device__execution__policy.html">thrust/execution_policy</a>,</p></li>
<li><p><a class="reference external" href="https://thrust.github.io/doc/group__reductions_ga43eea9a000f912716189687306884fc7.html#ga43eea9a000f912716189687306884fc7">thhrust/reduce</a>.</p></li>
</ul>
</li>
</ul>
<p>Se hace explícito el uso de la política de ejecucion <a class="reference external" href="https://thrust.github.io/doc/group__execution__policies_ga78249cb3aa4239b64e65aaf6e82ac2f8.html">thrust::device</a>.</p>
<p>Referencias para el programa siguiente se encuentran en <a class="reference external" href="https://stackoverflow.com/questions/5510715/thrust-inside-user-written-kernels">thrust inside user written kernels</a> y <a class="reference external" href="https://stackoverflow.com/questions/42525713/cuda-how-to-sum-all-elements-of-an-array-into-one-number-within-the-gpu">cuda how to sum all elements of an array into one number within the gpu</a>.</p>
<p><strong>Primero utilicemos <span class="math notranslate nohighlight">\(n=10^3\)</span> subintervalos.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span> <span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
        <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">data</span><span class="p">[</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="mf">1e3</span><span class="p">;</span> 
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf.cu -o Rcf.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 7.468241634690490e-01
Error relativo de la solución: 4.104931878976858e-08
Tiempo de cálculo en la gpu 0.00014
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvprof --normalized-time-unit s ./Rcf.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 7.468241634690490e-01
Error relativo de la solución: 4.104931878976858e-08
Tiempo de cálculo en la gpu 0.00019
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==18211== NVPROF is profiling process 18211, command: ./Rcf.out
==18211== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.
==18211== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==18211== Profiling application: ./Rcf.out
==18211== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
                        %         s                   s         s         s
 GPU activities:    97.53  1.01e-04         1  1.01e-04  1.01e-04  1.01e-04  Rcf(double*, double, double, int, double*)
                     2.47  2.56e-06         1  2.56e-06  2.56e-06  2.56e-06  [CUDA memcpy DtoH]
      API calls:    99.58  0.285237         2  0.142618  6.00e-06  0.285231  cudaMalloc
                     0.18  5.22e-04         1  5.22e-04  5.22e-04  5.22e-04  cuDeviceTotalMem
                     0.10  2.84e-04       101  2.81e-06  7.33e-07  9.81e-05  cuDeviceGetAttribute
                     0.05  1.48e-04         2  7.41e-05  9.64e-06  1.38e-04  cudaFree
                     0.04  1.08e-04         1  1.08e-04  1.08e-04  1.08e-04  cudaDeviceSynchronize
                     0.02  6.53e-05         1  6.53e-05  6.53e-05  6.53e-05  cudaLaunchKernel
                     0.01  3.28e-05         1  3.28e-05  3.28e-05  3.28e-05  cudaMemcpy
                     0.01  3.16e-05         1  3.16e-05  3.16e-05  3.16e-05  cuDeviceGetName
                     0.00  9.56e-06         1  9.56e-06  9.56e-06  9.56e-06  cuDeviceGetPCIBusId
                     0.00  4.41e-06         3  1.47e-06  7.78e-07  2.30e-06  cuDeviceGetCount
                     0.00  2.58e-06         2  1.29e-06  8.15e-07  1.76e-06  cuDeviceGet
                     0.00  9.06e-07         1  9.06e-07  9.06e-07  9.06e-07  cuDeviceGetUuid
</pre></div>
</div>
</div>
</div>
<p><strong>Incrementemos a <span class="math notranslate nohighlight">\(n=1025\)</span> subintervalos.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf2.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span> <span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
        <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">data</span><span class="p">[</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">1025</span><span class="p">;</span> 
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf2.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf2.cu -o Rcf2.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf2.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 0.000000000000000e+00
Error relativo de la solución: 1.000000000000000e+00
Tiempo de cálculo en la gpu 0.00001
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese error relativo de <span class="math notranslate nohighlight">\(100\%\)</span></p>
</div>
<p><strong>¿Cómo lo arreglamos?</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf3.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span><span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">stride</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
        <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">data</span><span class="p">[</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
        <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">+</span><span class="n">stride</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">data</span><span class="p">[</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">+</span><span class="n">stride</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_threads_per_block</span><span class="o">=</span><span class="mi">1024</span><span class="p">;</span> 
    <span class="nb">int</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">1025</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="n">n_blocks</span><span class="p">,</span><span class="n">n_threads_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf3.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf3.cu -o Rcf3.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf3.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 7.468241619918411e-01
Error relativo de la solución: 3.907133247860604e-08
Tiempo de cálculo en la gpu 0.00015
</pre></div>
</div>
</div>
</div>
<p>Pero en la propuesta anterior lanzamos <span class="math notranslate nohighlight">\(2*1024\)</span> (bloques <span class="math notranslate nohighlight">\(\times\)</span> número de <em>threads</em>) <span class="math notranslate nohighlight">\(=2048\)</span> <em>threads</em> y sólo ocupamos <span class="math notranslate nohighlight">\(1025\)</span> <em>threads</em>. Entonces podemos cambiar el código anterior para aprovechar los <span class="math notranslate nohighlight">\(2048\)</span> <em>threads</em> como sigue:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf4.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span><span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">stride</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">stride</span><span class="o">=</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span><span class="n">i</span><span class="o">+=</span><span class="n">stride</span><span class="p">){</span>
        <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
            <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
            <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_threads_per_block</span><span class="o">=</span><span class="mi">1024</span><span class="p">;</span> 
    <span class="nb">int</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="n">n_threads_per_block</span><span class="o">*</span><span class="n">n_blocks</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="n">n_blocks</span><span class="p">,</span><span class="n">n_threads_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span><span class="o">=</span><span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf4.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf4.cu -o Rcf4.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf4.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 7.468241401215338e-01
Error relativo de la solución: 9.786918140590463e-09
Tiempo de cálculo en la gpu 0.00024
</pre></div>
</div>
</div>
</div>
<p><strong>Y podemos no utilizar el ciclo <em>for</em></strong>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Para una visualización sobre la construcción del índice en el kernel utilizando <code class="docutils literal notranslate"><span class="pre">blockDim.x*blockIdx.x</span> <span class="pre">+</span> <span class="pre">threadIdx.x</span></code> ver <a class="reference external" href="https://devblogs.nvidia.com/even-easier-introduction-cuda/">An Even Easier Introduction to CUDA</a>.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf5.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span> <span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">idx</span><span class="p">;</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
        <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_threads_per_block</span><span class="o">=</span><span class="mi">1024</span><span class="p">;</span> 
    <span class="nb">int</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="n">n_blocks</span><span class="o">*</span><span class="n">n_threads_per_block</span><span class="p">;</span><span class="o">//</span><span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="n">n_blocks</span><span class="p">,</span><span class="n">n_threads_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf5.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf5.cu -o Rcf5.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf5.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 7.468241401215338e-01
Error relativo de la solución: 9.786918140590463e-09
Tiempo de cálculo en la gpu 0.00024
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvprof --normalized-time-unit s ./Rcf5.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 7.468241401215338e-01
Error relativo de la solución: 9.786918140590463e-09
Tiempo de cálculo en la gpu 0.00028
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==18401== NVPROF is profiling process 18401, command: ./Rcf5.out
==18401== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.
==18401== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==18401== Profiling application: ./Rcf5.out
==18401== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
                        %         s                   s         s         s
 GPU activities:    98.70  1.95e-04         1  1.95e-04  1.95e-04  1.95e-04  Rcf(double*, double, double, int, double*)
                     1.30  2.56e-06         1  2.56e-06  2.56e-06  2.56e-06  [CUDA memcpy DtoH]
      API calls:    99.51  0.258055         2  0.129027  4.82e-06  0.258050  cudaMalloc
                     0.20  5.14e-04         1  5.14e-04  5.14e-04  5.14e-04  cuDeviceTotalMem
                     0.10  2.58e-04       101  2.56e-06  7.36e-07  8.51e-05  cuDeviceGetAttribute
                     0.08  2.00e-04         1  2.00e-04  2.00e-04  2.00e-04  cudaDeviceSynchronize
                     0.06  1.49e-04         2  7.45e-05  9.64e-06  1.39e-04  cudaFree
                     0.03  6.99e-05         1  6.99e-05  6.99e-05  6.99e-05  cudaLaunchKernel
                     0.01  3.26e-05         1  3.26e-05  3.26e-05  3.26e-05  cudaMemcpy
                     0.01  2.71e-05         1  2.71e-05  2.71e-05  2.71e-05  cuDeviceGetName
                     0.00  9.56e-06         1  9.56e-06  9.56e-06  9.56e-06  cuDeviceGetPCIBusId
                     0.00  4.23e-06         3  1.41e-06  9.18e-07  2.18e-06  cuDeviceGetCount
                     0.00  2.52e-06         2  1.26e-06  8.01e-07  1.72e-06  cuDeviceGet
                     0.00  9.07e-07         1  9.07e-07  9.07e-07  9.07e-07  cuDeviceGetUuid
</pre></div>
</div>
</div>
</div>
<p><strong>Utilicemos más nodos.</strong></p>
<p>Para el siguiente código, incrementamos el número de bloques.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf6.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span> <span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">idx</span><span class="p">;</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
        <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_threads_per_block</span><span class="o">=</span><span class="mi">1024</span><span class="p">;</span> 
    <span class="nb">int</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaDeviceProp</span> <span class="n">properties</span><span class="p">;</span>
    <span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">properties</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="o">//</span><span class="n">we</span> <span class="n">choose</span> <span class="n">a</span> <span class="n">multiple</span> <span class="n">of</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">SMs</span><span class="o">.</span>
    <span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">256</span> <span class="o">*</span> <span class="n">properties</span><span class="o">.</span><span class="n">multiProcessorCount</span><span class="p">;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n_blocks</span><span class="o">*</span><span class="n">n_threads_per_block</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="n">n_blocks</span><span class="p">,</span><span class="n">n_threads_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Número de subintervalos: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf6.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf6.cu -o Rcf6.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Mientras se ejecuta la siguiente celda se sugiere en la terminal ejecutar en la línea de comando <code class="docutils literal notranslate"><span class="pre">nvtop</span></code>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf6.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número de subintervalos: 3407872
Integral de 0.000000 a 1.000000 = 7.468241328124654e-01
Error relativo de la solución: 5.128743524305478e-14
Tiempo de cálculo en la gpu 0.42854
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvprof --normalized-time-unit s ./Rcf6.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número de subintervalos: 3407872
Integral de 0.000000 a 1.000000 = 7.468241328124654e-01
Error relativo de la solución: 5.128743524305478e-14
Tiempo de cálculo en la gpu 0.38611
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==18515== NVPROF is profiling process 18515, command: ./Rcf6.out
==18515== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.
==18515== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==18515== Profiling application: ./Rcf6.out
==18515== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
                        %         s                   s         s         s
 GPU activities:   100.00  0.386719         1  0.386719  0.386719  0.386719  Rcf(double*, double, double, int, double*)
                     0.00  3.23e-06         1  3.23e-06  3.23e-06  3.23e-06  [CUDA memcpy DtoH]
      API calls:    58.94  0.386743         1  0.386743  0.386743  0.386743  cudaDeviceSynchronize
                    40.45  0.265420         2  0.132710  1.41e-04  0.265279  cudaMalloc
                     0.43  2.85e-03         2  1.43e-03  2.51e-04  2.60e-03  cudaFree
                     0.08  5.46e-04         1  5.46e-04  5.46e-04  5.46e-04  cuDeviceTotalMem
                     0.04  2.65e-04       101  2.62e-06  7.41e-07  8.77e-05  cuDeviceGetAttribute
                     0.03  1.72e-04         1  1.72e-04  1.72e-04  1.72e-04  cudaGetDeviceProperties
                     0.01  7.08e-05         1  7.08e-05  7.08e-05  7.08e-05  cudaMemcpy
                     0.01  6.56e-05         1  6.56e-05  6.56e-05  6.56e-05  cudaLaunchKernel
                     0.00  2.80e-05         1  2.80e-05  2.80e-05  2.80e-05  cuDeviceGetName
                     0.00  8.45e-06         1  8.45e-06  8.45e-06  8.45e-06  cuDeviceGetPCIBusId
                     0.00  4.07e-06         3  1.36e-06  7.75e-07  2.08e-06  cuDeviceGetCount
                     0.00  2.56e-06         2  1.28e-06  8.00e-07  1.76e-06  cuDeviceGet
                     0.00  9.30e-07         1  9.30e-07  9.30e-07  9.30e-07  cuDeviceGetUuid
</pre></div>
</div>
</div>
</div>
<p><strong>Incrementamos el número de subintervalos.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf7.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span> <span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">idx</span><span class="p">;</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
        <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_threads_per_block</span><span class="o">=</span><span class="mi">512</span><span class="p">;</span> 
    <span class="nb">int</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaDeviceProp</span> <span class="n">properties</span><span class="p">;</span>
    <span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">properties</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">1500</span> <span class="o">*</span> <span class="n">properties</span><span class="o">.</span><span class="n">multiProcessorCount</span><span class="p">;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n_blocks</span><span class="o">*</span><span class="n">n_threads_per_block</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="n">n_blocks</span><span class="p">,</span><span class="n">n_threads_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">)</span> <span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Número de subintervalos: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>    
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf7.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf7.cu -o Rcf7.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Mientras se ejecuta la siguiente celda se sugiere en la terminal ejecutar en la línea de comando <code class="docutils literal notranslate"><span class="pre">nvtop</span></code>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf7.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número de subintervalos: 9984000
Integral de 0.000000 a 1.000000 = 7.468241328124303e-01
Error relativo de la solución: 4.311117745068373e-15
Tiempo de cálculo en la gpu 1.10993
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvprof --normalized-time-unit s ./Rcf7.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número de subintervalos: 9984000
Integral de 0.000000 a 1.000000 = 7.468241328124303e-01
Error relativo de la solución: 4.311117745068373e-15
Tiempo de cálculo en la gpu 1.12291
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==18755== NVPROF is profiling process 18755, command: ./Rcf7.out
==18755== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.
==18755== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==18755== Profiling application: ./Rcf7.out
==18755== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
                        %         s                   s         s         s
 GPU activities:   100.00  1.121829         1  1.121829  1.121829  1.121829  Rcf(double*, double, double, int, double*)
                     0.00  2.24e-06         1  2.24e-06  2.24e-06  2.24e-06  [CUDA memcpy DtoH]
      API calls:    80.22  1.121856         1  1.121856  1.121856  1.121856  cudaDeviceSynchronize
                    19.21  0.268620         2  0.134310  1.46e-04  0.268474  cudaMalloc
                     0.49  6.86e-03         2  3.43e-03  2.98e-04  6.56e-03  cudaFree
                     0.04  5.16e-04         1  5.16e-04  5.16e-04  5.16e-04  cuDeviceTotalMem
                     0.02  2.75e-04       101  2.72e-06  7.35e-07  9.35e-05  cuDeviceGetAttribute
                     0.01  1.89e-04         1  1.89e-04  1.89e-04  1.89e-04  cudaGetDeviceProperties
                     0.01  8.55e-05         1  8.55e-05  8.55e-05  8.55e-05  cudaLaunchKernel
                     0.00  6.15e-05         1  6.15e-05  6.15e-05  6.15e-05  cudaMemcpy
                     0.00  3.98e-05         1  3.98e-05  3.98e-05  3.98e-05  cuDeviceGetName
                     0.00  9.34e-06         1  9.34e-06  9.34e-06  9.34e-06  cuDeviceGetPCIBusId
                     0.00  3.96e-06         3  1.32e-06  7.68e-07  1.83e-06  cuDeviceGetCount
                     0.00  2.41e-06         2  1.20e-06  7.43e-07  1.67e-06  cuDeviceGet
                     0.00  9.00e-07         1  9.00e-07  9.00e-07  9.00e-07  cuDeviceGetUuid
</pre></div>
</div>
</div>
</div>
<p><strong>Incrementamos el número de subintervalos.</strong></p>
<p id="rcf8cu"><code class="docutils literal notranslate"><span class="pre">Rcf8.cu</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf8.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="n">long</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span> <span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">idx</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">num_threads</span><span class="o">=</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">num_threads</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="n">idx</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span> <span class="n">i</span><span class="o">+=</span><span class="n">stride</span><span class="p">){</span>
        <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
            <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
            <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
        <span class="p">}</span>
<span class="p">}</span>
    
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">cudaError_t</span> <span class="n">check_error</span><span class="p">(</span><span class="n">cudaError_t</span> <span class="n">result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">result</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s2">&quot;Error: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">result</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_threads_per_block</span><span class="o">=</span><span class="mi">1024</span><span class="p">;</span> 
    <span class="n">long</span> <span class="nb">int</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> 
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="n">long</span> <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> 
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaDeviceProp</span> <span class="n">properties</span><span class="p">;</span>    
    <span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">properties</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">100000</span> <span class="o">*</span> <span class="n">properties</span><span class="o">.</span><span class="n">multiProcessorCount</span><span class="p">;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n_blocks</span><span class="o">*</span><span class="n">n_threads_per_block</span><span class="p">;</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">n_threads_per_block</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">check_error</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">));</span>
    <span class="n">check_error</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">check_error</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">));</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Número de subintervalos: </span><span class="si">%ld</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>    
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf8.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf8.cu -o Rcf8.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf8.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número de subintervalos: 1331200000
Integral de 0.000000 a 1.000000 = 7.468241328124491e-01
Error relativo de la solución: 2.943452805253579e-14
Tiempo de cálculo en la gpu 130.57445
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>En la programación con CUDA-C es importante checar posibles errores de alojamiento de memoria. Una forma es con los tipos <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6">cudaError_t</a> y <code class="docutils literal notranslate"><span class="pre">cudaSuccess</span></code> . Ver <a class="reference external" href="https://stackoverflow.com/questions/58902166/why-do-i-have-insufficient-buffer-space-when-i-put-allocation-code-in-a-functi">why-do-i-have-insufficient-buffer-space-when-i-put-allocation-code-in-a-functi</a>.</p>
</div>
<p><strong>Incrementamos el número de subintervalos.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%file</span> Rcf9.cu
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include &lt;thrust/reduce.h&gt;</span>
<span class="c1">#include &lt;thrust/execution_policy.h&gt;</span>

<span class="n">__global__</span> <span class="n">void</span> <span class="n">Rcf</span><span class="p">(</span><span class="n">double</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="n">long</span> <span class="nb">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">double</span> <span class="o">*</span><span class="n">sum_res</span> <span class="p">)</span> <span class="p">{</span>
    <span class="o">/*</span>
    <span class="n">Compute</span> <span class="n">numerical</span> <span class="n">approximation</span> <span class="n">using</span> <span class="n">rectangle</span> <span class="ow">or</span> <span class="n">mid</span><span class="o">-</span><span class="n">point</span> <span class="n">method</span> <span class="ow">in</span> 
    <span class="n">an</span> <span class="n">interval</span><span class="o">.</span>
    <span class="n">Nodes</span> <span class="n">are</span> <span class="n">generated</span> <span class="n">via</span> <span class="n">formula</span><span class="p">:</span> <span class="n">x_i</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="n">h_hat</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">Args</span><span class="p">:</span>
        <span class="n">data</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">array</span> <span class="n">that</span> <span class="n">will</span> <span class="n">hold</span> <span class="n">values</span> <span class="n">evaluated</span> <span class="ow">in</span> <span class="n">function</span>
        <span class="n">a</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">left</span> <span class="n">point</span> <span class="n">of</span> <span class="n">interval</span>
        <span class="n">h_hat</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">width</span> <span class="n">of</span> <span class="n">subinterval</span>    
        <span class="n">n</span> <span class="p">(</span><span class="nb">int</span><span class="p">):</span> <span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>    
    <span class="n">Returns</span><span class="p">:</span>
        <span class="n">sum_res</span> <span class="p">(</span><span class="n">double</span><span class="p">):</span> <span class="n">pointer</span> <span class="n">to</span> <span class="n">result</span>
    <span class="o">*/</span>
    <span class="n">double</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">idx</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">num_threads</span><span class="o">=</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">num_threads</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="n">idx</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span> <span class="n">i</span><span class="o">+=</span><span class="n">stride</span><span class="p">){</span>
        <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">&lt;=</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">){</span>
            <span class="n">x</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
            <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span><span class="n">std</span><span class="p">::</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">std</span><span class="p">::</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
        <span class="p">}</span>
<span class="p">}</span>
    
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span><span class="o">==</span><span class="mi">0</span><span class="p">){</span>
        <span class="o">*</span><span class="n">sum_res</span> <span class="o">=</span> <span class="n">thrust</span><span class="p">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">thrust</span><span class="p">::</span><span class="n">device</span><span class="p">,</span> <span class="n">data</span> <span class="p">,</span> <span class="n">data</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span> <span class="n">thrust</span><span class="p">::</span><span class="n">plus</span><span class="o">&lt;</span><span class="n">double</span><span class="o">&gt;</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">cudaError_t</span> <span class="n">check_error</span><span class="p">(</span><span class="n">cudaError_t</span> <span class="n">result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">result</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s2">&quot;Error: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">result</span><span class="p">));</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[]){</span>
    <span class="n">double</span> <span class="n">sum_res</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_data</span><span class="p">;</span>
    <span class="n">double</span> <span class="o">*</span><span class="n">d_sum</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">h_hat</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_threads_per_block</span><span class="o">=</span><span class="mi">1024</span><span class="p">;</span> 
    <span class="n">long</span> <span class="nb">int</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> 
    <span class="n">double</span> <span class="n">obj</span><span class="o">=</span><span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="n">long</span> <span class="nb">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> 
    <span class="n">double</span> <span class="n">time_spent</span><span class="p">;</span>
    <span class="n">clock_t</span> <span class="n">begin</span><span class="p">,</span><span class="n">end</span><span class="p">;</span>
    <span class="n">cudaDeviceProp</span> <span class="n">properties</span><span class="p">;</span>    
    <span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">properties</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">150000</span> <span class="o">*</span> <span class="n">properties</span><span class="o">.</span><span class="n">multiProcessorCount</span><span class="p">;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n_blocks</span><span class="o">*</span><span class="n">n_threads_per_block</span><span class="p">;</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">n_threads_per_block</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">check_error</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_data</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">));</span>
    <span class="n">check_error</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_sum</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">)));</span>
    <span class="n">h_hat</span><span class="o">=</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">Rcf</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d_sum</span><span class="p">);</span> 
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
    <span class="n">time_spent</span> <span class="o">=</span> <span class="p">(</span><span class="n">double</span><span class="p">)(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
    <span class="n">check_error</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sum_res</span><span class="p">,</span> <span class="n">d_sum</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">));</span>
    <span class="n">sum_res</span><span class="o">=</span><span class="n">h_hat</span><span class="o">*</span><span class="n">sum_res</span><span class="p">;</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_data</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_sum</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Número de subintervalos: </span><span class="si">%ld</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>    
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_res</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_res</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de cálculo en la gpu </span><span class="si">%.5f</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">time_spent</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing Rcf9.cu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
source ~/.profile
nvcc -gencode arch=compute_37,code=sm_37 --compiler-options -Wall Rcf9.cu -o Rcf9.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nvcc warning : The &#39;compute_35&#39;, &#39;compute_37&#39;, &#39;compute_50&#39;, &#39;sm_35&#39;, &#39;sm_37&#39; and &#39;sm_50&#39; architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./Rcf9.out
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número de subintervalos: 1996800000
Integral de 0.000000 a 1.000000 = 0.000000000000000e+00
Error relativo de la solución: 1.000000000000000e+00
Tiempo de cálculo en la gpu 0.06584
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Error: out of memory
Error: an illegal memory access was encountered
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Ejercicio</p>
<p>Implementar la regla de Simpson compuesta con <em>CUDA-C</em> en una máquina de AWS con las mismas características que la que se presenta en esta nota y medir tiempo de ejecución.</p>
</div>
</section>
</section>
<section id="cupy">
<h2><a class="reference external" href="https://github.com/cupy/cupy">CuPy</a><a class="headerlink" href="#cupy" title="Permalink to this headline">#</a></h2>
<p><em>NumPy-like API accelerated with CUDA. CuPy is an implementation of NumPy-compatible multi-dimensional array on CUDA. CuPy consists of the core multi-dimensional array class, cupy.ndarray, and many functions on it. It supports a subset of numpy.ndarray interface.</em></p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/tutorial/basic.html">Basics of CuPy</a>.</p>
</aside>
<p>Un subconjunto de funciones del paquete <em>NumPy</em> de <em>Python</em> están implementadas en <em>CuPy</em> vía la clase <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/reference/generated/cupy.ndarray.html#cupy.ndarray">cupy.ndarray</a> la cual es compatible en la GPU con la clase <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray">numpy.ndarray</a> que utiliza la CPU.</p>
<section id="arrays">
<h3><em>Arrays</em><a class="headerlink" href="#arrays" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cupy</span> <span class="k">as</span> <span class="nn">cp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Y el <em>array</em> <span class="math notranslate nohighlight">\(1\)</span>-dimensional anterior está alojado en la GPU.</p>
<p>Podemos obtener información del <em>array</em> anterior utilizando algunos métodos y atributos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_gpu.ndim:&#39;</span><span class="p">,</span><span class="n">x_gpu</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_gpu.shape:&#39;</span><span class="p">,</span><span class="n">x_gpu</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_gpu.size:&#39;</span><span class="p">,</span><span class="n">x_gpu</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_gpu.dtype:&#39;</span><span class="p">,</span><span class="n">x_gpu</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x_gpu.ndim: 1
x_gpu.shape: (3,)
x_gpu.size: 3
x_gpu.dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Accedemos con corchetes a sus componentes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;primer elemento&#39;</span><span class="p">,</span> <span class="n">x_gpu</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;último elemento&#39;</span><span class="p">,</span> <span class="n">x_gpu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;segundo elemento&#39;</span><span class="p">,</span> <span class="n">x_gpu</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;penúltimo elemento&#39;</span><span class="p">,</span> <span class="n">x_gpu</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;del primero al 2º elemento incluyendo este último&#39;</span><span class="p">,</span> <span class="n">x_gpu</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;del 2º al último elemento sin incluir el 2º&#39;</span><span class="p">,</span> <span class="n">x_gpu</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>primer elemento 1
último elemento 3
segundo elemento 2
penúltimo elemento 2
del primero al 2º elemento incluyendo este último [1 2]
del 2º al último elemento sin incluir el 2º [3]
</pre></div>
</div>
</div>
</div>
<p>A diferencia de <em>NumPy</em> que nos devuelve un error al ejecutar.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_cpu</span><span class="p">[[</span><span class="mi">3</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">IndexError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">7</span><span class="o">-</span><span class="mi">78</span><span class="n">c8861b3dfe</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="nb">print</span><span class="p">(</span><span class="n">x_cpu</span><span class="p">[[</span><span class="mi">3</span><span class="p">]])</span>

<span class="ne">IndexError</span>: index 3 is out of bounds for axis 0 with size 3
</pre></div>
</div>
</div>
</div>
<p>Con <em>CuPy</em> se reciclan los índices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">[[</span><span class="mi">3</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1]
</pre></div>
</div>
</div>
</div>
<p>Otra forma de generar <em>arrays</em> en <em>NumPy</em> es con la función <a class="reference external" href="https://docs.cupy.dev/en/stable/reference/generated/cupy.arange.html">arange</a> o <a class="reference external" href="https://docs.cupy.dev/en/stable/reference/random.html">random</a> para un <em>array</em> pseudo aleatorio.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0 1 2]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.59640368 0.42459851 0.15535147 0.95573683]
</pre></div>
</div>
</div>
</div>
<p><strong><em>Array</em>’s dos dimensionales.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[1 2 3]
 [4 5 6]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A.ndim:&#39;</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A.shape:&#39;</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A.size:&#39;</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A.dtype&#39;</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A.ndim: 2
A.shape: (2, 3)
A.size: 6
A.dtype int64
</pre></div>
</div>
</div>
</div>
<p>Accedemos con corchetes a sus componentes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;elemento en la posición (0,0):&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;elemento en la posición (1,2):&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
<span class="c1">#also with:</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;elemento en la posición (0,0):&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;elemento en la posición (1,2):&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>elemento en la posición (0,0): 1
elemento en la posición (1,2): 6
elemento en la posición (0,0): 1
elemento en la posición (1,2): 6
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;primer columna:&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;tercer columna:&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[:,</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;segundo renglón:&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">,:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>primer columna: [1 4]
tercer columna: [3 6]
segundo renglón: [4 5 6]
</pre></div>
</div>
</div>
</div>
<p>Funciones <code class="docutils literal notranslate"><span class="pre">arange</span></code> o <code class="docutils literal notranslate"><span class="pre">random</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.2</span><span class="p">,</span><span class="mf">.2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0 1 2]
 [3 4 5]]
[[0.  0.2]
 [0.4 0.6]
 [0.8 1. ]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0.59640368 0.42459851 0.15535147 0.95573683]
 [0.97054217 0.68966838 0.72790884 0.12783432]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="operaciones-en-el-algebra-lineal-con-cupy">
<h3>Operaciones en el álgebra lineal con CuPy<a class="headerlink" href="#operaciones-en-el-algebra-lineal-con-cupy" title="Permalink to this headline">#</a></h3>
</section>
<section id="producto-escalar-vector-suma-y-punto-entre-vectores">
<h3>Producto escalar-vector, suma y punto entre vectores<a class="headerlink" href="#producto-escalar-vector-suma-y-punto-entre-vectores" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v1</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">scalar</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">scalar</span><span class="o">*</span><span class="n">v1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-3.   1.5 -2. ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">v1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>9
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">v1</span><span class="o">+</span><span class="n">v2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[10  2  4]
</pre></div>
</div>
</div>
</div>
</section>
<section id="producto-matriz-vector-point-wise">
<h3>Producto matriz vector <em>point-wise</em><a class="headerlink" href="#producto-matriz-vector-point-wise" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 2  5  0]
 [ 3  6  6]
 [-6  4 -1]
 [ 5  4  9]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-2  1  4]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">*</span><span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ -4   5   0]
 [ -6   6  24]
 [ 12   4  -4]
 [-10   4  36]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="producto-matriz-vector">
<h3>Producto matriz-vector<a class="headerlink" href="#producto-matriz-vector" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 2  5  0]
 [ 3  6  6]
 [-6  4 -1]
 [ 5  4  9]]
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese que las clases de los objetos deben ser del mismo tipo.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-2  1  4]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">28</span><span class="o">-</span><span class="mi">1</span><span class="n">b54d307edad</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>

<span class="ne">TypeError</span>: Argument &#39;b&#39; has incorrect type (expected cupy._core.core.ndarray, got numpy.ndarray)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-2  1  4]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 1 24 12 30]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="nd">@v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 1 24 12 30]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 7  0 -3  2]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="nd">@A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[42 31 21]
</pre></div>
</div>
</div>
</div>
</section>
<section id="suma-y-producto-matriz-matriz-pointwise">
<h3>Suma y producto matriz-matriz pointwise<a class="headerlink" href="#suma-y-producto-matriz-matriz-pointwise" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 2  5  0]
 [ 3  6  6]
 [-6  4 -1]
 [ 5  4  9]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 2 -2  3]
 [ 1 -1  5]
 [ 0 -2  1]
 [ 0  0 -3]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">+</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 4  3  3]
 [ 4  5 11]
 [-6  2  0]
 [ 5  4  6]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">*</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[  4 -10   0]
 [  3  -6  30]
 [  0  -8  -1]
 [  0   0 -27]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="producto-matriz-matriz">
<h3>Producto matriz-matriz<a class="headerlink" href="#producto-matriz-matriz" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 2  5  0]
 [ 3  6  6]
 [-6  4 -1]
 [ 5  4  9]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 2 -2  3]
 [ 1 -1  5]
 [ 0 -2  1]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="nd">@B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[  9  -9  31]
 [ 12 -24  45]
 [ -8  10   1]
 [ 14 -32  44]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="algunas-operaciones-basicas-del-algebra-lineal">
<h3>Algunas operaciones básicas del álgebra lineal<a class="headerlink" href="#algunas-operaciones-basicas-del-algebra-lineal" title="Permalink to this headline">#</a></h3>
</section>
<section id="norma-de-vectores">
<h3>Norma de vectores<a class="headerlink" href="#norma-de-vectores" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1 2 3]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.7416573867739413
</pre></div>
</div>
</div>
</div>
</section>
<section id="norma-de-matrices">
<h3>Norma de matrices<a class="headerlink" href="#norma-de-matrices" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 2  5  0]
 [ 3  6  6]
 [-6  4 -1]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12.767145334803704
</pre></div>
</div>
</div>
</div>
</section>
<section id="resolver-sistema-de-ecuaciones-lineales">
<h3>Resolver sistema de ecuaciones lineales<a class="headerlink" href="#resolver-sistema-de-ecuaciones-lineales" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="o">-</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">28</span><span class="p">,</span><span class="o">-</span><span class="mi">40</span><span class="p">,</span><span class="mi">33</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A:
[[ 8 -6  2]
 [-4 11 -7]
 [ 4 -7  6]]
b:
[ 28 -40  33]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x:
[ 2. -1.  3.]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Verificando resultado Ax = b&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Ax:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="nd">@x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Verificando resultado Ax = b
b:
[ 28 -40  33]
Ax:
[ 28. -40.  33.]
</pre></div>
</div>
</div>
</div>
</section>
<section id="transferencia-de-datos-del-host-al-device-o-viceversa">
<h3>Transferencia de datos del <em>host</em> al <em>device</em> o viceversa<a class="headerlink" href="#transferencia-de-datos-del-host-al-device-o-viceversa" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">x_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_cpu</span><span class="p">)</span>  <span class="c1"># move the data to the current device.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1 2 3]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;cupy._core.core.ndarray&#39;&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># create an array in the current device</span>
<span class="n">x_cpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">)</span>  <span class="c1"># move the array to the host.</span>
</pre></div>
</div>
</div>
</div>
<p>Y estas funciones pueden utilizarse para realizar operaciones dependiendo del tipo de <em>array</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_gpu</span> <span class="o">+</span> <span class="n">y_cpu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">55</span><span class="o">-</span><span class="n">e0e7324dadac</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="nb">print</span><span class="p">(</span><span class="n">x_gpu</span> <span class="o">+</span> <span class="n">y_cpu</span><span class="p">)</span>

<span class="nn">cupy/_core/core.pyx</span> in <span class="ni">cupy._core.core.ndarray.__add__</span><span class="nt">()</span>

<span class="nn">cupy/_core/core.pyx</span> in <span class="ni">cupy._core.core.ndarray.__array_ufunc__</span><span class="nt">()</span>

<span class="nn">cupy/_core/_kernel.pyx</span> in <span class="ni">cupy._core._kernel.ufunc.__call__</span><span class="nt">()</span>

<span class="nn">cupy/_core/_kernel.pyx</span> in <span class="ni">cupy._core._kernel._preprocess_args</span><span class="nt">()</span>

<span class="ne">TypeError</span>: Unsupported type &lt;class &#39;numpy.ndarray&#39;&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_gpu</span> <span class="o">+</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_cpu</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 6  8 10]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">)</span> <span class="o">+</span> <span class="n">y_cpu</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 6  8 10]
</pre></div>
</div>
</div>
</div>
</section>
<section id="funcion-ejecutada-dependiendo-de-que-sean-array-s-de-numpy-o-cupy">
<h3>Función ejecutada dependiendo de que sean <em>array</em>’s de <em>NumPy</em> o <em>CuPy</em><a class="headerlink" href="#funcion-ejecutada-dependiendo-de-que-sean-array-s-de-numpy-o-cupy" title="Permalink to this headline">#</a></h3>
<p>Es posible ejecutar una función dependiendo de sus argumentos con el módulo <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/reference/generated/cupy.get_array_module.html#cupy.get_array_module">get_array_module</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">xp</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">xp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">xp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">fun</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1.03424619 0.74963557 1.03984615]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">fun</span><span class="p">(</span><span class="n">x_cpu</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1.03424619 0.74963557 1.03984615]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h3>Ejemplo regla compuesta del rectángulo<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f_cp</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">cp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Rcf_cupy</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute numerical approximation using rectangle or mid-point</span>
<span class="sd">    method in an interval.</span>
<span class="sd">    Nodes are generated via formula: x_i = a+(i+1/2)h_hat for</span>
<span class="sd">    i=0,1,...,n-1 and h_hat=(b-a)/n</span>
<span class="sd">    Args:</span>
<span class="sd">    </span>
<span class="sd">        f (float): function expression of integrand.</span>
<span class="sd">        </span>
<span class="sd">        a (float): left point of interval.</span>
<span class="sd">        </span>
<span class="sd">        b (float): right point of interval.</span>
<span class="sd">        </span>
<span class="sd">        n (int): number of subintervals.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">    </span>
<span class="sd">        sum_res (float): numerical approximation to integral</span>
<span class="sd">            of f in the interval a,b</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">h_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">aux_vec</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">nodes</span> <span class="o">=</span> <span class="p">(</span><span class="n">aux_vec</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">aux_vec</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">/</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">h_hat</span><span class="o">*</span><span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">nodes</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">from</span> <span class="nn">pytest</span> <span class="kn">import</span> <span class="n">approx</span>
<span class="kn">from</span> <span class="nn">scipy.integrate</span> <span class="kn">import</span> <span class="n">quad</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">7</span>
<span class="n">a</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="c1">#using math library</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">obj</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">quad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_cupy</span> <span class="o">=</span> <span class="n">Rcf_cupy</span><span class="p">(</span><span class="n">f_cp</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">res_cupy</span><span class="o">.</span><span class="n">get</span><span class="p">()</span> <span class="o">==</span> <span class="n">approx</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cupyx.time</span> <span class="kn">import</span> <span class="n">repeat</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="n">Rcf_cupy</span><span class="p">,</span> <span class="p">(</span><span class="n">f_cp</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">n</span><span class="p">),</span> <span class="n">n_repeat</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/ubuntu/.local/lib/python3.8/site-packages/cupyx/time.py:115: FutureWarning: cupyx.time.repeat is experimental. The interface can change in the future.
  _util.experimental(&#39;cupyx.time.repeat&#39;)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Rcf_cupy            :    CPU:  379.885 us   +/-64.506 (min:  328.881 / max:  543.411) us     GPU-0:21021.779 us   +/-768.554 (min:19397.568 / max:22042.303) us
</pre></div>
</div>
</div>
</div>
<p>Ver <a class="reference external" href="https://docs.cupy.dev/en/stable/user_guide/performance.html">performance</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese que se utiliza mayor cantidad de memoria por <em>CuPy</em> que utilizando la implementación con <em>CUDA-C</em> <a class="reference internal" href="#rcf8cu"><span class="std std-ref">Rcf8.cu</span></a>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">9</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="n">Rcf_cupy</span><span class="p">,</span> <span class="p">(</span><span class="n">f_cp</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">n</span><span class="p">),</span> <span class="n">n_repeat</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/ubuntu/.local/lib/python3.8/site-packages/cupyx/time.py:115: FutureWarning: cupyx.time.repeat is experimental. The interface can change in the future.
  _util.experimental(&#39;cupyx.time.repeat&#39;)
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NVRTCError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="nn">~/.local/lib/python3.8/site-packages/cupy/cuda/compiler.py</span> in <span class="ni">compile</span><span class="nt">(self, options, log_stream)</span>
<span class="g g-Whitespace">    </span><span class="mi">622</span>                     <span class="n">nvrtc</span><span class="o">.</span><span class="n">addAddNameExpression</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ptr</span><span class="p">,</span> <span class="n">ker</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">623</span>             <span class="n">nvrtc</span><span class="o">.</span><span class="n">compileProgram</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ptr</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">624</span>             <span class="n">mapping</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">cupy_backends/cuda/libs/nvrtc.pyx</span> in <span class="ni">cupy_backends.cuda.libs.nvrtc.compileProgram</span><span class="nt">()</span>

<span class="nn">cupy_backends/cuda/libs/nvrtc.pyx</span> in <span class="ni">cupy_backends.cuda.libs.nvrtc.compileProgram</span><span class="nt">()</span>

<span class="nn">cupy_backends/cuda/libs/nvrtc.pyx</span> in <span class="ni">cupy_backends.cuda.libs.nvrtc.check_status</span><span class="nt">()</span>

<span class="ne">NVRTCError</span>: NVRTC_ERROR_COMPILATION (6)

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">CompileException</span><span class="g g-Whitespace">                          </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">6</span><span class="o">-</span><span class="mi">33</span><span class="n">ae1eff6e88</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="nb">print</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="n">Rcf_cupy</span><span class="p">,</span> <span class="p">(</span><span class="n">f_cp</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">n</span><span class="p">),</span> <span class="n">n_repeat</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupyx/time.py</span> in <span class="ni">repeat</span><span class="nt">(func, args, kwargs, n_repeat, name, n_warmup, max_duration, devices)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`devices` should be of tuple type&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span> 
<span class="ne">--&gt; </span><span class="mi">139</span>     <span class="k">return</span> <span class="n">_repeat</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>         <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">n_repeat</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">n_warmup</span><span class="p">,</span> <span class="n">max_duration</span><span class="p">,</span> <span class="n">devices</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">141</span> 

<span class="nn">~/.local/lib/python3.8/site-packages/cupyx/time.py</span> in <span class="ni">_repeat</span><span class="nt">(func, args, kwargs, n_repeat, name, n_warmup, max_duration, devices)</span>
<span class="g g-Whitespace">    </span><span class="mi">156</span> 
<span class="g g-Whitespace">    </span><span class="mi">157</span>     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_warmup</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">158</span>         <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span> 
<span class="g g-Whitespace">    </span><span class="mi">160</span>     <span class="k">for</span> <span class="n">event</span><span class="p">,</span> <span class="n">device</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">events_1</span><span class="p">,</span> <span class="n">devices</span><span class="p">):</span>

<span class="nn">&lt;ipython-input-3-417a01c1f5d1&gt;</span> in <span class="ni">Rcf_cupy</span><span class="nt">(f, a, b, n)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>     <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span><span class="s2">     h_hat = (b-a)/n</span>
<span class="ne">---&gt; </span><span class="mi">23</span><span class="s2">     aux_vec = cp.linspace(a, b, n+1)</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span><span class="s2">     nodes = (aux_vec[:-1]+aux_vec[1:])/2</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span><span class="s2">     return h_hat*cp.sum(f(nodes))</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupy/_creation/ranges.py</span> in <span class="ni">linspace</span><span class="nt">(start, stop, num, endpoint, retstep, dtype, axis)</span>
<span class="g g-Whitespace">    </span><span class="mi">156</span><span class="s2">     scalar_stop = cupy.isscalar(stop)</span>
<span class="g g-Whitespace">    </span><span class="mi">157</span><span class="s2">     if scalar_start and scalar_stop:</span>
<span class="ne">--&gt; </span><span class="mi">158</span><span class="s2">         return _linspace_scalar(start, stop, num, endpoint, retstep, dtype)</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">160</span><span class="s2">     if not scalar_start:</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupy/_creation/ranges.py</span> in <span class="ni">_linspace_scalar</span><span class="nt">(start, stop, num, endpoint, retstep, dtype)</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span><span class="s2">         if endpoint:</span>
<span class="g g-Whitespace">    </span><span class="mi">105</span><span class="s2">             # Here num == div + 1 &gt; 1 is ensured.</span>
<span class="ne">--&gt; </span><span class="mi">106</span><span class="s2">             ret[-1] = stop</span>
<span class="g g-Whitespace">    </span><span class="mi">107</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">108</span><span class="s2">     if cupy.issubdtype(dtype, cupy.integer):</span>

<span class="nn">cupy/_core/core.pyx</span> in <span class="ni">cupy._core.core.ndarray.__setitem__</span><span class="nt">()</span>

<span class="nn">cupy/_core/_routines_indexing.pyx</span> in <span class="ni">cupy._core._routines_indexing._ndarray_setitem</span><span class="nt">()</span>

<span class="nn">cupy/_core/_routines_indexing.pyx</span> in <span class="ni">cupy._core._routines_indexing._scatter_op</span><span class="nt">()</span>

<span class="nn">cupy/_core/core.pyx</span> in <span class="ni">cupy._core.core.ndarray.fill</span><span class="nt">()</span>

<span class="nn">cupy/_core/_kernel.pyx</span> in <span class="ni">cupy._core._kernel.ElementwiseKernel.__call__</span><span class="nt">()</span>

<span class="nn">cupy/_core/_kernel.pyx</span> in <span class="ni">cupy._core._kernel.ElementwiseKernel._get_elementwise_kernel</span><span class="nt">()</span>

<span class="nn">cupy/_util.pyx</span> in <span class="ni">cupy._util.memoize.decorator.ret</span><span class="nt">()</span>

<span class="nn">cupy/_core/_kernel.pyx</span> in <span class="ni">cupy._core._kernel._get_elementwise_kernel</span><span class="nt">()</span>

<span class="nn">cupy/_core/_kernel.pyx</span> in <span class="ni">cupy._core._kernel._get_simple_elementwise_kernel</span><span class="nt">()</span>

<span class="nn">cupy/_core/core.pyx</span> in <span class="ni">cupy._core.core.compile_with_cache</span><span class="nt">()</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupy/cuda/compiler.py</span> in <span class="ni">compile_with_cache</span><span class="nt">(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, jitify)</span>
<span class="g g-Whitespace">    </span><span class="mi">430</span><span class="s2">             name_expressions, log_stream, cache_in_memory)</span>
<span class="g g-Whitespace">    </span><span class="mi">431</span><span class="s2">     else:</span>
<span class="ne">--&gt; </span><span class="mi">432</span><span class="s2">         return _compile_with_cache_cuda(</span>
<span class="g g-Whitespace">    </span><span class="mi">433</span><span class="s2">             source, options, arch, cache_dir, extra_source, backend,</span>
<span class="g g-Whitespace">    </span><span class="mi">434</span><span class="s2">             enable_cooperative_groups, name_expressions, log_stream,</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupy/cuda/compiler.py</span> in <span class="ni">_compile_with_cache_cuda</span><span class="nt">(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, cache_in_memory, jitify)</span>
<span class="g g-Whitespace">    </span><span class="mi">507</span><span class="s2">     if backend == &#39;nvrtc&#39;:</span>
<span class="g g-Whitespace">    </span><span class="mi">508</span><span class="s2">         cu_name = &#39;&#39; if cache_in_memory else name + &#39;.cu&#39;</span>
<span class="ne">--&gt; </span><span class="mi">509</span><span class="s2">         ptx, mapping = compile_using_nvrtc(</span>
<span class="g g-Whitespace">    </span><span class="mi">510</span><span class="s2">             source, options, arch, cu_name, name_expressions,</span>
<span class="g g-Whitespace">    </span><span class="mi">511</span><span class="s2">             log_stream, cache_in_memory, jitify)</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupy/cuda/compiler.py</span> in <span class="ni">compile_using_nvrtc</span><span class="nt">(source, options, arch, filename, name_expressions, log_stream, cache_in_memory, jitify)</span>
<span class="g g-Whitespace">    </span><span class="mi">269</span><span class="s2">                 cu_file.write(source)</span>
<span class="g g-Whitespace">    </span><span class="mi">270</span><span class="s2"> </span>
<span class="ne">--&gt; </span><span class="mi">271</span><span class="s2">             return _compile(source, options, cu_path,</span>
<span class="g g-Whitespace">    </span><span class="mi">272</span><span class="s2">                             name_expressions, log_stream, jitify)</span>
<span class="g g-Whitespace">    </span><span class="mi">273</span><span class="s2">     else:</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupy/cuda/compiler.py</span> in <span class="ni">_compile</span><span class="nt">(source, options, cu_path, name_expressions, log_stream, jitify)</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span><span class="s2">                              name_expressions=name_expressions)</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">255</span><span class="s2">             ptx, mapping = prog.compile(options, log_stream)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span><span class="s2">         except CompileException as e:</span>
<span class="g g-Whitespace">    </span><span class="mi">257</span><span class="s2">             dump = _get_bool_env_variable(</span>

<span class="nn">~/.local/lib/python3.8/site-packages/cupy/cuda/compiler.py</span> in <span class="ni">compile</span><span class="nt">(self, options, log_stream)</span>
<span class="g g-Whitespace">    </span><span class="mi">633</span><span class="s2">         except nvrtc.NVRTCError:</span>
<span class="g g-Whitespace">    </span><span class="mi">634</span><span class="s2">             log = nvrtc.getProgramLog(self.ptr)</span>
<span class="ne">--&gt; </span><span class="mi">635</span><span class="s2">             raise CompileException(log, self.src, self.name, options,</span>
<span class="g g-Whitespace">    </span><span class="mi">636</span><span class="s2">                                    &#39;nvrtc&#39; if not runtime.is_hip else &#39;hiprtc&#39;)</span>
<span class="g g-Whitespace">    </span><span class="mi">637</span><span class="s2"> </span>

<span class="ne">CompileException</span>: /home/ubuntu/.local/lib/python3.8/site-packages/cupy/_core/include/cupy/carray.cuh(220): error: the size of an array must be greater than zero
<span class="s2">          detected during instantiation of class &quot;CArray&lt;T, _ndim, _c_contiguous, _use_32bit_indexing&gt; [with T=double, _ndim=0, _c_contiguous=true, _use_32bit_indexing=false]&quot; </span>
<span class="s2">/tmp/tmpy38z_fir/80b50dce313ef4bb36a0d424596a2ca1_2.cubin.cu(8): here</span>

<span class="s2">/home/ubuntu/.local/lib/python3.8/site-packages/cupy/_core/include/cupy/carray.cuh(221): error: the size of an array must be greater than zero</span>
<span class="s2">          detected during instantiation of class &quot;CArray&lt;T, _ndim, _c_contiguous, _use_32bit_indexing&gt; [with T=double, _ndim=0, _c_contiguous=true, _use_32bit_indexing=false]&quot; </span>
<span class="s2">/tmp/tmpy38z_fir/80b50dce313ef4bb36a0d424596a2ca1_2.cubin.cu(8): here</span>

<span class="s2">/home/ubuntu/.local/lib/python3.8/site-packages/cupy/_core/include/cupy/carray.cuh(322): error: the size of an array must be greater than zero</span>
<span class="s2">          detected during instantiation of class &quot;CArray&lt;T, _ndim, _c_contiguous, _use_32bit_indexing&gt; [with T=double, _ndim=0, _c_contiguous=true, _use_32bit_indexing=false]&quot; </span>
<span class="s2">/tmp/tmpy38z_fir/80b50dce313ef4bb36a0d424596a2ca1_2.cubin.cu(8): here</span>

<span class="s2">/home/ubuntu/.local/lib/python3.8/site-packages/cupy/_core/include/cupy/carray.cuh(327): error: the size of an array must be greater than zero</span>
<span class="s2">          detected during instantiation of class &quot;CArray&lt;T, _ndim, _c_contiguous, _use_32bit_indexing&gt; [with T=double, _ndim=0, _c_contiguous=true, _use_32bit_indexing=false]&quot; </span>
<span class="s2">/tmp/tmpy38z_fir/80b50dce313ef4bb36a0d424596a2ca1_2.cubin.cu(8): here</span>

<span class="s2">/tmp/tmpy38z_fir/80b50dce313ef4bb36a0d424596a2ca1_2.cubin.cu(12): error: no operator &quot;[]&quot; matches these operands</span>
<span class="s2">            operand types are: CArray&lt;double, 0, true, false&gt; [ const ptrdiff_t * ]</span>

<span class="mi">5</span><span class="s2"> errors detected in the compilation of &quot;/tmp/tmpy38z_fir/80b50dce313ef4bb36a0d424596a2ca1_2.cubin.cu&quot;.</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Ejercicio</p>
<p>Implementar la regla de Simpson compuesta con <em>CuPy</em> en una máquina de AWS con las mismas características que la que se presenta en esta nota y medir tiempo de ejecución.</p>
</div>
</section>
</section>
<section id="referencias-de-interes">
<h2>Referencias de interés<a class="headerlink" href="#referencias-de-interes" title="Permalink to this headline">#</a></h2>
<p>Para más sobre <em>Unified Memory</em> revisar:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://devblogs.nvidia.com/even-easier-introduction-cuda/">Even easier introduction to cuda</a></p></li>
<li><p><a class="reference external" href="https://devblogs.nvidia.com/unified-memory-cuda-beginners/">Unified memory cuda beginners</a></p></li>
</ul>
<p>Es importante el manejo de errores por ejemplo en el alojamiento de memoria en la GPU. En este caso es útil revisar:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://devblogs.nvidia.com/how-query-device-properties-and-handle-errors-cuda-cc/">How to Query Device Properties and Handle Errors in CUDA C/C++</a></p></li>
</ul>
<p>En las siguientes preguntas encontramos a personas desarrolladoras de CUDA que las resuelven y resultan muy útiles para continuar con el aprendizaje de <em>CUDA C</em>. Por ejemplo:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://stackoverflow.com/questions/51526082/cuda-parallel-reduction-over-one-axis">Parallel reduction over one axis</a></p></li>
</ul>
<p>Otros sistemas de software para el <a class="reference external" href="https://en.wikipedia.org/wiki/Heterogeneous_computing">Heterogeneous computing</a> son:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/OpenCL">OpenCl</a>. Ver <a class="reference external" href="https://developer.nvidia.com/opencl">NVIDIA OpenCL SDK Code Samples</a> para ejemplos con NVIDIA GPU’s.</p></li>
<li><p><a class="reference external" href="https://github.com/Rth-org/Rth">Rth-org/Rth</a> y más reciente <a class="reference external" href="https://github.com/matloff/Rth">matloff/Rth</a>. Ver también <a class="reference external" href="https://rdrr.io/github/matloff/Rth/f/README.md">rdrr.io matloff/Rth</a>.</p></li>
</ul>
<p>Es posible escribir <em>kernels</em> con <em>CuPy</em>. Ver por ejemplo: <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/tutorial/kernel.html">User-Defined Kernels</a>.</p>
<p>Otro paquete para uso de Python+GPU para cómputo matricial es:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/inducer/pycuda/">PyCUDA</a> y ver <a class="reference external" href="https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/Python/PyCUDA">PyCUDA en el repo de la clase</a> para más información.</p></li>
</ul>
<p>Un paquete para uso de pandas+GPU:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/rapidsai">Rapids</a>, <a class="reference external" href="https://github.com/rapidsai/cudf">cudf</a></p></li>
</ul>
<p>Ver <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/install.html#optional-libraries">optional-libraries</a> para librerías que pueden ser utilizadas con CuPy.</p>
<p>Un paquete de <em>R</em> para uso de GPU: <a class="reference external" href="https://rdrr.io/cran/gputools/">gputools: cran</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Ejercicios</p>
<p>1.Resuelve los ejercicios y preguntas de la nota.</p>
</div>
<p><strong>Preguntas de comprehensión:</strong></p>
<p>1)¿Qué factores han determinado un mejor <em>performance</em> de una GPU vs una CPU? (contrasta los diseños de una CPU vs una GPU).</p>
<p>2)¿Dentro de qué modelo de arquitectura de máquinas se ubica a la GPU dentro de la taxonomía de Flynn? (tip: tal modelo se le puede comparar con el modelo <strong>Single Program Multiple Data (SPMD)</strong>)</p>
<p>3)¿Qué significan las siglas CUDA y detalla qué es CUDA?.</p>
<p>4)¿Qué es y en qué consiste CUDA C?</p>
<p>5)¿Qué es un <em>kernel</em>?</p>
<p>6)¿Qué pieza de CUDA se encarga de asignar los bloques de <em>cuda-threads</em> a las SM’s?</p>
<p>7)¿Qué características (recursos compartidos, dimensiones, forma de agendar la ejecución en <em>threads</em>) tienen los bloques que se asignan a una SM al lanzarse y ejecutarse un <em>kernel</em>?</p>
<p>8)¿Qué es un <em>warp</em>?</p>
<p>9)Menciona los tipos de memorias que existen en las GPU’s.</p>
<p>10)Supón que tienes una tarjeta GT200 cuyas características son:</p>
<ul class="simple">
<li><p>Máximo número de <em>threads</em> que soporta una SM en un mismo instante en el tiempo: 1024</p></li>
<li><p>Máximo número de <em>threads</em> en un bloque: 512</p></li>
<li><p>Máximo número de bloques por SM: 8</p></li>
<li><p>Número de SM’s que tiene esta GPU: 30</p></li>
</ul>
<p>Responde:</p>
<p>a)¿Cuál es la máxima cantidad de <em>threads</em> que puede soportar esta GPU en un mismo instante en el tiempo?</p>
<p>b)¿Cuál es la máxima cantidad de <em>warps</em> por SM que puede soportar esta GPU en un mismo instante en el tiempo?</p>
<p>c)¿Cuáles configuraciones de bloques y <em>threads</em> siguientes aprovechan la máxima cantidad de <em>warps</em> en una SM de esta GPU para un mismo instante en el tiempo?</p>
<p>1.Una configuración del tipo: bloques de 64 <em>threads</em> y 16 bloques.</p>
<p>2.Una configuración del tipo: bloques de 1024 <em>threads</em> y 1 bloque.</p>
<p>3.Una configuración del tipo: bloques de 256 <em>threads</em> y 4 bloques.</p>
<p>4.Una configuración del tipo: bloques de 512 <em>threads</em> y 8 bloques.</p>
<p>*Debes considerar las restricciones/características de la GPU dadas para responder pues algunas configuraciones infringen las mismas. No estamos considerando <em>registers</em> o <em>shared memory</em>.</p>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.</p></li>
<li><p>D. B. Kirk, W. W. Hwu, Programming Massively Parallel Processors: A Hands-on Approach, Morgan Kaufmann, 2010.</p></li>
<li><p>NVIDIA,CUDA Programming Guide, NVIDIA Corporation, 2007.</p></li>
<li><p>B. W. Kernighan, D. M. Ritchie, The C Programming Language, Prentice Hall Software Series, 1988</p></li>
<li><p><a class="reference external" href="https://github.com/palmoreck/programming-languages/tree/master/C/extensiones_a_C/CUDA">C/extensiones_a_C/CUDA/</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion_2",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./5.optimizacion_de_codigo/5.5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../6.algoritmos_optimizacion_convexa/6.1/Metodo_de_descenso_mas_pronunciado_para_UCO.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">6.1 Método de descenso más pronunciado para <em>Unconstrained Convex Optimization</em> (UCO)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Erick Palacios Moreno<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>