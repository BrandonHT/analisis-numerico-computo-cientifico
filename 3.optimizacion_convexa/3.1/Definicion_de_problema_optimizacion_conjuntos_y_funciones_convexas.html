
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3.1 Definición de problemas de optimización, conjuntos y funciones convexas</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3.2 Algoritmos de descenso y búsqueda de línea en Unconstrained Convex Optimization (UCO)" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html" />
    <link rel="prev" title="2.4 Valores, vectores singulares y algoritmos para calcular la SVD" href="../../2.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Optimización
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  1. Cómputo científico
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../1.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  2. Cómputo matricial
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../2.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  3. Optimización convexa y ecuaciones no lineales
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html">
   3.2 Algoritmos de descenso y búsqueda de línea en
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.3/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI.html">
   3.3 Ejemplos de problemas UCO, introducción a
   <em>
    Constrained Inequality and Equality Optimization
   </em>
   (CIEO) y puntos interiores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.4/Ecuaciones_no_lineales.html">
   3.4 Ecuaciones no lineales
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  4. Optimización en redes y programación lineal
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.1/Programacion_lineal_y_metodo_simplex.html">
   4.1 Programación lineal (PL) y método símplex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.2/Definiciones_generales_de_flujo_en_redes.html">
   4.2 Definiciones generales de flujo en redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.3/Ejemplo_metodo_simplex_de_redes.html">
   4.3 Ejemplo del método símplex de redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.4/Dualidad_lema_de_Farkas_condiciones_KKT_de_optimalidad.html">
   4.4 Dualidad, lema de Farkas y condiciones de Karush-Kuhn-Tucker (KKT) de optimalidad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../4.optimizacion_en_redes_y_prog_lineal/4.5/Metodo_primal_dual_de_BL.html">
   4.5 Método primal-dual de barrera logarítmica (BL)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  5. Optimización de código
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../5.optimizacion_de_codigo/5.1/introduccion_optimizacion_de_codigo.html">
   5.1 Introducción a optimización de código
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../5.optimizacion_de_codigo/5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html">
   5.2 Herramientas de lenguajes de programación y del sistema operativo para perfilamiento e implementaciones de BLAS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../5.optimizacion_de_codigo/5.3/Compilacion_a_C.html">
   5.3 Compilación a C
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../5.optimizacion_de_codigo/5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html">
   5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../5.optimizacion_de_codigo/5.5/Computo_en_paralelo_usando_GPUS_en_SMC.html">
   5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  6. Algoritmos de optimización convexa
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.1/Metodo_de_descenso_mas_pronunciado_para_UCO.html">
   6.1 Método de descenso más pronunciado para
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.2/Problemas_CECO.html">
   6.2 Problemas tipo
   <em>
    Constrained Equality Convex Optimization
   </em>
   (CECO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../6.algoritmos_optimizacion_convexa/6.3/Problemas_CIECO.html">
   6.3 Problemas tipo
   <em>
    Constrained Equality and Inequality Convex Optimization
   </em>
   (CIECO)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  7. Temas selectos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../7.temas_selectos/7.1/Optimizacion_estocastica.html">
   7.1 Optimización estocástica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../7.temas_selectos/7.2/Metodos_cuasi_Newton.html">
   7.2 Métodos cuasi Newton
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion_2?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/3.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/3.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problemas-de-optimizacion-numerica">
   ¿Problemas de optimización numérica?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizacion-numerica-en-ciencia-de-datos">
   Optimización numérica en ciencia de datos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizacion-numerica-y-machine-learning">
     Optimización numérica y
     <em>
      machine learning
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#del-small-scale-al-large-scale-machine-learning">
     Del
     <em>
      small scale
     </em>
     al
     <em>
      large scale machine learning
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizacion-numerica-convexa">
   ¿Optimización numérica convexa?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problema-estandar-de-optimizacion">
   Problema estándar de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dominio-del-problema-de-optimizacion-y-puntos-factibles">
   Dominio del problema de optimización y puntos factibles
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#valor-optimo-del-problema-de-optimizacion">
   Valor óptimo del problema de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#punto-optimo-del-problema-de-optimizacion">
   Punto óptimo del problema de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimo-local">
   Óptimo local
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#restricciones-activas-no-activas-y-redundantes">
   Restricciones activas, no activas y redundantes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problemas-de-optimizacion-convexa-en-su-forma-estandar-o-canonica">
   Problemas de optimización convexa en su forma estándar o canónica
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funcion-convexa">
   Función convexa
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#propiedades">
     Propiedades
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conjuntos-convexos">
   Conjuntos convexos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linea-y-segmentos-de-linea">
     Línea y segmentos de línea
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conjunto-convexo">
     Conjunto convexo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-de-funciones-convexas-y-concavas">
   Ejemplos de funciones convexas y cóncavas
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resultados-utiles">
   Resultados útiles
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-funciones-convexas-concavas">
     Sobre funciones convexas/cóncavas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-problemas-de-optimizacion">
     Sobre problemas de optimización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-problemas-de-optimizacion-convexa">
     Sobre problemas de optimización convexa
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-puntos-criticos">
     Sobre puntos críticos
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funcion-fuertemente-convexa">
   Función fuertemente convexa
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunos-resultados-que-son-posibles-probar-para-funciones-fuertemente-convexas">
     Algunos resultados que son posibles probar para funciones fuertemente convexas
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>3.1 Definición de problemas de optimización, conjuntos y funciones convexas</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problemas-de-optimizacion-numerica">
   ¿Problemas de optimización numérica?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizacion-numerica-en-ciencia-de-datos">
   Optimización numérica en ciencia de datos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizacion-numerica-y-machine-learning">
     Optimización numérica y
     <em>
      machine learning
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#del-small-scale-al-large-scale-machine-learning">
     Del
     <em>
      small scale
     </em>
     al
     <em>
      large scale machine learning
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizacion-numerica-convexa">
   ¿Optimización numérica convexa?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problema-estandar-de-optimizacion">
   Problema estándar de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dominio-del-problema-de-optimizacion-y-puntos-factibles">
   Dominio del problema de optimización y puntos factibles
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#valor-optimo-del-problema-de-optimizacion">
   Valor óptimo del problema de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#punto-optimo-del-problema-de-optimizacion">
   Punto óptimo del problema de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimo-local">
   Óptimo local
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#restricciones-activas-no-activas-y-redundantes">
   Restricciones activas, no activas y redundantes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problemas-de-optimizacion-convexa-en-su-forma-estandar-o-canonica">
   Problemas de optimización convexa en su forma estándar o canónica
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funcion-convexa">
   Función convexa
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#propiedades">
     Propiedades
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conjuntos-convexos">
   Conjuntos convexos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linea-y-segmentos-de-linea">
     Línea y segmentos de línea
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conjunto-convexo">
     Conjunto convexo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-de-funciones-convexas-y-concavas">
   Ejemplos de funciones convexas y cóncavas
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resultados-utiles">
   Resultados útiles
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-funciones-convexas-concavas">
     Sobre funciones convexas/cóncavas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-problemas-de-optimizacion">
     Sobre problemas de optimización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-problemas-de-optimizacion-convexa">
     Sobre problemas de optimización convexa
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-puntos-criticos">
     Sobre puntos críticos
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funcion-fuertemente-convexa">
   Función fuertemente convexa
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunos-resultados-que-son-posibles-probar-para-funciones-fuertemente-convexas">
     Algunos resultados que son posibles probar para funciones fuertemente convexas
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="definicion-de-problemas-de-optimizacion-conjuntos-y-funciones-convexas">
<span id="dpocfc"></span><h1>3.1 Definición de problemas de optimización, conjuntos y funciones convexas<a class="headerlink" href="#definicion-de-problemas-de-optimizacion-conjuntos-y-funciones-convexas" title="Permalink to this headline">#</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker y <code class="docutils literal notranslate"><span class="pre">&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code> por la versión más actualizada que se presenta en la documentación.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion:&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion:&lt;versión</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">docker&gt;</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de <a class="reference external" href="https://www.dropbox.com/s/qb3swgkpaps7yba/4.1.Introduccion_optimizacion_convexa.pdf?dl=0">liga1</a>, <a class="reference external" href="https://www.dropbox.com/s/6isby5h1e5f2yzs/4.2.Problemas_de_optimizacion_convexa.pdf?dl=0">liga2</a>, <a class="reference external" href="https://www.dropbox.com/s/ko86cce1olbtsbk/4.3.1.Teoria_de_convexidad_Conjuntos_convexos.pdf?dl=0">liga3</a>, <a class="reference external" href="https://www.dropbox.com/s/mmd1uzvwhdwsyiu/4.3.2.Teoria_de_convexidad_Funciones_convexas.pdf?dl=0">liga4</a>, <a class="reference external" href="https://drive.google.com/file/d/1xtkxPCx05Xg4Dj7JZoQ-LusBDrtYUqOF/view">liga5</a>, <a class="reference external" href="https://drive.google.com/file/d/16-_PvWNaO0Zc9x04-SRsxCRdn5fxebf2/view">liga6</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota la comunidad lectora:</p>
<ul class="simple">
<li><p>Conocerá la definición de un problema de optimización, algunos ejemplos, definiciones y resultados que serán utilizados en los métodos para resolver problemas de optimización con énfasis en funciones convexas.</p></li>
<li><p>Tendrá una lista ejemplo de funciones convexas utilizadas en aplicaciones.</p></li>
</ul>
</div>
<section id="problemas-de-optimizacion-numerica">
<h2>¿Problemas de optimización numérica?<a class="headerlink" href="#problemas-de-optimizacion-numerica" title="Permalink to this headline">#</a></h2>
<p>Una gran cantidad de aplicaciones plantean problemas de optimización. Tenemos problemas básicos que se presentan en cursos iniciales de cálculo:</p>
<p><em>Una caja con base y tapa cuadradas debe tener un volumen de <span class="math notranslate nohighlight">\(100 cm^3\)</span>. Encuentre las dimensiones de la caja que minimicen la cantidad de material.</em></p>
<p>Y tenemos más especializados que encontramos en áreas como Estadística, Ingeniería, Finanzas o Aprendizaje de Máquina, <em>Machine Learning</em>:</p>
<ul class="simple">
<li><p>Ajustar un modelo de regresión lineal a un conjunto de datos.</p></li>
<li><p>Buscar la mejor forma de invertir un capital en un conjunto de activos.</p></li>
<li><p>Elección del ancho y largo de un dispositivo en un circuito electrónico.</p></li>
<li><p>Ajustar un modelo que clasifique un conjunto de datos.</p></li>
</ul>
<p>En general un problema de optimización matemática o numérica tiene la forma:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:} f_i(x) \leq b_i, i=1,\dots, m\]</div>
<p>donde: <span class="math notranslate nohighlight">\(x=(x_1,x_2,\dots, x_n)^T\)</span> es la <strong>variable de optimización del problema</strong>, la función <span class="math notranslate nohighlight">\(f_o: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span> es la <strong>función objetivo</strong>, las funciones <span class="math notranslate nohighlight">\(f_i: \mathbb{R}^n \rightarrow \mathbb{R}, i=1,\dots,m\)</span> son las <strong>funciones de restricción</strong> (aquí se colocan únicamente desigualdades pero pueden ser sólo igualdades o bien una combinación de ellas) y las constantes <span class="math notranslate nohighlight">\(b_1,b_2,\dots, b_m\)</span> son los <strong>límites o cotas de las restricciones</strong>.</p>
<p>Un vector <span class="math notranslate nohighlight">\(x^* \in \mathbb{R}^n\)</span> es nombrado <strong>óptimo</strong> o solución del problema anterior si tiene el valor más pequeño de entre todos los vectores <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> que satisfacen las restricciones. Por ejemplo, si <span class="math notranslate nohighlight">\(z \in \mathbb{R}^n\)</span> satisface <span class="math notranslate nohighlight">\(f_1(z) \leq b_1, f_2(z) \leq b_2, \dots, f_m(z) \leq b_m\)</span> y <span class="math notranslate nohighlight">\(x^*\)</span> es óptimo entonces <span class="math notranslate nohighlight">\(f_o(z) \geq f_o(x^*)\)</span>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>A grandes rasgos dos problemas de optimización son equivalentes si con la solución de uno de ellos se obtiene la solución del otro y viceversa.</p>
</aside>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Se consideran funciones objetivo <span class="math notranslate nohighlight">\(f_o: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, sin embargo, hay formulaciones que utilizan <span class="math notranslate nohighlight">\(f_o: \mathbb{R}^n \rightarrow \mathbb{R}^q\)</span>. Tales formulaciones pueden hallarlas en la optimización multicriterio, multiobjetivo, vectorial o también nombrada Pareto, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Multi-objective_optimization">Multi objective optimization</a>.</p></li>
<li><p>El problema de optimización definido utiliza una forma de minimización y no de maximización. Típicamente en la literatura por convención se consideran problemas de este tipo. Además minimizar <span class="math notranslate nohighlight">\(f_o\)</span> y maximizar <span class="math notranslate nohighlight">\(-f_o\)</span> son <strong>problemas de optimización equivalentes</strong>.</p></li>
</ul>
</div>
<section id="ejemplo">
<h3>Ejemplo<a class="headerlink" href="#ejemplo" title="Permalink to this headline">#</a></h3>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \mathbb{R}^n} ||x||_2\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:} Ax \leq b\]</div>
<p>con <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^m\)</span>. En este problema buscamos el vector <span class="math notranslate nohighlight">\(x\)</span> que es solución del problema <span class="math notranslate nohighlight">\(Ax \leq b\)</span> con <strong>mínima norma Euclidiana</strong>. La función objetivo es <span class="math notranslate nohighlight">\(f_o(x)=||x||_2\)</span>, las funciones de restricción son las desigualdades lineales <span class="math notranslate nohighlight">\(f_i(x) = a_i^Tx \leq b_i\)</span> con <span class="math notranslate nohighlight">\(a_i\)</span> <span class="math notranslate nohighlight">\(i\)</span>-ésimo renglón de <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(b_i\)</span> <span class="math notranslate nohighlight">\(i\)</span>-ésima componente de <span class="math notranslate nohighlight">\(b\)</span>, <span class="math notranslate nohighlight">\(\forall i=1,\dots,m\)</span>.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Un problema similar (sólo modificando desigualdad por igualdad) lo encontramos al resolver un sistema de ecuaciones lineales <span class="math notranslate nohighlight">\(Ax=b\)</span> <em>underdetermined</em> en el que <span class="math notranslate nohighlight">\(m &lt; n\)</span> y se busca el vector <span class="math notranslate nohighlight">\(x\)</span> con mínima norma Euclidiana que satisfaga tal sistema. Este sistema puede tener infinitas soluciones o ninguna solución.</p>
</div>
</section>
<section id="id1">
<h3>Ejemplo<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>Encuentra el punto en la gráfica de <span class="math notranslate nohighlight">\(y=x^2\)</span> que es más cercano al punto <span class="math notranslate nohighlight">\(P=(1,0)\)</span> bajo la norma Euclidiana.</p>
<p>Deseamos minimizar la cantidad <span class="math notranslate nohighlight">\(||(1,0)-(x,y)||_2\)</span>. Además <span class="math notranslate nohighlight">\(y = y(x)\)</span> por lo que definiendo la función objetivo <span class="math notranslate nohighlight">\(f_o(x) = ||(1,0)-(x,x^2)||_2=||(1-x,-x^2)||_2=\sqrt{(1-x)^2+x^4}\)</span>, el problema de optimización (sin restricciones) es:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \text{dom}f_o}\sqrt{(1-x)^2+x^4}\]</div>
</section>
</section>
<section id="optimizacion-numerica-en-ciencia-de-datos">
<h2>Optimización numérica en ciencia de datos<a class="headerlink" href="#optimizacion-numerica-en-ciencia-de-datos" title="Permalink to this headline">#</a></h2>
<p>La ciencia de datos apunta al desarrollo de técnicas y se apoya de aplicaciones de <em>machine learning</em> para la extracción de conocimiento útil tomando como fuente de información las grandes cantidades de datos. Algunas de las aplicaciones son:</p>
<ul class="simple">
<li><p>Clasificación de documentos o textos: detección de <em>spam</em>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Natural_language_processing">Procesamiento de lenguaje natural</a>:  <a class="reference external" href="https://en.wikipedia.org/wiki/Named-entity_recognition">named-entity recognition</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Speech_recognition">Reconocimiento de voz</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Computer_vision">Visión por computadora</a>: reconocimiento de rostros o imágenes.</p></li>
<li><p>Detección de fraude.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Pattern_recognition">Reconocimiento de patrones</a>.</p></li>
<li><p>Diagnóstico médico.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Recommender_system">Sistemas de recomendación</a>.</p></li>
</ul>
<p>Las aplicaciones anteriores involucran problemas como son:</p>
<ul class="simple">
<li><p>Clasificación.</p></li>
<li><p>Regresión.</p></li>
<li><p><em>Ranking</em>.</p></li>
<li><p><em>Clustering</em>.</p></li>
<li><p>Reducción de la dimensionalidad.</p></li>
</ul>
<section id="optimizacion-numerica-y-machine-learning">
<h3>Optimización numérica y <em>machine learning</em><a class="headerlink" href="#optimizacion-numerica-y-machine-learning" title="Permalink to this headline">#</a></h3>
<p>En cada una de las aplicaciones o problemas anteriores se utilizan <strong>funciones de pérdida</strong> que guían el proceso de aprendizaje. Tal proceso involucra <strong>optimización parámetros</strong> de la función de pérdida. Por ejemplo, si la función de pérdida en un problema de regresión es una pérdida cuadrática <span class="math notranslate nohighlight">\(\mathcal{L}(y,\hat{y}) = (\hat{y}-y)^2\)</span> con <span class="math notranslate nohighlight">\(\hat{y} = \hat{\beta}_0 + \hat{\beta_1}x\)</span>, entonces el vector de parámetros a optimizar (aprender) es <span class="math notranslate nohighlight">\(\beta= \left[ \begin{array}{c} \beta_0\\ \beta_1 \end{array} \right]\)</span>.</p>
<aside class="sidebar">
<p class="sidebar-title">Un poco de historia…</p>
<p>La IA o Inteligencia Artificial es una rama de la Ciencia de la Computación que atrajo un gran interés en 1950.</p>
<p>Colloquially, the term artificial intelligence is often used to describe machines (or computers) that mimic “cognitive” functions that humans associate with the human mind, such as learning and problem solving (<a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach">S. J. Russel, P. Norvig, 1995</a>)</p>
</aside>
<p><em>Machine learning</em> no sólo se apoya de la optimización pues es un área de Inteligencia Artificial que utiliza técnicas estadísticas para el diseño de sistemas capaces de aplicaciones como las escritas anteriormente, de modo que hoy en día tenemos <em>statistical machine learning</em>. No obstante, uno de los <strong>pilares</strong> de <em>machine learning</em> o <em>statistical machine learning</em> es la optimización.</p>
<p><em>Machine learning</em> o <em>statistical machine learning</em> se apoya de las formulaciones y algoritmos en optimización. Sin embargo, también ha contribuido a ésta área desarrollando nuevos enfoques en los métodos o algoritmos para el tratamiento de grandes cantidades de datos o <em>big data</em> y estableciendo retos significativos no presentes en problemas clásicos de optimización. De hecho, al revisar literatura que intersecta estas dos disciplinas encontramos comunidades científicas que desarrollan o utilizan métodos o algoritmos exactos (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Exact_algorithm">Exact algorithm</a>) y otras que utilizan métodos de optimización estocástica (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_optimization">Stochastic optimization</a> y <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_approximation">Stochastic approximation</a>) basados en métodos o algoritmos aproximados (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Approximation_algorithm">Approximation algorithm</a>). Hoy en día es común encontrar estudios que hacen referencia a <strong>modelos o métodos de aprendizaje</strong>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Como ejemplo de lo anterior considérese la técnica de <a class="reference external" href="https://en.wikipedia.org/wiki/Regularization_(mathematics)"><strong>regularización</strong></a> que en <em>machine learning</em> se utiliza para encontrar soluciones que generalicen y provean una explicación no compleja del fenómeno en estudio.</p>
<p>La regularización sigue el principio de la navaja de Occam, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Occam%27s_razor">Occam’s razor</a>: para cualquier conjunto de observaciones en general se prefieren explicaciones simples a explicaciones más complicadas. Aunque la técnica de regularización es conocida en optimización, han sido varias las aplicaciones de <em>machine learning</em> las que la han posicionado como clave.</p>
</div>
</section>
<section id="del-small-scale-al-large-scale-machine-learning">
<h3>Del <em>small scale</em> al <em>large scale machine learning</em><a class="headerlink" href="#del-small-scale-al-large-scale-machine-learning" title="Permalink to this headline">#</a></h3>
<aside class="sidebar">
<p class="sidebar-title">Un poco de historia…</p>
<p>Un ejemplo de esto se observa en métodos de optimización desarrollados en la década de los <span class="math notranslate nohighlight">\(50\)</span>’s. Mientras que métodos tradicionales en optimización basados en el cálculo del gradiente y la Hessiana de una función son efectivos para problemas de aprendizaje <em>small-scale</em> (en los que  utilizamos un enfoque en <em><strong>batch</strong></em> o por lote), en el contexto del aprendizaje <em>large-scale</em>, el <strong>método de gradiente estocástico</strong> se posicionó en el centro de discusiones a inicios del siglo XXI.</p>
<p>El método de gradiente estocástico fue propuesto por Robbins y Monro en 1951, es un <strong>algoritmo estocástico</strong>. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a>.</p>
</aside>
<p>El inicio del siglo XXI estuvo marcado, entre otros temas, por un incremento significativo en la generación de información. Esto puede contrastarse con el desarrollo de los procesadores de las máquinas, el cual tuvo un menor avance en el incremento del <em>performance</em> al del siglo XX. Asimismo, las mejoras en dispositivos de almacenamiento o <em>storage</em> abarató costos de almacenamiento y mejoras en sistemas de <em>networking</em> permitieron la transmisión de la información más eficiente.  En este contexto, los modelos y métodos de <em>statistical machine learning</em> se vieron limitados por el tiempo de cómputo y no por el tamaño de muestra. La conclusión de esto fue una inclinación en la comunidad científica por el diseño o uso de métodos o modelos para procesar grandes cantidades de datos usando recursos computacionales comparativamente menores.</p>
</section>
</section>
<section id="optimizacion-numerica-convexa">
<h2>¿Optimización numérica convexa?<a class="headerlink" href="#optimizacion-numerica-convexa" title="Permalink to this headline">#</a></h2>
<p>Aplicaciones de <em>machine learning</em> conducen al planteamiento de problemas de optimización convexa y no convexa. Por ejemplo en la aplicación de clasificación de textos, en donde se desea asignar un texto a clases definidas de acuerdo a su contenido (determinar si un documento de texto es sobre un tema), puede formularse un problema convexo a partir de una <strong>función de pérdida convexa</strong>.</p>
<aside class="sidebar">
<p class="sidebar-title">Un poco de historia…</p>
<p>Los tipos de redes neuronales profundas, <em>deep neural networks</em>, que han sido mayormente usadas a inicios del siglo XXI son las mismas que las que eran populares en los años <span class="math notranslate nohighlight">\(90\)</span>’s. El éxito de éstos tipos y su uso primordialmente se debe a la disponibilidad de <em>larger datasets</em> y mayores recursos computacionales.</p>
</aside>
<p>Como ejemplos de aplicaciones en la <strong>optimización no convexa</strong> están el reconocimiento de voz y reconocimiento de imágenes. El uso de <a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_neural_network">redes neuronales</a> <a class="reference external" href="https://en.wikipedia.org/wiki/Deep_learning">profundas</a> ha tenido muy buen desempeño en tales aplicaciones haciendo uso de cómputo en la GPU, ver <a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>, <a class="reference external" href="https://medium.com/limitlessai/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73">2012: A Breakthrough Year for Deep Learning</a>. En este caso se utilizan <strong>funciones objetivo no lineales y no convexas</strong>.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Desde los <span class="math notranslate nohighlight">\(40\)</span>’s se han desarrollado algoritmos para resolver problemas de optimización, se han analizado sus propiedades y se han desarrollado buenas implementaciones de software.  Sin embargo, una clase de problemas de optimización en los que encontramos métodos <strong>efectivos</strong> son los convexos.</p></li>
<li><p>Métodos para optimización no convexa utilizan parte de la teoría de convexidad desarrollada en optimización convexa. Además, un buen número de problemas de aprendizaje utilizan funciones de pérdida convexas.</p></li>
</ul>
</div>
</section>
<section id="problema-estandar-de-optimizacion">
<span id="pestopt"></span><h2>Problema estándar de optimización<a class="headerlink" href="#problema-estandar-de-optimizacion" title="Permalink to this headline">#</a></h2>
<p>En lo que continúa se considera <span class="math notranslate nohighlight">\(f_0 = f_o\)</span> (el subíndice “0” y el subíndice “o” son iguales)</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un problema estándar de optimización es:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f_i(x) \leq 0, \quad \forall i=1,\dots,m\]</div>
<div class="math notranslate nohighlight">
\[h_i(x) = 0, \quad \forall i=1,\dots,p\]</div>
<p>con <span class="math notranslate nohighlight">\(x=(x_1,x_2,\dots, x_n)^T\)</span> es la <strong>variable de optimización del problema</strong>, <span class="math notranslate nohighlight">\(f_o: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> es la <strong>función objetivo</strong>, <span class="math notranslate nohighlight">\(f_i: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> <span class="math notranslate nohighlight">\(\forall i=1,\dots,m\)</span> son las <strong>restricciones de desigualdad</strong>, <span class="math notranslate nohighlight">\(h_i: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(\forall i=1,\dots,p\)</span> son las <strong>restricciones de igualdad</strong>.</p>
</div>
</section>
<section id="dominio-del-problema-de-optimizacion-y-puntos-factibles">
<h2>Dominio del problema de optimización y puntos factibles<a class="headerlink" href="#dominio-del-problema-de-optimizacion-y-puntos-factibles" title="Permalink to this headline">#</a></h2>
<div class="admonition-definiciones admonition">
<p class="admonition-title">Definiciones</p>
<ul class="simple">
<li><p>El conjunto de puntos para los que la función objetivo y las funciones de restricción <span class="math notranslate nohighlight">\(f_i, h_i\)</span> están definidas se nombra <strong>dominio del problema de optimización</strong>, esto es:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathcal{D} = \bigcap_{i=0}^m\text{dom}f_i \cap \bigcap_{i=1}^p\text{dom}h_i.\]</div>
<ul class="simple">
<li><p>Un punto <span class="math notranslate nohighlight">\(x \in \mathcal{D}\)</span> se nombra <strong>factible</strong> si satisface las restricciones de igualdad y desigualdad. El conjunto de puntos factibles se nombra <strong>conjunto de factibilidad</strong>.</p></li>
<li><p>El <a class="reference internal" href="#pestopt"><span class="std std-ref">problema estándar de optimización</span></a> se nombra <strong>problema de optimización factible</strong> si existe <strong>al menos un punto factible</strong>, si no entonces es infactible.</p></li>
</ul>
</div>
</section>
<section id="valor-optimo-del-problema-de-optimizacion">
<h2>Valor óptimo del problema de optimización<a class="headerlink" href="#valor-optimo-del-problema-de-optimizacion" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</aside>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>El valor óptimo del problema se denota como <span class="math notranslate nohighlight">\(p^*\)</span>. En notación matemática es:</p>
<div class="math notranslate nohighlight">
\[p^* = \inf\{f_o(x) | f_i(x) \leq 0, \forall i=1,\dots,m, h_i(x) = 0 \forall i=1,\dots,p\}\]</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Si el problema es <strong>infactible</strong> entonces <span class="math notranslate nohighlight">\(p^* = \infty\)</span>.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\exists x_k\)</span> factible tal que <span class="math notranslate nohighlight">\(f_o(x_k) \rightarrow -\infty\)</span> para <span class="math notranslate nohighlight">\(k \rightarrow \infty\)</span> entonces <span class="math notranslate nohighlight">\(p^*=-\infty\)</span> y se nombra <strong>problema de optimización no acotado por debajo</strong>.</p></li>
</ul>
</div>
</section>
<section id="punto-optimo-del-problema-de-optimizacion">
<span id="poptprobopt"></span><h2>Punto óptimo del problema de optimización<a class="headerlink" href="#punto-optimo-del-problema-de-optimizacion" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</aside>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p><span class="math notranslate nohighlight">\(x^*\)</span> es <strong>punto óptimo</strong> si es factible y <span class="math notranslate nohighlight">\(f_o(x^*) = p^*\)</span>.</p>
<p>El conjunto de óptimos se nombra <strong>conjunto óptimo</strong> y se denota:</p>
<div class="math notranslate nohighlight">
\[X_{\text{opt}} = \{x | f_i(x) \leq 0 \forall i=1,\dots,m, h_i(x) =0 \forall i=1,\dots,p, f_o(x) = p^*\}\]</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>La propiedad de un punto óptimo <span class="math notranslate nohighlight">\(x^*\)</span> es que si <span class="math notranslate nohighlight">\(z\)</span> satisface las restricciones <span class="math notranslate nohighlight">\(f_i(z) \leq 0\)</span> <span class="math notranslate nohighlight">\(\forall i=1,...,m\)</span>, <span class="math notranslate nohighlight">\(h_i(z)=0\)</span> <span class="math notranslate nohighlight">\(\forall i=1,..,p\)</span> se tiene: <span class="math notranslate nohighlight">\(f_o(x^*) \leq f_o(z)\)</span>. Es <strong>óptimo estricto</strong> si <span class="math notranslate nohighlight">\(z\)</span> satisface las restricciones y <span class="math notranslate nohighlight">\(f_o(x^*) &lt; f_o(z)\)</span>.</p></li>
<li><p>Si existe un punto óptimo se dice que el <strong>valor óptimo se alcanza</strong> y por tanto el problema de optimización tiene solución, es <strong>soluble o <em>solvable</em></strong>.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(X_{\text{opt}} = \emptyset\)</span> se dice que el valor óptimo no se alcanza. Obsérvese que para problemas no acotados nunca se alcanza el valor óptimo.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(x\)</span> es factible y <span class="math notranslate nohighlight">\(f_o(x) \leq p^* + \epsilon\)</span> con <span class="math notranslate nohighlight">\(\epsilon &gt;0\)</span>, <span class="math notranslate nohighlight">\(x\)</span> se nombra <strong><span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimo</strong> y el conjunto de puntos <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimos se nombra <strong>conjunto <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimo</strong>.</p></li>
</ul>
</div>
</section>
<section id="optimo-local">
<h2>Óptimo local<a class="headerlink" href="#optimo-local" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</aside>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un punto factible <span class="math notranslate nohighlight">\(x\)</span> se nombra <strong>óptimo local</strong> si <span class="math notranslate nohighlight">\(\exists R &gt; 0\)</span> tal que:</p>
<div class="math notranslate nohighlight">
\[f_o(x) = \inf \{f_o(z) | f_i(z) \leq 0 \forall i=1,\dots,m, h_i(z) = 0 \forall i=1,\dots, p, ||z-x||_2 \leq R\}.\]</div>
<p>Así, <span class="math notranslate nohighlight">\(x\)</span> resuelve:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(z)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f_i(z) \leq 0, \forall i =1,\dots,m\]</div>
<div class="math notranslate nohighlight">
\[h_i(z) =0, \forall i=1,\dots,p\]</div>
<div class="math notranslate nohighlight">
\[||z-x||_2 \leq R\]</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La palabra <strong>óptimo</strong> se utiliza para <strong>óptimo global</strong>, esto es, no consideramos la última restricción <span class="math notranslate nohighlight">\(||z-x||_2 \leq R\)</span> en el problema de optimización y exploramos en todo el <span class="math notranslate nohighlight">\(\text{dom}f\)</span>.</p>
</div>
<img src="https://dl.dropboxusercontent.com/s/xyprhh7erbb6icb/min-max-points-example.png?dl=0" heigth="700" width="700">
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Es común referirse al conjunto de mínimos y máximos como puntos extremos de una función.</p>
</div>
</section>
<section id="restricciones-activas-no-activas-y-redundantes">
<h2>Restricciones activas, no activas y redundantes<a class="headerlink" href="#restricciones-activas-no-activas-y-redundantes" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</aside>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Si <span class="math notranslate nohighlight">\(x\)</span> es factible y <span class="math notranslate nohighlight">\(f_i(x)=0\)</span> entonces la restricción de desigualdad <span class="math notranslate nohighlight">\(f_i(x) \leq 0\)</span> se nombra <strong>restricción activa en <span class="math notranslate nohighlight">\(x\)</span></strong>. Se nombra <strong>inactiva en <span class="math notranslate nohighlight">\(x\)</span></strong> si <span class="math notranslate nohighlight">\(f_i(x) &lt;0\)</span> para alguna <span class="math notranslate nohighlight">\(i=1,\dots ,m\)</span>.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Las restricciones de igualdad, <span class="math notranslate nohighlight">\(h_i(x)\)</span>, siempre son activas en el conjunto factible con <span class="math notranslate nohighlight">\(i=1,\dots ,p\)</span>.</p></li>
<li><p>Una restricción se nombra <strong>restricción redundante</strong> si al quitarla el conjunto factible no se modifica.</p></li>
</ul>
</div>
</section>
<section id="problemas-de-optimizacion-convexa-en-su-forma-estandar-o-canonica">
<span id="proboptconvest"></span><h2>Problemas de optimización convexa en su forma estándar o canónica<a class="headerlink" href="#problemas-de-optimizacion-convexa-en-su-forma-estandar-o-canonica" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</aside>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuerda que una función afín es de la forma <span class="math notranslate nohighlight">\(h(x) = Ax+b\)</span> con <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{p \times n}\)</span> y <span class="math notranslate nohighlight">\(b \in \mathbb{R}^p\)</span>. En la definición <span class="math notranslate nohighlight">\(h_i(x) = a_i^Tx-b_i\)</span> con <span class="math notranslate nohighlight">\(a_i \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(b_i \in \mathbb{R}\)</span> <span class="math notranslate nohighlight">\(\forall i=1,\dots,p\)</span> y geométricamente <span class="math notranslate nohighlight">\(h_i(x)\)</span> es un <strong>hiperplano</strong> en <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.</p>
</aside>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Se define un problema de optimización convexa en su forma estándar o canónica como:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f_i(x) \leq 0 , i=1,\dots,m\]</div>
<div class="math notranslate nohighlight">
\[h_i(x)=0, i=1,\dots,p\]</div>
<p>donde: <span class="math notranslate nohighlight">\(f_i\)</span> son <strong>convexas</strong> <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span> y <span class="math notranslate nohighlight">\(h_i\)</span> <strong>es afín</strong> <span class="math notranslate nohighlight">\(\forall i =1,\dots,p\)</span>.</p>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Un conjunto <span class="math notranslate nohighlight">\(\alpha\)</span>-subnivel es de la forma <span class="math notranslate nohighlight">\(\{x \in \text{dom}f | f(x) \leq \alpha\}\)</span>. Un conjunto subnivel contiene las curvas de nivel de <span class="math notranslate nohighlight">\(f\)</span>, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Level_set">Level set</a>:</p>
<img src="https://dl.dropboxusercontent.com/s/0woqoj8foo5eco9/level_set_of_func.png?dl=0" heigth="300" width="300">
</aside>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El conjunto de factibilidad de un problema de optimización convexa es un conjunto convexo. Esto se sigue pues es una intersección finita de conjuntos convexos: intersección entre las <span class="math notranslate nohighlight">\(x\)</span>’s que satisfacen <span class="math notranslate nohighlight">\(f_i(x) \leq 0\)</span>, <span class="math notranslate nohighlight">\(i=1,\dots ,m\)</span>, que se nombra <strong>conjunto subnivel</strong>, y las <span class="math notranslate nohighlight">\(x\)</span>’s que están en un hiperplano, esto es, que satisfacen <span class="math notranslate nohighlight">\(h_i(x) = 0\)</span>, <span class="math notranslate nohighlight">\(i=1,\dots ,p\)</span>.</p></li>
<li><p>Si en el problema anterior se tiene que <strong>maximizar</strong> una <span class="math notranslate nohighlight">\(f_o\)</span> función objetivo <strong>cóncava</strong> y se tienen misma forma estándar: <span class="math notranslate nohighlight">\(f_i\)</span> convexa, <span class="math notranslate nohighlight">\(h_i\)</span> afín entonces también se nombra al problema como <strong>problema de optimización convexa</strong>. Todos los resultados, conclusiones y algoritmos desarrollados para los problemas de minimización son aplicables para maximización. En este caso se puede resolver un problema de maximización al minimizar la función objetivo  <span class="math notranslate nohighlight">\(-f_o\)</span> que es convexa.</p></li>
</ul>
</div>
</section>
<section id="funcion-convexa">
<h2>Función convexa<a class="headerlink" href="#funcion-convexa" title="Permalink to this headline">#</a></h2>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Sea <span class="math notranslate nohighlight">\(f:\mathbb{R}^n \rightarrow \mathbb{R}\)</span> una función con el conjunto <span class="math notranslate nohighlight">\(\text{dom}f\)</span> convexo. <span class="math notranslate nohighlight">\(f\)</span> se nombra convexa  (en su <span class="math notranslate nohighlight">\(\text{dom}f\)</span>) si <span class="math notranslate nohighlight">\(\forall x,y \in \text{dom}f\)</span> y <span class="math notranslate nohighlight">\(\theta \in [0,1]\)</span> se cumple:</p>
<div class="math notranslate nohighlight">
\[f(\theta x + (1-\theta) y) \leq \theta f(x) + (1-\theta)f(y).\]</div>
<p>Si la desigualdad se cumple de forma estricta <span class="math notranslate nohighlight">\(\forall x \neq y\)</span> <span class="math notranslate nohighlight">\(f\)</span> se nombra <strong>estrictamente convexa</strong>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Observaciones</p>
<ul class="simple">
<li><p>La convexidad de <span class="math notranslate nohighlight">\(f\)</span> se define para <span class="math notranslate nohighlight">\(\text{dom}f\)</span> aunque para casos en particular se detalla el conjunto en el que <span class="math notranslate nohighlight">\(f\)</span> es convexa.</p></li>
<li><p>La desigualdad que define a funciones convexas se nombra <a class="reference external" href="https://en.wikipedia.org/wiki/Jensen%27s_inequality"><strong>desigualdad de Jensen</strong></a>.</p></li>
</ul>
</div>
<section id="propiedades">
<h3>Propiedades<a class="headerlink" href="#propiedades" title="Permalink to this headline">#</a></h3>
<p>Entre las propiedades que tiene una función convexa se encuentran las siguientes:</p>
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(f\)</span> es convexa el conjunto subnivel es un conjunto convexo.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo <span class="math notranslate nohighlight">\(\therefore\)</span> <span class="math notranslate nohighlight">\(\theta x + (1-\theta)y \in \text{dom}f\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> es <strong>cóncava</strong> si <span class="math notranslate nohighlight">\(-f\)</span> es convexa y <strong>estrictamente cóncava</strong> si <span class="math notranslate nohighlight">\(-f\)</span> es estrictamente convexa. Otra forma de definir concavidad es con una desigualdad del tipo:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[f(\theta x + (1-\theta) y) \geq \theta f(x) + (1-\theta)f(y).\]</div>
<p>y mismas definiciones para <span class="math notranslate nohighlight">\(x,y, \theta\)</span> que en la definición de convexidad.</p>
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(f\)</span> es convexa, geométricamente el segmento de línea que se forma con los puntos <span class="math notranslate nohighlight">\((x,f(x)), (y,f(y))\)</span> está por encima o es igual a <span class="math notranslate nohighlight">\(f(\theta x + (1-\theta)y) \forall \theta \in [0,1]\)</span> y <span class="math notranslate nohighlight">\(\forall x,y \in \text{dom}f\)</span>:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/fdcx1k150nfwykv/draw_convexity_for_functions.png?dl=0" heigth="300" width="300">
</section>
</section>
<section id="conjuntos-convexos">
<h2>Conjuntos convexos<a class="headerlink" href="#conjuntos-convexos" title="Permalink to this headline">#</a></h2>
<section id="linea-y-segmentos-de-linea">
<h3>Línea y segmentos de línea<a class="headerlink" href="#linea-y-segmentos-de-linea" title="Permalink to this headline">#</a></h3>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Sean <span class="math notranslate nohighlight">\(x_1, x_2 \in \mathbb{R}^n\)</span> con <span class="math notranslate nohighlight">\(x_1 \neq x_2\)</span>. Entonces el punto:</p>
<div class="math notranslate nohighlight">
\[y = \theta x_1 + (1-\theta)x_2\]</div>
<p>con <span class="math notranslate nohighlight">\(\theta \in \mathbb{R}\)</span> se encuentra en la línea que pasa por <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(x_2\)</span>. <span class="math notranslate nohighlight">\(\theta\)</span> se le nombra parámetro y si <span class="math notranslate nohighlight">\(\theta \in [0,1]\)</span> tenemos un segmento de línea:</p>
<img src="https://dl.dropboxusercontent.com/s/dldljf5igy8xt9d/segmento_linea.png?dl=0" heigth="200" width="200">
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y = \theta x_1 + (1-\theta)x_2 = x_2 + \theta(x_1 -x_2)\)</span> y esta última igualdad se interpreta como “<span class="math notranslate nohighlight">\(y\)</span> es la suma del punto base <span class="math notranslate nohighlight">\(x_2\)</span> y la dirección <span class="math notranslate nohighlight">\(x_1-x_2\)</span> escalada por <span class="math notranslate nohighlight">\(\theta\)</span>”.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\theta=0\)</span> entonces <span class="math notranslate nohighlight">\(y=x_2\)</span>. Si <span class="math notranslate nohighlight">\(\theta \in [0,1]\)</span> entonces <span class="math notranslate nohighlight">\(y\)</span> se “mueve” en la dirección <span class="math notranslate nohighlight">\(x_1-x_2\)</span> hacia <span class="math notranslate nohighlight">\(x_1\)</span> y si <span class="math notranslate nohighlight">\(\theta&gt;1\)</span> entonces <span class="math notranslate nohighlight">\(y\)</span> se encuentra en la línea “más allá” de <span class="math notranslate nohighlight">\(x_1\)</span>:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/nbahrio7p1mj4hs/segmento_linea_2.png?dl=0" heigth="350" width="350">
<p>El punto entre <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(x_2\)</span> tiene <span class="math notranslate nohighlight">\(\theta=\frac{1}{2}\)</span>.</p>
</div>
</section>
<section id="conjunto-convexo">
<h3>Conjunto convexo<a class="headerlink" href="#conjunto-convexo" title="Permalink to this headline">#</a></h3>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un conjunto <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> es convexo si el segmento de línea entre cualquier par de puntos de <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> está completamente contenida en <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>. Esto se escribe matemáticamente como:</p>
<div class="math notranslate nohighlight">
\[\theta x_1 + (1-\theta) x_2 \in \mathcal{C} \quad \forall \theta \in [0,1], \forall x_1, x_2 \in \mathcal{C}.\]</div>
</div>
<p>Ejemplos gráficos de conjuntos convexos:</p>
<img src="https://dl.dropboxusercontent.com/s/gj54ism1lqojot6/ej_conj_convexos.png?dl=0" heigth="400" width="400"><p>Ejemplos gráficos de conjuntos no convexos:</p>
<img src="https://dl.dropboxusercontent.com/s/k37zh5v3iq3kx04/ej_conj_no_convexos.png?dl=0" heigth="350" width="350"><div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El punto <span class="math notranslate nohighlight">\(\displaystyle \sum_{i=1}^k \theta_i x_i\)</span> con <span class="math notranslate nohighlight">\(\displaystyle \sum_{i=1}^k \theta_i=1\)</span>, <span class="math notranslate nohighlight">\(\theta_i \geq 0 \forall i=1,\dots,k\)</span> se nombra <strong>combinación convexa</strong> de los puntos <span class="math notranslate nohighlight">\(x_1, x_2, \dots, x_k\)</span>. Una combinación convexa de los puntos <span class="math notranslate nohighlight">\(x_1, \dots, x_k\)</span> puede pensarse como una mezcla o promedio ponderado de los puntos, con <span class="math notranslate nohighlight">\(\theta_i\)</span> la fracción <span class="math notranslate nohighlight">\(\theta_i\)</span> de <span class="math notranslate nohighlight">\(x_i\)</span> en la mezcla.</p></li>
<li><p>Un conjunto es convexo si y sólo si contiene cualquier combinación convexa de sus puntos.</p></li>
<li><p>El conjunto óptimo y los conjuntos <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimos son convexos. Ver definiciones de conjunto óptimo y <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimos en <a class="reference internal" href="#poptprobopt"><span class="std std-ref">punto óptimo del problema de optimización</span></a>.</p></li>
</ul>
</div>
</section>
</section>
<section id="ejemplos-de-funciones-convexas-y-concavas">
<h2>Ejemplos de funciones convexas y cóncavas<a class="headerlink" href="#ejemplos-de-funciones-convexas-y-concavas" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Una función afín es convexa y cóncava en todo su dominio: <span class="math notranslate nohighlight">\(f(x) = Ax+b\)</span> con <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^m\)</span>, <span class="math notranslate nohighlight">\(\text{dom}f = \mathbb{R}^n\)</span>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Por tanto las funciones lineales también son convexas y cóncavas.</p>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese que los conjuntos de matrices que se utilizan para definir a matrices simétricas semidefinidas positivas y simétricas definidas positivas son <span class="math notranslate nohighlight">\(\mathbb{S}_{+}^n\)</span> y <span class="math notranslate nohighlight">\(\mathbb{S}_{++}^n\)</span> respectivamente (<span class="math notranslate nohighlight">\(\mathbb{S}\)</span> es el conjunto de matrices simétricas).</p>
</aside>
<ul class="simple">
<li><p>Funciones cuadráticas: <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \frac{1}{2} x^TPx + q^Tx + r\)</span> son convexas en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> si <span class="math notranslate nohighlight">\(P \in \mathbb{S}_+^n, q \in \mathbb{R}^n, r \in \mathbb{R}\)</span> con <span class="math notranslate nohighlight">\(\mathbb{S}_+^n\)</span> conjunto de <strong>matrices simétricas positivas semidefinidas</strong>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Observa que por este punto la norma <span class="math notranslate nohighlight">\(2\)</span> o Euclidiana es una función convexa en <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.</p>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese que el producto <span class="math notranslate nohighlight">\(x^T Ax\)</span> con <span class="math notranslate nohighlight">\(A\)</span> simétrica se le nombra forma cuadrática y es un número en <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.</p>
</aside>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p><span class="math notranslate nohighlight">\(x^TPx\)</span> con <span class="math notranslate nohighlight">\(P \in \mathbb{S}^{n}_+\)</span> se nombra forma cuadrática semidefinida positiva.</p>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>La función <span class="math notranslate nohighlight">\(f(x) = \frac{1}{2} x^TPx + q^Tx + r\)</span> es estrictamente convexa si y sólo si <span class="math notranslate nohighlight">\(P \in \mathbb{S}_{++}^n\)</span>. <span class="math notranslate nohighlight">\(f\)</span> es cóncava si y sólo si <span class="math notranslate nohighlight">\(P \in -\mathbb{S}_+^n\)</span>.</p>
</div>
<ul class="simple">
<li><p>Exponenciales: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = e^{ax}\)</span> para cualquier <span class="math notranslate nohighlight">\(a \in \mathbb{R}\)</span> es convexa en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.</p></li>
<li><p>Potencias: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x)=x^a\)</span>:</p>
<ul>
<li><p>Si <span class="math notranslate nohighlight">\(a \geq 1\)</span> o <span class="math notranslate nohighlight">\(a \leq 0\)</span> entonces <span class="math notranslate nohighlight">\(f\)</span> es convexa en <span class="math notranslate nohighlight">\(\mathbb{R}_{++}\)</span> (números reales positivos).</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(0 \leq a \leq 1\)</span> entonces <span class="math notranslate nohighlight">\(f\)</span> es cóncava en <span class="math notranslate nohighlight">\(\mathbb{R}_{++}\)</span>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Potencias del valor absoluto: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x)=|x|^p\)</span> con <span class="math notranslate nohighlight">\(p \geq 1\)</span> es convexa en <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.</p></li>
<li><p>Logaritmo: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \log(x)\)</span> es cóncava en su dominio: <span class="math notranslate nohighlight">\(\mathbb{R}_{++}\)</span>.</p></li>
<li><p>Entropía negativa: <span class="math notranslate nohighlight">\(f(x) = \begin{cases}
x\log(x) &amp;\text{ si } x &gt; 0 ,\\
0 &amp;\text{ si } x = 0
\end{cases}\)</span> es estrictamente convexa en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}_+\)</span>.</p></li>
<li><p>Normas: cualquier norma es convexa en su dominio.</p></li>
<li><p>Función máximo: <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \max\{x_1,\dots,x_n\}\)</span> es convexa.</p></li>
<li><p>Función log-sum-exp: <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x)=\log\left(\displaystyle \sum_{i=1}^ne^{x_i}\right)\)</span> es convexa en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.</p></li>
<li><p>La media geométrica: <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \left(\displaystyle \prod_{i=1}^n x_i \right)^\frac{1}{n}\)</span> es cóncava en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}_{++}^n\)</span>.</p></li>
<li><p>Función log-determinante: <span class="math notranslate nohighlight">\(f: \mathbb{S}^{n} \rightarrow \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(f(x) = \log(\det(X))\)</span> es cóncava en su dominio <span class="math notranslate nohighlight">\(\mathbb{S}_{++}^n\)</span>.</p></li>
</ul>
</section>
<section id="resultados-utiles">
<span id="resut"></span><h2>Resultados útiles<a class="headerlink" href="#resultados-utiles" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se sugiere revisar <a class="reference internal" href="../../1.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html#fcd"><span class="std std-ref">definición de función, continuidad y derivada</span></a> y <a class="reference internal" href="../../1.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html#cpea"><span class="std std-ref">condición de un problema y estabilidad de un algoritmo</span></a> como recordatorio de definiciones. En particular las <strong>definiciones de primera y segunda derivada, gradiente y Hessiana</strong> para la primer nota y la <strong>definición de número de condición de una matriz</strong> para la segunda.</p>
</aside>
<section id="sobre-funciones-convexas-concavas">
<h3>Sobre funciones convexas/cóncavas<a class="headerlink" href="#sobre-funciones-convexas-concavas" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> diferenciable entonces <span class="math notranslate nohighlight">\(f\)</span> es convexa si y sólo si <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es un conjunto convexo y se cumple:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[f(y) \geq f(x) + \nabla f(x)^T(y-x) \forall x,y \in \text{dom}f.\]</div>
<p>Si se cumple de forma estricta la desigualdad <span class="math notranslate nohighlight">\(f\)</span> se nombra estrictamente convexa. También si su <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo y se tiene la desigualdad en la otra dirección “<span class="math notranslate nohighlight">\(\leq\)</span>” entonces <span class="math notranslate nohighlight">\(f\)</span> es cóncava.</p>
<p>Geométricamente este resultado se ve como sigue para <span class="math notranslate nohighlight">\(\nabla f(x) \neq 0\)</span>:</p>
<img src="https://dl.dropboxusercontent.com/s/e581e22xeejdwu0/convexidad_con_hiperplano_de_soporte.png?dl=0" heigth="350" width="350">
<p>y el hiperplano <span class="math notranslate nohighlight">\(f(x) + \nabla f(x)^T(y-x)\)</span> se nombra <strong>hiperplano de soporte para la función <span class="math notranslate nohighlight">\(f\)</span> en el punto <span class="math notranslate nohighlight">\((x,f(x))\)</span></strong>. Obsérvese que si <span class="math notranslate nohighlight">\(\nabla f(x)=0\)</span> se tiene <span class="math notranslate nohighlight">\(f(y) \geq f(x) \forall y \in \text{dom}f\)</span> y por lo tanto <span class="math notranslate nohighlight">\(x\)</span> es un mínimo global de <span class="math notranslate nohighlight">\(f\)</span>.</p>
<ul class="simple">
<li><p>Una función es convexa si y sólo si es convexa al restringirla a cualquier línea que intersecte su dominio, esto es, si <span class="math notranslate nohighlight">\(g(t) = f(x + tv)\)</span> es convexa <span class="math notranslate nohighlight">\(\forall x,v \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(\forall t \in \mathbb{R}\)</span> talque <span class="math notranslate nohighlight">\(x + tv \in \text{dom}f\)</span></p></li>
</ul>
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> tal que <span class="math notranslate nohighlight">\(f \in \mathcal{C}^2(\text{dom}f)\)</span>. Entonces <span class="math notranslate nohighlight">\(f\)</span> es convexa en <span class="math notranslate nohighlight">\(\text{dom}f\)</span> si y sólo si <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo y <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}^n_+\)</span> en <span class="math notranslate nohighlight">\(\text{dom}f\)</span>. Si <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}^n_{++}\)</span> en <span class="math notranslate nohighlight">\(\text{dom}f\)</span> y <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo entonces <span class="math notranslate nohighlight">\(f\)</span> es estrictamente convexa en <span class="math notranslate nohighlight">\(\text{dom}f\)</span>.</p></li>
</ul>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Para una función: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, la hipótesis del enunciado anterior (<span class="math notranslate nohighlight">\(\nabla^2 f(x) \in \mathbb{S}^n_{++}\)</span> en <span class="math notranslate nohighlight">\(\text{dom}f\)</span>) es que la segunda derivada sea positiva. El recíproco no es verdadero, para ver esto considérese <span class="math notranslate nohighlight">\(f(x)=x^4\)</span> la cual es estrictamente convexa en <span class="math notranslate nohighlight">\(\text{dom}f\)</span> pero su segunda derivada en <span class="math notranslate nohighlight">\(0\)</span> no es positiva.</p>
</div>
</section>
<section id="sobre-problemas-de-optimizacion">
<span id="spopt"></span><h3>Sobre problemas de optimización<a class="headerlink" href="#sobre-problemas-de-optimizacion" title="Permalink to this headline">#</a></h3>
<p>Para <strong>problemas de optimización sin restricciones</strong>:</p>
<ul class="simple">
<li><p><strong>Condición necesaria de primer orden:</strong> si <span class="math notranslate nohighlight">\(f_o\)</span> es diferenciable y <span class="math notranslate nohighlight">\(x^*\)</span> es óptimo entonces <span class="math notranslate nohighlight">\(\nabla f_o(x^*) = 0\)</span>.</p></li>
<li><p><strong>Condición necesaria de segundo orden:</strong> si <span class="math notranslate nohighlight">\(f_o \in \mathcal{C}^2(\text{domf})\)</span> y <span class="math notranslate nohighlight">\(x^*\)</span> es mínimo local entonces <span class="math notranslate nohighlight">\(\nabla^2 f_o(x^*) \in \mathbb{S}^n_{+}\)</span></p></li>
<li><p><strong>Condición suficiente de segundo orden:</strong> si <span class="math notranslate nohighlight">\(f_o \in \mathcal{C}^2(\text{domf})\)</span>, <span class="math notranslate nohighlight">\(\nabla f_o(x)=0\)</span> y <span class="math notranslate nohighlight">\(\nabla^2f_o(x) \in \mathbb{S}^n_{++}\)</span> entonces <span class="math notranslate nohighlight">\(x\)</span> es mínimo local estricto.</p></li>
</ul>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Las condiciones anteriores se les conoce con el nombre de <strong>condiciones de optimalidad</strong> para problemas de optimización sin restricciones.</p>
</div>
</section>
<section id="sobre-problemas-de-optimizacion-convexa">
<span id="spoptconv"></span><h3>Sobre problemas de optimización convexa<a class="headerlink" href="#sobre-problemas-de-optimizacion-convexa" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Una propiedad fundamental de un óptimo local en un problema de optimización convexa es que también es un óptimo global. Si la función es estrictamente convexa entonces el conjunto óptimo contiene a lo más un punto.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(f_o\)</span> es diferenciable y <span class="math notranslate nohighlight">\(X\)</span> es el conjunto de factibilidad entonces <span class="math notranslate nohighlight">\(x\)</span> es óptimo si y sólo si <span class="math notranslate nohighlight">\(x \in X\)</span> y <span class="math notranslate nohighlight">\(\nabla f_o(x)^T(y-x) \geq 0\)</span> <span class="math notranslate nohighlight">\(\forall y \in X\)</span>. Si se considera como conjunto de factibilidad <span class="math notranslate nohighlight">\(X = \text{dom}f_o\)</span> (que es un problema sin restricciones) la propiedad se reduce a la <strong>condición necesaria y suficiente de primer orden</strong>: <span class="math notranslate nohighlight">\(x\)</span> es óptimo si y sólo si <span class="math notranslate nohighlight">\(\nabla f_o(x) = 0\)</span>.</p></li>
</ul>
<p>Geométricamente el resultado anterior se visualiza para <span class="math notranslate nohighlight">\(\nabla f_o(x) \neq 0\)</span> y <span class="math notranslate nohighlight">\(-\nabla f_o(x)\)</span> apuntando hacia la dirección dibujada:</p>
<img src="https://dl.dropboxusercontent.com/s/0tmpivvo5ob4oox/optimo_convexidad_con_hiperplano_de_soporte.png?dl=0" heigth="550" width="550">
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Por los resultados anteriores los métodos de optimización buscan resolver la <strong>ecuación no lineal</strong> <span class="math notranslate nohighlight">\(\nabla f_o(x)=0\)</span> para aproximar en general mínimos locales. Dependiendo del número de soluciones de la ecuación <span class="math notranslate nohighlight">\(\nabla f_o(x)=0\)</span> se tienen situaciones distintas. Por ejemplo, si no tiene solución entonces el/los óptimos no se alcanza(n) pues el problema puede no ser acotado por debajo o si existe el óptimo éste puede no alcanzarse. Por otro lado, si la ecuación tiene múltiples soluciones entonces cada solución es un mínimo de <span class="math notranslate nohighlight">\(f_o\)</span>.</p>
</div>
</section>
<section id="sobre-puntos-criticos">
<span id="spcriticos"></span><h3>Sobre puntos críticos<a class="headerlink" href="#sobre-puntos-criticos" title="Permalink to this headline">#</a></h3>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Puntos <span class="math notranslate nohighlight">\(x \in \text{intdom}f\)</span> en los que <span class="math notranslate nohighlight">\(\nabla f(x) = 0\)</span>  o en los que <span class="math notranslate nohighlight">\(\nabla f\)</span> no existe, se les nombra <strong>puntos críticos o estacionarios</strong> de <span class="math notranslate nohighlight">\(f\)</span>.</p>
</div>
<ul class="simple">
<li><p>No todo punto crítico es un extremo de <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p>La Hessiana de <span class="math notranslate nohighlight">\(f\)</span> nos ayuda a caracterizar los puntos críticos en mínimos o máximos locales. Si <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> es punto crítico:</p>
<ul>
<li><p>Y además <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}_{++}\)</span> entonces <span class="math notranslate nohighlight">\(x\)</span> es mínimo local.</p></li>
<li><p>Y además <span class="math notranslate nohighlight">\(\nabla^2f(x) \in -\mathbb{S}_{++}\)</span> entonces <span class="math notranslate nohighlight">\(x\)</span> es máximo local.</p></li>
<li><p>Y además <span class="math notranslate nohighlight">\(\nabla^2f(x)\)</span> es indefinida entonces <span class="math notranslate nohighlight">\(x\)</span> se nombra punto silla o <a class="reference external" href="https://en.wikipedia.org/wiki/Saddle_point"><em>saddle point</em></a>.</p></li>
</ul>
</li>
<li><p>Si <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> es punto crítico y <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}_{+}\)</span> no podemos concluir si es máximo o mínimo local (análogo si <span class="math notranslate nohighlight">\(\nabla^2f(x) \in -\mathbb{S}_{+}\)</span>).</p></li>
</ul>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Una matriz es indefinida si tiene eigenvalores positivos, negativos y cero.</p>
</div>
</section>
</section>
<section id="funcion-fuertemente-convexa">
<h2>Función fuertemente convexa<a class="headerlink" href="#funcion-fuertemente-convexa" title="Permalink to this headline">#</a></h2>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Una función <span class="math notranslate nohighlight">\(f:\mathbb{R}^n \rightarrow \mathbb{R}\)</span> tal que <span class="math notranslate nohighlight">\(f \in \mathcal{C}^2(\text{dom}f)\)</span> se nombra <strong>fuertemente convexa</strong> en el conjunto convexo <span class="math notranslate nohighlight">\(\mathcal{S} \neq \emptyset\)</span> si existe <span class="math notranslate nohighlight">\(m&gt;0\)</span> tal que <span class="math notranslate nohighlight">\(\nabla^2 f(x) - mI\)</span> es simétrica semidefinida positiva <span class="math notranslate nohighlight">\(\forall x \in \mathcal{S}\)</span>.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Es equivalente escribir que una función <span class="math notranslate nohighlight">\(f\)</span> es fuertemente convexa en un conjunto <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> que escribir qu la forma cuadrática que utiliza la matriz <span class="math notranslate nohighlight">\(\nabla^2 f(x)\)</span> está acotada por debajo por una cantidad positiva para toda <span class="math notranslate nohighlight">\(x \in \mathcal{S}\)</span> en la que se evalúe la forma cuadrática.</p></li>
<li><p>Por el punto anterior la función <span class="math notranslate nohighlight">\(e^x\)</span> no es fuertemente convexa pero sí estrictamente convexa (pensar en valores muy negativos). Asimismo <span class="math notranslate nohighlight">\(-log(x)\)</span> tampoco es fuertemente convexa pero sí estrictamente convexa (pensar en valores muy negativos o muy positivos).</p></li>
<li><p>La función <span class="math notranslate nohighlight">\(x^2\)</span> es fuertemente convexa y las formas cuadráticas definidas positivas también lo son.</p></li>
</ul>
</div>
<section id="algunos-resultados-que-son-posibles-probar-para-funciones-fuertemente-convexas">
<span id="resffuertcon"></span><h3>Algunos resultados que son posibles probar para funciones fuertemente convexas<a class="headerlink" href="#algunos-resultados-que-son-posibles-probar-para-funciones-fuertemente-convexas" title="Permalink to this headline">#</a></h3>
<p>Si una función es fuertemente convexa se puede probar que:</p>
<ul class="simple">
<li><p>El conjunto óptimo contiene a lo más un punto.</p></li>
<li><p><span class="math notranslate nohighlight">\(f(y) \geq f(x) + \nabla f(x)^T(y-x) + \frac{m}{2}||y-x||_2^2 \forall x,y \in \mathcal{S}\)</span>, <span class="math notranslate nohighlight">\(m &gt; 0\)</span>. Por esto si <span class="math notranslate nohighlight">\(f\)</span> es fuertemente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> entonces es estrictamente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. También esta desigualdad indica que la diferencia entre la función de <span class="math notranslate nohighlight">\(y\)</span>, <span class="math notranslate nohighlight">\(f(y)\)</span>, y la función lineal en <span class="math notranslate nohighlight">\(y\)</span>, <span class="math notranslate nohighlight">\(f(x) + \nabla f(x)^T(y-x)\)</span> (Taylor a primer orden), está acotada por debajo por una cantidad cuadrática.</p></li>
<li><p>Existe una cota superior para el <strong>número de condición</strong> bajo la norma 2 de la Hessiana de <span class="math notranslate nohighlight">\(f\)</span>, esto es: <span class="math notranslate nohighlight">\(\text{cond}(\nabla ^2 f(x))= \frac{\lambda_\text{max}(\nabla^2 f(x))}{\lambda_\text{min}(\nabla^2 f(x))} \leq K\)</span> con <span class="math notranslate nohighlight">\(K&gt;0\)</span>, <span class="math notranslate nohighlight">\(\forall x \in \mathcal{S}\)</span>.</p></li>
<li><p>La propiedad que una función sea fuertemente convexa garantiza que el número de condición de la Hessiana de <span class="math notranslate nohighlight">\(f\)</span> es una buena medida del desempeño de los algoritmos de optimización convexa sin restricciones (se revisará más adelante).</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Si <span class="math notranslate nohighlight">\(f\)</span> es fuertemente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> entonces es estrictamente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> pero no viceversa, considérese por ejemplo <span class="math notranslate nohighlight">\(f(x)=x^4\)</span> la cual es estrictamente convexa en todo su dominio pero no es fuertemente convexa en todo su dominio pues su segunda derivada se anula en <span class="math notranslate nohighlight">\(x=0\)</span>.</p>
</div>
<p><strong>Preguntas de comprehensión.</strong></p>
<p>1)Revisar el siguiente video: <a class="reference external" href="https://www.youtube.com/watch?v=Qi1Yry33TQE">Ali Rahimi’s talk at NIPS</a> de la plática de <a class="reference external" href="https://twitter.com/alirahimi0">Ali Rahimi</a> y la respuesta de <a class="reference external" href="https://twitter.com/ylecun">Yann LeCun</a>: <a class="reference external" href="https://www2.isye.gatech.edu/~tzhao80/Yann_Response.pdf">My take on Ali Rahimi’s “Test of Time” award talk at NIPS</a>.</p>
<p>2)Detalla qué es un problema de optimización matemática y describe sus elementos.</p>
<p>3)¿Qué forma tiene un problema estándar de optimización?</p>
<p>4)¿Qué propiedad tienen los problemas de optimización que nos ayuda a considerar únicamente problemas de minimización en el desarrollo de métodos y teoría para generalizarlos hacia los de maximización?</p>
<p>5)¿Qué propiedad cumple un punto que es óptimo para un problema de minimización?</p>
<p>6)¿Qué propiedad debe satisfacer una función para que se le llame convexa?</p>
<p>7)¿Qué forma tiene un problema convexo estándar con igualdades y desigualdades?</p>
<p>8)¿Cuál es la definición de un conjunto convexo?</p>
<p>9)Da ejemplos de conjuntos convexos.</p>
<p>10)¿Cuál es la definición de una combinación convexa?</p>
<p>11)Escribe equivalencias para definir funciones convexas.</p>
<p>12)¿Cuál es la definición de una función cóncava?</p>
<p>13)Escribe ejemplos de funciones convexas.</p>
<p>14)¿Cuál es la definición de una función estrictamente convexa?</p>
<p>15)Escribe resultados útiles respecto a problemas de optimización, optimización convexos y puntos críticos.</p>
<p>16)¿Cuál es la definición de una función fuertemente convexa?</p>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>S. P. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2009.</p></li>
</ol>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion_2",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./3.optimizacion_convexa/3.1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../2.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">2.4 Valores, vectores singulares y algoritmos para calcular la SVD</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3.2 Algoritmos de descenso y búsqueda de línea en <em>Unconstrained Convex Optimization</em> (UCO)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Erick Palacios Moreno<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>